id: "db-opt-index-trap-001"
version: "2.0.0"
category: "databases"
subcategory: "optimization"

# =============================================================================
# LLM GENERATION FRAMEWORK
# =============================================================================
# This configuration enables generation of 10,000+ unique, complex tasks
# related to database indexing, index optimization, and index-related issues.
# =============================================================================

generation_framework:
  # Difficulty parameters - SIGNIFICANTLY increased for database architect-level challenges
  time_range: [5400, 14400]  # 90-240 minutes for database architects with internals expertise
  command_steps: [80, 200]   # Requires extensive multi-layer investigation and debugging
  
  generation_targets:
    minimum_difficulty: "90+ minutes, requires deep database index internals and storage engine expertise"
    target_audience: "Principal Database Architects and query optimization engineers with 10+ years experience"
    complexity_level: "Nightmare - requires synthesizing knowledge across B-tree/LSM internals, query optimizer integration, and storage layer interactions"
  
  multi_agent_orchestration:
    description: "Coordinate 5-8 specialized database agents for complex index optimization"
    required_agents:
      - name: "btree_internals_expert"
        role: "Analyze B-tree structure, page splits, and traversal efficiency"
        expertise: ["tree rebalancing", "fill factor", "page organization", "key compression"]
      - name: "query_optimizer_index_analyst"
        role: "Debug optimizer index selection and cost estimation"
        expertise: ["index selectivity", "cost models", "statistics usage", "plan costing"]
      - name: "covering_index_designer"
        role: "Design covering indexes and analyze index-only scan opportunities"
        expertise: ["INCLUDE columns", "column ordering", "visibility map", "index-only execution"]
      - name: "composite_key_optimizer"
        role: "Optimize composite index column ordering and prefix matching"
        expertise: ["leftmost prefix", "equality vs range", "sort optimization", "skip scan"]
      - name: "index_maintenance_analyst"
        role: "Analyze index maintenance overhead and fragmentation"
        expertise: ["page splits", "fill factor", "bloat detection", "online rebuild"]
      - name: "partial_index_specialist"
        role: "Design partial and filtered indexes for specific query patterns"
        expertise: ["WHERE clause matching", "predicate selectivity", "multi-tenant indexing"]
      - name: "specialized_index_expert"
        role: "Analyze GIN, GiST, BRIN, and specialized index types"
        expertise: ["full-text search", "geometric indexing", "range indexing", "array indexing"]
      - name: "index_impact_profiler"
        role: "Profile index impact on write performance and resource usage"
        expertise: ["write amplification", "checkpoint behavior", "WAL generation", "I/O patterns"]
    
    cross_engine_attack_chains:
      - chain: "missing_index -> full_table_scan -> buffer_pool_churn -> checkpoint_stall -> write_amplification"
        description: "Missing index causes scans that destabilize buffer pool and trigger checkpoint issues"
      - chain: "over_indexing -> write_overhead -> WAL_explosion -> replication_lag -> read_staleness"
        description: "Too many indexes cause write overhead leading to replication issues"
      - chain: "wrong_column_order -> index_scan_fallback -> high_io -> lock_contention -> deadlock"
        description: "Suboptimal index ordering causes IO patterns that increase lock conflicts"
      - chain: "stale_statistics -> wrong_index_choice -> nested_loop_on_large -> memory_exhaustion -> query_timeout"
        description: "Stale statistics lead to wrong index selection causing query resource exhaustion"
    
    parallel_analysis_requirements:
      - "Concurrent index usage analysis across all query patterns"
      - "Parallel selectivity estimation for multi-column indexes"
      - "Simultaneous fragmentation assessment across all indexes"
      - "Coordinated write impact analysis under varying workloads"
    
    agent_handoff_scenarios:
      - from: "query_optimizer_index_analyst"
        to: "composite_key_optimizer"
        trigger: "Index selection issue traced to column ordering"
      - from: "index_maintenance_analyst"
        to: "btree_internals_expert"
        trigger: "Maintenance issue requires deep B-tree analysis"
      - from: "covering_index_designer"
        to: "index_impact_profiler"
        trigger: "Covering index design needs write impact assessment"
  
  multi_conversation_workflow:
    phase_1_research: |
      Research advanced database indexing concepts:
      - Index types and their internal structures
      - Index selection algorithms
      - Query optimizer interaction with indexes
      - Index maintenance overhead
      - Database-specific index features
    
    phase_2_creation: |
      Create task with hidden complexity and traps including:
      - Subtle index design flaws
      - Function-on-column antipatterns
      - Composite index ordering issues
      - Covering index opportunities
      - Index selectivity problems
    
    phase_3_amplification: |
      Add difficulty multipliers and edge cases:
      - Large table scenarios
      - High-write workloads
      - Complex query patterns
      - Multi-column index decisions
      - Partial and filtered indexes
    
    phase_4_verification: |
      Validate task requires deep indexing expertise:
      - Must understand index internals at storage engine level
      - Must know optimizer index selection algorithms and cost model integration
      - Cannot be solved by simple index creation or obvious optimizations
      - Requires deep query plan analysis with buffer and I/O correlation
      - Tests understanding of read/write tradeoffs across workload patterns
      - Has at least 10+ deeply interacting traps across index/optimizer/storage/maintenance layers
      - Has cascading failure modes that span index structure, query execution, and storage I/O
      - Requires knowledge of B-tree/LSM internals, optimizer cost models, and buffer pool interactions
      - Would take experienced database architects 90+ minutes
      - Involves multi-column index optimization with complex access pattern analysis
  
  quality_requirements:
    - "Must require understanding of B-tree/LSM-tree/specialized index internals at implementation level"
    - "Must have at least 8 non-obvious performance issues with complex interactions"
    - "Must not be solvable by creating obvious indexes or following simple rules"
    - "Must require deep query plan analysis with cost model understanding"
    - "Must involve database-specific index behaviors and version-specific optimizations"
    - "90+ minutes for experienced database architects, 180+ for senior engineers"
    - "Requires synthesizing index structures, optimizer cost models, buffer pool behavior, and maintenance overhead"
    - "Must involve workload-specific optimization with read/write balance analysis"
    - "Requires understanding of statistics generation, selectivity estimation, and histogram usage"

# =============================================================================
# TOPIC UNIVERSE - 150+ Index-Related Topics
# =============================================================================

topic_universe:
  # ---------------------------------------------------------------------------
  # Index Types and Structures
  # ---------------------------------------------------------------------------
  index_types:
    btree:
      description: "Balanced tree index, most common type"
      structure:
        root: "Top-level node"
        internal: "Branch nodes with keys and pointers"
        leaf: "Contains keys and row pointers/data"
      characteristics:
        - "O(log n) search, insert, delete"
        - "Ordered traversal"
        - "Range queries efficient"
        - "Equality queries efficient"
      implementations:
        postgresql: "Default index type"
        mysql_innodb: "B+tree (data in leaf)"
        sql_server: "B+tree"
        oracle: "B*tree (balanced at all levels)"
      best_for:
        - "Equality comparisons (=)"
        - "Range comparisons (<, >, BETWEEN)"
        - "ORDER BY optimization"
        - "PREFIX LIKE ('abc%')"
      not_good_for:
        - "Full-text search"
        - "Spatial queries"
        - "Pattern matching (LIKE '%abc')"
    
    hash:
      description: "Hash-based index for equality only"
      structure:
        - "Hash function maps key to bucket"
        - "Bucket contains key-value pairs"
      characteristics:
        - "O(1) lookup for exact match"
        - "No ordering"
        - "No range queries"
      implementations:
        postgresql: "CREATE INDEX ... USING hash"
        mysql_memory: "MEMORY tables only"
        mysql_adaptive: "Adaptive hash index (InnoDB internal)"
      best_for:
        - "Exact equality queries only"
        - "Join operations on equality"
      limitations:
        - "No range scans"
        - "No ordering"
        - "Not crash-safe in older PostgreSQL"
    
    bitmap:
      description: "Bitmap for low-cardinality columns"
      structure:
        - "One bitmap per distinct value"
        - "Bit position = row position"
      characteristics:
        - "Very efficient for low cardinality"
        - "Excellent for AND/OR operations"
        - "Space efficient"
      implementations:
        oracle: "CREATE BITMAP INDEX"
        postgresql: "Bitmap index scan (runtime)"
      best_for:
        - "Low cardinality columns (gender, status)"
        - "Data warehousing"
        - "Complex WHERE with AND/OR"
      limitations:
        - "Poor for high cardinality"
        - "Lock contention on updates"
        - "Not in all databases"
    
    gist:
      description: "Generalized Search Tree"
      uses:
        - "Geometric data"
        - "Full-text search"
        - "Range types"
        - "Custom data types"
      implementations:
        postgresql: "CREATE INDEX ... USING gist"
      operations:
        - "Containment (@>)"
        - "Overlap (&&)"
        - "Nearest neighbor (ORDER BY distance)"
    
    gin:
      description: "Generalized Inverted Index"
      uses:
        - "Full-text search"
        - "Array containment"
        - "JSONB containment"
      implementations:
        postgresql: "CREATE INDEX ... USING gin"
      best_for:
        - "Multi-valued attributes"
        - "Full-text search"
        - "JSONB queries"
      characteristics:
        - "Slow to build and update"
        - "Fast to query"
        - "Pending list for updates"
    
    brin:
      description: "Block Range Index"
      structure:
        - "Stores min/max per block range"
        - "Very small index size"
      implementations:
        postgresql: "CREATE INDEX ... USING brin"
      best_for:
        - "Naturally ordered data (timestamps)"
        - "Very large tables"
        - "Append-only workloads"
      characteristics:
        - "Much smaller than B-tree"
        - "Less precise (lossy)"
        - "Good for correlated columns"
    
    fulltext:
      description: "Full-text search index"
      implementations:
        mysql: "FULLTEXT index"
        postgresql: "GIN on tsvector"
        sql_server: "Full-text catalog"
        oracle: "Oracle Text"
      features:
        - "Word tokenization"
        - "Stop words"
        - "Stemming"
        - "Ranking"
    
    spatial:
      description: "Index for geographic/geometric data"
      types:
        r_tree: "Rectangle-based partitioning"
        quad_tree: "Quadrant-based partitioning"
      implementations:
        postgresql: "PostGIS with GiST"
        mysql: "SPATIAL index"
        sql_server: "Spatial index"
      operations:
        - "Within distance"
        - "Intersects"
        - "Contains"

  # ---------------------------------------------------------------------------
  # Index Operations
  # ---------------------------------------------------------------------------
  index_operations:
    index_scan:
      description: "Traverse index to find matching rows"
      types:
        index_scan: "Use index, then fetch rows"
        index_only_scan: "All data from index (covering)"
        bitmap_index_scan: "Build bitmap, then fetch"
      cost_factors:
        - "Index depth"
        - "Selectivity"
        - "Random I/O for row fetch"
    
    index_seek:
      description: "Direct lookup in index"
      when_used: "Equality or range on leading columns"
      efficiency: "Very efficient, O(log n)"
    
    index_range_scan:
      description: "Scan portion of index"
      when_used: "Range conditions on indexed column"
      considerations:
        - "Selectivity determines efficiency"
        - "May degrade to table scan"
    
    index_full_scan:
      description: "Scan entire index"
      when_used:
        - "All index values needed"
        - "Ordered output without sort"
      better_than_table_scan: "When index smaller than table"
    
    index_skip_scan:
      description: "Skip leading columns with few values"
      when_used: "Leading column not in WHERE but low cardinality"
      implementations:
        oracle: "INDEX SKIP SCAN"
        mysql_8: "Skip scan optimization"
        postgresql: "Not directly supported"
    
    index_merge:
      description: "Combine multiple indexes"
      types:
        intersection: "AND conditions"
        union: "OR conditions"
        sort_union: "OR with ordering"
      implementations:
        mysql: "Index merge optimization"
        postgresql: "BitmapAnd, BitmapOr"

  # ---------------------------------------------------------------------------
  # Composite Index Considerations
  # ---------------------------------------------------------------------------
  composite_indexes:
    column_ordering:
      principles:
        - "Equality columns before range columns"
        - "Most selective column considerations"
        - "Query pattern matching"
      leftmost_prefix:
        description: "Index on (a, b, c) supports queries on (a), (a, b), (a, b, c)"
        implication: "Column order matters for query coverage"
    
    covering_index:
      description: "Index contains all columns needed by query"
      benefits:
        - "No table access needed"
        - "Faster queries"
        - "Reduced I/O"
      creation:
        postgresql: "CREATE INDEX ... INCLUDE (col1, col2)"
        sql_server: "CREATE INDEX ... INCLUDE (col1, col2)"
        mysql: "No separate INCLUDE, add to key"
    
    selectivity_ordering:
      high_selectivity_first:
        argument: "Filters more data early"
        caveat: "May not always be optimal"
      query_pattern_first:
        argument: "Match actual query patterns"
        caveat: "Multiple queries may conflict"

  # ---------------------------------------------------------------------------
  # Partial and Filtered Indexes
  # ---------------------------------------------------------------------------
  partial_indexes:
    description: "Index only subset of rows"
    syntax:
      postgresql: "CREATE INDEX ... WHERE condition"
      sql_server: "CREATE INDEX ... WHERE condition"
      mysql: "Not directly supported (use generated column)"
    use_cases:
      - "Index only active records"
      - "Index only recent data"
      - "Index only non-null values"
      - "Multi-tenant with filtered indexes"
    benefits:
      - "Smaller index size"
      - "Faster updates"
      - "More specific optimization"
    considerations:
      - "Query must match filter exactly"
      - "Optimizer must recognize applicability"

  # ---------------------------------------------------------------------------
  # Index Maintenance
  # ---------------------------------------------------------------------------
  index_maintenance:
    fragmentation:
      causes:
        - "Random inserts"
        - "Updates changing indexed values"
        - "Deletes leaving gaps"
      effects:
        - "Larger index size"
        - "More I/O operations"
        - "Slower scans"
      remediation:
        postgresql: "REINDEX, VACUUM"
        mysql: "OPTIMIZE TABLE, ALTER TABLE ... REBUILD"
        sql_server: "ALTER INDEX REBUILD, REORGANIZE"
        oracle: "ALTER INDEX REBUILD"
    
    statistics:
      purpose: "Help optimizer estimate costs"
      contents:
        - "Histogram of value distribution"
        - "Number of distinct values"
        - "Number of nulls"
        - "Correlation with physical order"
      update_triggers:
        automatic: "After certain % changes"
        manual: "ANALYZE, UPDATE STATISTICS"
      staleness_effects:
        - "Wrong index chosen"
        - "Bad cardinality estimates"
        - "Suboptimal plans"
    
    bloat:
      description: "Dead space in index"
      causes:
        postgresql: "MVCC leaves dead tuples"
        mysql: "Page splits, deletes"
      detection:
        postgresql: "pgstattuple extension"
        mysql: "SHOW INDEX FROM table"
      remediation:
        postgresql: "REINDEX, pg_repack"
        mysql: "OPTIMIZE TABLE"

  # ---------------------------------------------------------------------------
  # Database-Specific Index Features
  # ---------------------------------------------------------------------------
  database_specific:
    postgresql:
      unique_features:
        - "Expression indexes"
        - "Partial indexes"
        - "INCLUDE columns"
        - "BRIN indexes"
        - "Multiple index types"
      index_only_scan: "Requires visibility map"
      concurrent_creation: "CREATE INDEX CONCURRENTLY"
    
    mysql_innodb:
      clustered_index: "Primary key is clustered"
      secondary_indexes: "Contain primary key value"
      adaptive_hash: "Auto-created hash index"
      online_ddl: "ALGORITHM=INPLACE"
      invisible_indexes: "Test before drop"
    
    sql_server:
      clustered_index: "Table ordered by clustered index"
      nonclustered: "Separate structure with row locator"
      columnstore: "Column-oriented for analytics"
      online_operations: "Enterprise edition"
      filtered_indexes: "WHERE clause on index"
    
    oracle:
      index_organized_tables: "Table stored in B-tree"
      bitmap_indexes: "Native support"
      function_based_indexes: "Index on expression"
      invisible_indexes: "Test impact before drop"
      compression: "Index key compression"

# =============================================================================
# TRAP TYPES - 80+ Index Traps
# =============================================================================

trap_types:
  # ---------------------------------------------------------------------------
  # Function-on-Column Traps
  # ---------------------------------------------------------------------------
  function_on_column:
    - trap_id: "FC-001"
      name: "UPPER/LOWER Function Prevents Index"
      description: "Function on column prevents index use"
      trigger: "WHERE UPPER(name) = 'JOHN'"
      difficulty: "easy"
      solution: "Expression index or normalize data"
      example: |
        -- Index not used
        SELECT * FROM users WHERE UPPER(email) = 'TEST@EXAMPLE.COM';
        
        -- Solutions:
        -- 1. Store lowercase, query lowercase
        -- 2. CREATE INDEX idx_email_upper ON users (UPPER(email));
    
    - trap_id: "FC-002"
      name: "DATE/YEAR Function Prevents Index"
      description: "Extracting date part prevents index use"
      trigger: "WHERE YEAR(created_at) = 2024"
      difficulty: "easy"
      solution: "Use range query instead"
      example: |
        -- Index not used
        SELECT * FROM orders WHERE YEAR(order_date) = 2024;
        
        -- Solution: range query
        SELECT * FROM orders 
        WHERE order_date >= '2024-01-01' 
          AND order_date < '2025-01-01';
    
    - trap_id: "FC-003"
      name: "Type Cast Prevents Index"
      description: "Implicit or explicit type cast prevents index"
      trigger: "WHERE CAST(id AS VARCHAR) = '123'"
      difficulty: "medium"
      solution: "Keep types consistent"
    
    - trap_id: "FC-004"
      name: "Arithmetic on Column"
      description: "Math operation prevents index use"
      trigger: "WHERE price * 1.1 > 100"
      difficulty: "medium"
      solution: "WHERE price > 100 / 1.1"
    
    - trap_id: "FC-005"
      name: "COALESCE/IFNULL Prevents Index"
      description: "Null-handling function prevents index"
      trigger: "WHERE COALESCE(status, 'unknown') = 'active'"
      difficulty: "medium"
      solution: "Handle NULL separately or index expression"

  # ---------------------------------------------------------------------------
  # Composite Index Ordering Traps
  # ---------------------------------------------------------------------------
  composite_ordering:
    - trap_id: "CO-001"
      name: "Wrong Column Order"
      description: "Index columns not matching query pattern"
      trigger: "Index (a, b) but query has WHERE b = x AND a = y"
      difficulty: "medium"
      note: "Query still uses index, but less efficiently"
      example: |
        -- Index on (status, customer_id)
        -- Query: WHERE customer_id = 123 AND status = 'active'
        -- Index can be used but not optimally
    
    - trap_id: "CO-002"
      name: "Range After Equality"
      description: "Range condition after equality in WHERE"
      trigger: "Index (a, b) WHERE a > 5 AND b = 10"
      difficulty: "hard"
      issue: "Range on 'a' makes 'b' condition less useful"
    
    - trap_id: "CO-003"
      name: "Missing Leftmost Column"
      description: "Query doesn't include leftmost index column"
      trigger: "Index (a, b, c) but query only has WHERE b = x"
      difficulty: "medium"
      consequence: "Index may not be used at all"
    
    - trap_id: "CO-004"
      name: "ORDER BY Mismatch"
      description: "ORDER BY doesn't match index order"
      trigger: "Index (a, b) but ORDER BY b, a"
      difficulty: "medium"
      consequence: "Additional sort operation needed"
    
    - trap_id: "CO-005"
      name: "Mixed ASC/DESC"
      description: "Mixed sort directions prevent index-based sort"
      trigger: "ORDER BY a ASC, b DESC with index (a, b)"
      difficulty: "hard"
      solution: "Create index with matching sort direction"

  # ---------------------------------------------------------------------------
  # Selectivity Traps
  # ---------------------------------------------------------------------------
  selectivity:
    - trap_id: "SE-001"
      name: "Low Selectivity Index"
      description: "Index on low-cardinality column"
      trigger: "Index on boolean or status column"
      difficulty: "medium"
      example: |
        -- Index on is_active (true/false)
        -- If 95% are active, index rarely helps
    
    - trap_id: "SE-002"
      name: "High Selectivity Not Used"
      description: "Optimizer chooses wrong index"
      trigger: "Statistics out of date"
      difficulty: "hard"
      solution: "Update statistics"
    
    - trap_id: "SE-003"
      name: "Selectivity Estimation Error"
      description: "Optimizer misjudges cardinality"
      trigger: "Correlated columns, skewed data"
      difficulty: "hard"
      solution: "Multi-column statistics, hints"
    
    - trap_id: "SE-004"
      name: "NULL Selectivity"
      description: "NULLs not indexed or miscounted"
      trigger: "Query for NULL values"
      difficulty: "medium"
      databases: ["Oracle (NULLs not in B-tree index)"]

  # ---------------------------------------------------------------------------
  # Covering Index Traps
  # ---------------------------------------------------------------------------
  covering_index:
    - trap_id: "CI-001"
      name: "Missing Covering Column"
      description: "Index almost covers query but misses one column"
      trigger: "SELECT a, b, c with index (a, b)"
      difficulty: "medium"
      solution: "Add c to index with INCLUDE"
    
    - trap_id: "CI-002"
      name: "Covering Index Too Wide"
      description: "Too many columns makes index large"
      trigger: "INCLUDE all columns for coverage"
      difficulty: "medium"
      tradeoff: "Write overhead vs read benefit"
    
    - trap_id: "CI-003"
      name: "Visibility Map Not Updated"
      description: "PostgreSQL can't use index-only scan"
      trigger: "Recent updates, no VACUUM"
      difficulty: "hard"
      databases: ["PostgreSQL"]

  # ---------------------------------------------------------------------------
  # Over-Indexing Traps
  # ---------------------------------------------------------------------------
  over_indexing:
    - trap_id: "OI-001"
      name: "Too Many Indexes"
      description: "Write performance suffers from many indexes"
      trigger: "Every column indexed"
      difficulty: "medium"
      impact: "Slow INSERT/UPDATE/DELETE"
    
    - trap_id: "OI-002"
      name: "Redundant Indexes"
      description: "Index covered by another index"
      trigger: "Index (a) when index (a, b) exists"
      difficulty: "easy"
      solution: "Remove redundant index"
    
    - trap_id: "OI-003"
      name: "Duplicate Indexes"
      description: "Same index created twice"
      trigger: "Different names, same columns"
      difficulty: "easy"
    
    - trap_id: "OI-004"
      name: "Unused Indexes"
      description: "Index never used by queries"
      trigger: "Query pattern changed"
      difficulty: "medium"
      detection: "pg_stat_user_indexes, sys.dm_db_index_usage_stats"

  # ---------------------------------------------------------------------------
  # LIKE Query Traps
  # ---------------------------------------------------------------------------
  like_queries:
    - trap_id: "LK-001"
      name: "Leading Wildcard"
      description: "LIKE '%pattern' can't use index"
      trigger: "LIKE '%search%'"
      difficulty: "easy"
      solution: "Full-text search, reverse index"
    
    - trap_id: "LK-002"
      name: "Collation Mismatch"
      description: "Index collation doesn't match query"
      trigger: "Case-sensitive index, case-insensitive query"
      difficulty: "hard"
      databases: ["PostgreSQL"]
    
    - trap_id: "LK-003"
      name: "Pattern Too Short"
      description: "Very short pattern has low selectivity"
      trigger: "LIKE 'a%'"
      difficulty: "medium"

  # ---------------------------------------------------------------------------
  # NULL Handling Traps
  # ---------------------------------------------------------------------------
  null_handling:
    - trap_id: "NH-001"
      name: "NULL Not in Index"
      description: "Some databases don't index NULLs"
      trigger: "Query for NULL values"
      difficulty: "medium"
      databases: ["Oracle"]
      workaround: "Include constant in composite index"
    
    - trap_id: "NH-002"
      name: "IS NULL vs = NULL"
      description: "Wrong NULL comparison syntax"
      trigger: "WHERE column = NULL"
      difficulty: "easy"
    
    - trap_id: "NH-003"
      name: "NULL in UNIQUE Index"
      description: "Multiple NULLs allowed in unique index"
      trigger: "Unique constraint on nullable column"
      difficulty: "medium"
      behavior_varies: true

  # ---------------------------------------------------------------------------
  # Index Hints Traps
  # ---------------------------------------------------------------------------
  hints:
    - trap_id: "HT-001"
      name: "Hardcoded Index Hint"
      description: "Index hint becomes wrong over time"
      trigger: "Index renamed or schema changed"
      difficulty: "hard"
    
    - trap_id: "HT-002"
      name: "Hint Overrides Better Plan"
      description: "Hint forces suboptimal plan"
      trigger: "Data distribution changed"
      difficulty: "hard"
    
    - trap_id: "HT-003"
      name: "Hint Syntax Varies"
      description: "Hint syntax different per database"
      trigger: "Migrating queries between databases"
      difficulty: "medium"

  # ---------------------------------------------------------------------------
  # Maintenance Traps
  # ---------------------------------------------------------------------------
  maintenance:
    - trap_id: "MT-001"
      name: "Index Fragmentation"
      description: "Fragmented index causes slow scans"
      trigger: "Many random updates and deletes"
      difficulty: "medium"
    
    - trap_id: "MT-002"
      name: "Stale Statistics"
      description: "Out-of-date statistics cause bad plans"
      trigger: "Large data changes without ANALYZE"
      difficulty: "medium"
    
    - trap_id: "MT-003"
      name: "Index Bloat"
      description: "Dead space in index"
      trigger: "Many updates in PostgreSQL MVCC"
      difficulty: "hard"
      databases: ["PostgreSQL"]

# =============================================================================
# EDGE CASES - 100+ Edge Cases
# =============================================================================

edge_cases:
  # ---------------------------------------------------------------------------
  # Data Type Edge Cases
  # ---------------------------------------------------------------------------
  data_types:
    - case_id: "DT-001"
      name: "VARCHAR vs TEXT Index"
      description: "TEXT columns may have index limitations"
      impact: "Some databases limit TEXT index length"
    
    - case_id: "DT-002"
      name: "DECIMAL Precision in Index"
      description: "Precision affects index key size"
      impact: "Larger keys = deeper tree"
    
    - case_id: "DT-003"
      name: "UUID Index Efficiency"
      description: "Random UUIDs cause index fragmentation"
      impact: "Page splits, random I/O"
      mitigation: "Use UUIDv7 (time-ordered) or ULID"
    
    - case_id: "DT-004"
      name: "JSON/JSONB Indexing"
      description: "JSON field indexing varies by database"
      approaches:
        postgresql: "GIN on JSONB, expression index"
        mysql: "Generated column + index"

  # ---------------------------------------------------------------------------
  # Query Pattern Edge Cases
  # ---------------------------------------------------------------------------
  query_patterns:
    - case_id: "QP-001"
      name: "OR Conditions"
      description: "OR may prevent single index use"
      solution: "UNION or index merge"
    
    - case_id: "QP-002"
      name: "IN with Many Values"
      description: "Large IN list may not use index well"
      threshold: "Database-specific, often 100-1000"
    
    - case_id: "QP-003"
      name: "NOT IN / NOT EXISTS"
      description: "Negation conditions hard to index"
      approach: "Anti-join patterns"
    
    - case_id: "QP-004"
      name: "DISTINCT Optimization"
      description: "DISTINCT may or may not use index"
      varies_by: "Database and query structure"

  # ---------------------------------------------------------------------------
  # Concurrency Edge Cases
  # ---------------------------------------------------------------------------
  concurrency:
    - case_id: "CC-001"
      name: "Index Lock Contention"
      description: "Concurrent inserts lock index pages"
      impact: "Write throughput limited"
    
    - case_id: "CC-002"
      name: "Online Index Build Conflict"
      description: "Concurrent DML during index creation"
      handling: "Database-specific mechanisms"
    
    - case_id: "CC-003"
      name: "Statistics Update During Query"
      description: "Statistics change mid-execution"
      impact: "Usually none, but edge cases exist"

  # ---------------------------------------------------------------------------
  # Large Table Edge Cases
  # ---------------------------------------------------------------------------
  large_tables:
    - case_id: "LT-001"
      name: "Index Build Time"
      description: "Creating index on billion-row table"
      consideration: "May take hours, blocks writes"
    
    - case_id: "LT-002"
      name: "Index Size vs Table Size"
      description: "Wide index may be larger than table"
      impact: "More I/O for index scan than table scan"
    
    - case_id: "LT-003"
      name: "Memory for Index Operations"
      description: "Sort space for index creation"
      parameter: "maintenance_work_mem (PostgreSQL)"

# =============================================================================
# DIFFICULTY MULTIPLIERS
# =============================================================================

difficulty_multipliers:
  difficulty_amplifiers:
    nightmare:
      multiplier: 3.0
      description: "Extreme difficulty requiring expert DBA knowledge across multiple systems"
      requirements:
        - "7+ interacting traps across storage engine, query optimizer, and lock manager"
        - "Requires understanding of database internals and source code behavior"
        - "Time estimate: 90+ minutes for senior database engineers"
        - "Cross-database compatibility issues that manifest differently"
        - "Requires synthesizing SQL, transactions, and distributed systems knowledge"
    
    nightmare_plus:
      multiplier: 5.0
      estimated_time: [28800, 172800]  # 8-48 hours
      command_steps: [400, 1500]
      techniques_required: 12
      description: "Database kernel development difficulty requiring index implementation and optimizer internals expertise"
      requirements:
        - "12+ deeply interacting traps across index structure, optimizer, storage, and I/O layers"
        - "Requires understanding of B-tree/LSM-tree implementation source code and optimization algorithms"
        - "Time estimate: 8-48 hours for principal database architects"
        - "Cross-database index behavior requiring deep internals knowledge"
        - "Requires synthesizing index structures, cost models, buffer management, and I/O patterns"
        - "Must optimize indexes for billion-row tables with complex access patterns"
        - "Requires understanding of parallel index scans, bitmap operations, and index-only execution"
        - "Must balance read performance, write overhead, and storage efficiency"
  
  storage_engine_internals:
    btree_implementation_details:
      description: "B-tree/B+tree internal mechanics affecting index performance"
      factors:
        - "Page split algorithm and fill factor impact"
        - "Key prefix compression and suffix truncation"
        - "Leaf page linking for range scans"
        - "Non-leaf page fanout and tree height"
      multiplier: 2.0
    
    lsm_tree_indexing:
      description: "LSM-tree index structure and performance"
      factors:
        - "Memtable index organization"
        - "SSTable index block structure"
        - "Bloom filter effectiveness"
        - "Compaction impact on index performance"
      multiplier: 1.9
    
    wal_and_index_updates:
      description: "Write-ahead logging for index modifications"
      factors:
        - "Index page WAL record types"
        - "Index recovery after crash"
        - "Concurrent index updates and WAL"
        - "Index WAL volume optimization"
      multiplier: 1.6
    
    buffer_pool_index_caching:
      description: "Buffer pool behavior for index pages"
      factors:
        - "Index page caching priority"
        - "Index working set size"
        - "Random vs sequential index I/O"
        - "Index prefetching algorithms"
      multiplier: 1.7
    
    lock_manager_index_locking:
      description: "Lock acquisition during index operations"
      factors:
        - "Index page locking during traversal"
        - "Key-value locking granularity"
        - "Index maintenance lock escalation"
        - "Concurrent index builds"
      multiplier: 1.8
    
    mvcc_index_interaction:
      description: "MVCC version handling in indexes"
      factors:
        - "Index entries for multiple versions"
        - "Index-only scan visibility requirements"
        - "Index vacuum and version cleanup"
        - "HOT updates and index avoidance"
      multiplier: 1.9
  
  distributed_database_complexity:
    distributed_index_management:
      global_secondary_indexes:
        - "GSI consistency with base table"
        - "GSI write amplification"
        - "GSI partition strategies"
        - "Cross-shard index maintenance"
      local_vs_global_indexes:
        - "Local index query routing"
        - "Global index update overhead"
        - "Index-based query optimization"
        - "Partition pruning with indexes"
      multiplier: 2.2
    
    replicated_index_consistency:
      index_replication:
        - "Index build on replicas"
        - "Index lag behind data"
        - "Stale index on secondaries"
        - "Index divergence scenarios"
      multiplier: 1.8
    
    index_in_sharded_environment:
      shard_key_indexes:
        - "Shard key index requirements"
        - "Non-shard-key index scatter-gather"
        - "Index-based shard routing"
        - "Cross-shard unique indexes"
      multiplier: 2.1
    
    cloud_index_optimization:
      managed_database_indexes:
        - "Auto-indexing recommendations"
        - "Index storage tier optimization"
        - "Serverless index scaling"
        - "Cost-based index decisions"
      multiplier: 1.7
  
  scale_factors:
    - factor: "billion_row_table"
      multiplier: 1.8
      description: "Table has 1B+ rows"
    
    - factor: "high_write_rate"
      multiplier: 1.5
      description: "Thousands of writes per second"
    
    - factor: "many_indexes"
      multiplier: 1.4
      description: "Table has 20+ indexes"
  
  query_complexity:
    - factor: "complex_joins"
      multiplier: 1.6
      description: "5+ table joins"
    
    - factor: "subqueries"
      multiplier: 1.4
      description: "Correlated subqueries"
    
    - factor: "aggregations"
      multiplier: 1.3
      description: "Complex GROUP BY"
  
  constraints:
    - factor: "zero_downtime"
      multiplier: 1.7
      description: "Cannot take downtime for index changes"
    
    - factor: "limited_storage"
      multiplier: 1.3
      description: "Strict storage constraints"

# =============================================================================
# DATABASE SYSTEM SPECIFICS
# =============================================================================

database_specifics:
  postgresql:
    versions: ["12", "13", "14", "15", "16"]
    index_features:
      - "Expression indexes"
      - "Partial indexes"
      - "INCLUDE columns"
      - "BRIN indexes"
      - "GIN, GiST indexes"
      - "CREATE INDEX CONCURRENTLY"
    monitoring:
      - "pg_stat_user_indexes"
      - "pg_stat_all_indexes"
      - "pg_index"
    
  mysql:
    versions: ["5.7", "8.0", "8.1"]
    index_features:
      - "Clustered index (InnoDB)"
      - "Invisible indexes"
      - "Descending indexes (8.0+)"
      - "Functional indexes (8.0.13+)"
    monitoring:
      - "SHOW INDEX FROM table"
      - "performance_schema"
      - "sys.schema_unused_indexes"
    
  sql_server:
    versions: ["2016", "2017", "2019", "2022"]
    index_features:
      - "Clustered and nonclustered"
      - "Filtered indexes"
      - "Columnstore indexes"
      - "Online index operations"
    monitoring:
      - "sys.dm_db_index_usage_stats"
      - "sys.dm_db_index_physical_stats"
      - "Missing index DMVs"
    
  oracle:
    versions: ["19c", "21c", "23c"]
    index_features:
      - "Bitmap indexes"
      - "Function-based indexes"
      - "Invisible indexes"
      - "Partitioned indexes"
    monitoring:
      - "DBA_INDEXES"
      - "V$OBJECT_USAGE"
      - "INDEX_STATS"

# =============================================================================
# PROBLEM STATEMENT TEMPLATES
# =============================================================================

problem_statement: |
  A {{ application_type }} database has query performance issues.
  The system uses {{ database_system }} {{ database_version }}.
  
  Performance symptoms:
  {{ performance_symptoms }}
  
  Current index configuration:
  - Tables: {{ table_count }}
  - Total indexes: {{ index_count }}
  - Largest table: {{ largest_table_rows }} rows
  
  Query patterns:
  {{ query_patterns }}
  
  Constraints:
  {{ constraints }}

requirements: |
  - Improve query performance by {{ performance_goal }}
  - Analyze and optimize index strategy
  - Handle {{ edge_cases }} edge cases
  - Balance read vs write performance
  - Provide {{ deliverables }}

interface: |
  Input: {{ input_description }}
  Output: {{ output_description }}
  Validation: {{ validation_criteria }}

# =============================================================================
# REFERENCE SOLUTION PATTERNS
# =============================================================================

reference_solution: |
  -- Database Index Optimization Patterns
  
  -- ============================================================
  -- PATTERN 1: Expression Index for Function Queries
  -- ============================================================
  
  /*
  PROBLEM: Function on column prevents index use
  
  SELECT * FROM users WHERE UPPER(email) = 'TEST@EXAMPLE.COM';
  -- Full table scan even with index on email
  */
  
  -- SOLUTION 1: Expression index (PostgreSQL)
  CREATE INDEX idx_users_email_upper ON users (UPPER(email));
  
  -- SOLUTION 2: Generated column (MySQL 8.0+)
  ALTER TABLE users ADD COLUMN email_lower VARCHAR(255) 
    GENERATED ALWAYS AS (LOWER(email)) STORED;
  CREATE INDEX idx_users_email_lower ON users (email_lower);
  
  -- SOLUTION 3: Normalize data (store lowercase)
  -- Application ensures email stored lowercase
  -- Query: WHERE email = LOWER('Test@Example.com')
  
  -- ============================================================
  -- PATTERN 2: Optimal Composite Index Order
  -- ============================================================
  
  /*
  Query: SELECT * FROM orders 
         WHERE customer_id = 123 
         AND status = 'pending'
         AND created_at > '2024-01-01'
         ORDER BY created_at DESC;
  
  Principles:
  1. Equality columns first
  2. Range column last
  3. Include ORDER BY column
  */
  
  -- Optimal index for this query:
  CREATE INDEX idx_orders_cust_status_created 
  ON orders (customer_id, status, created_at DESC);
  
  -- Explanation:
  -- - customer_id: equality, high cardinality, goes first
  -- - status: equality, goes second
  -- - created_at DESC: range + ORDER BY, goes last with sort direction
  
  -- ============================================================
  -- PATTERN 3: Covering Index
  -- ============================================================
  
  /*
  Query: SELECT order_id, status, amount 
         FROM orders 
         WHERE customer_id = 123;
  
  Without covering: Index scan + table fetch
  With covering: Index-only scan (much faster)
  */
  
  -- PostgreSQL with INCLUDE
  CREATE INDEX idx_orders_covering ON orders (customer_id)
  INCLUDE (order_id, status, amount);
  
  -- MySQL (include in key)
  CREATE INDEX idx_orders_covering 
  ON orders (customer_id, order_id, status, amount);
  
  -- SQL Server
  CREATE INDEX idx_orders_covering ON orders (customer_id)
  INCLUDE (order_id, status, amount);
  
  -- ============================================================
  -- PATTERN 4: Partial Index
  -- ============================================================
  
  /*
  Query: SELECT * FROM orders WHERE status = 'pending';
  
  If only 5% of orders are pending, full index is wasteful.
  */
  
  -- PostgreSQL
  CREATE INDEX idx_orders_pending ON orders (id, created_at)
  WHERE status = 'pending';
  
  -- SQL Server
  CREATE INDEX idx_orders_pending ON orders (id, created_at)
  WHERE status = 'pending';
  
  -- Note: Query must match filter exactly to use partial index
  
  -- ============================================================
  -- PATTERN 5: Handling NULL in Index
  -- ============================================================
  
  /*
  Oracle doesn't index NULL values in B-tree.
  Query: SELECT * FROM products WHERE category IS NULL;
  */
  
  -- Oracle workaround: Include constant in index
  CREATE INDEX idx_products_category ON products (category, 0);
  -- The constant ensures NULLs are indexed
  
  -- PostgreSQL: NULLs indexed, partial index for efficiency
  CREATE INDEX idx_products_null_category ON products (id)
  WHERE category IS NULL;
  
  -- ============================================================
  -- PATTERN 6: Index for OR Conditions
  -- ============================================================
  
  /*
  Query: SELECT * FROM users 
         WHERE email = 'test@example.com' 
         OR username = 'testuser';
  
  Single index won't help both conditions efficiently.
  */
  
  -- Solution 1: Two separate indexes, rely on index merge
  CREATE INDEX idx_users_email ON users (email);
  CREATE INDEX idx_users_username ON users (username);
  -- Optimizer may use BitmapOr / Index Merge
  
  -- Solution 2: UNION for guaranteed optimization
  SELECT * FROM users WHERE email = 'test@example.com'
  UNION
  SELECT * FROM users WHERE username = 'testuser';
  
  -- ============================================================
  -- PATTERN 7: LIKE Query Optimization
  -- ============================================================
  
  /*
  LIKE 'abc%' - Can use B-tree index
  LIKE '%abc%' - Cannot use B-tree index
  LIKE '%abc' - Cannot use B-tree index
  */
  
  -- For prefix search: normal B-tree works
  CREATE INDEX idx_products_name ON products (name);
  SELECT * FROM products WHERE name LIKE 'Apple%';
  
  -- For suffix search: reverse index
  CREATE INDEX idx_products_name_rev ON products (REVERSE(name));
  SELECT * FROM products WHERE REVERSE(name) LIKE REVERSE('%Phone');
  
  -- For contains search: full-text
  -- PostgreSQL
  CREATE INDEX idx_products_fts ON products USING gin(to_tsvector('english', name));
  SELECT * FROM products WHERE to_tsvector('english', name) @@ to_tsquery('apple');
  
  -- MySQL
  ALTER TABLE products ADD FULLTEXT INDEX idx_products_fts (name);
  SELECT * FROM products WHERE MATCH(name) AGAINST('apple');
  
  -- ============================================================
  -- PATTERN 8: Find and Remove Unused Indexes
  -- ============================================================
  
  -- PostgreSQL
  SELECT 
      schemaname, tablename, indexname,
      idx_scan as times_used,
      pg_size_pretty(pg_relation_size(indexrelid)) as index_size
  FROM pg_stat_user_indexes
  WHERE idx_scan = 0
  ORDER BY pg_relation_size(indexrelid) DESC;
  
  -- MySQL
  SELECT 
      object_schema, object_name, index_name
  FROM performance_schema.table_io_waits_summary_by_index_usage
  WHERE index_name IS NOT NULL
  AND count_star = 0
  ORDER BY object_schema, object_name;
  
  -- SQL Server
  SELECT 
      OBJECT_NAME(i.object_id) as table_name,
      i.name as index_name,
      s.user_seeks, s.user_scans, s.user_lookups, s.user_updates
  FROM sys.indexes i
  LEFT JOIN sys.dm_db_index_usage_stats s 
      ON i.object_id = s.object_id AND i.index_id = s.index_id
  WHERE OBJECTPROPERTY(i.object_id, 'IsUserTable') = 1
  AND (s.user_seeks + s.user_scans + s.user_lookups) = 0
  AND s.user_updates > 0;
  
  -- ============================================================
  -- PATTERN 9: Analyze Query Plan
  -- ============================================================
  
  -- PostgreSQL
  EXPLAIN (ANALYZE, BUFFERS, FORMAT TEXT)
  SELECT * FROM orders WHERE customer_id = 123;
  
  /*
  Look for:
  - Seq Scan = not using index (usually bad)
  - Index Scan = using index
  - Index Only Scan = covering index (best)
  - Bitmap Index Scan = using index for bitmap
  
  Check:
  - actual rows vs estimated rows
  - Buffers shared hit/read ratio
  */
  
  -- MySQL
  EXPLAIN FORMAT=JSON SELECT * FROM orders WHERE customer_id = 123;
  
  -- SQL Server
  SET STATISTICS IO ON;
  SELECT * FROM orders WHERE customer_id = 123;

# =============================================================================
# TEST CASES
# =============================================================================

fail_to_pass:
  - "test_expression_index_used"
  - "test_covering_index_works"
  - "test_composite_index_order_optimal"
  - "test_no_unused_indexes"
  - "test_function_queries_indexed"

pass_to_pass:
  - "test_basic_index_works"
  - "test_primary_key_lookup"

# =============================================================================
# VARIABLES FOR TASK GENERATION
# =============================================================================

variables:
  - name: application_type
    type: string
    options:
      - "e-commerce platform"
      - "analytics dashboard"
      - "content management"
      - "financial application"
      - "social network"
  
  - name: database_system
    type: string
    options: ["PostgreSQL", "MySQL", "SQL Server", "Oracle"]
  
  - name: table_count
    type: int
    min: 10
    max: 500
  
  - name: index_count
    type: int
    min: 20
    max: 1000
  
  - name: largest_table_rows
    type: string
    options: ["1 million", "10 million", "100 million", "1 billion"]

# =============================================================================
# ANTI-PATTERNS - LLM Failure Modes
# =============================================================================

anti_patterns:
  llm_failure_modes:
    - "Applying generic SQL patterns without considering database-specific behavior"
    - "Missing isolation level interactions between concurrent transactions"
    - "Ignoring lock manager implementation details"
    - "Not considering query optimizer behavior changes across versions"
    - "Missing hidden full table scans in seemingly optimized queries"
    - "Overlooking index maintenance overhead during writes"
    - "Assuming ORM generates efficient queries"
    - "Missing deadlock potential in cross-schema operations"
    - "Ignoring transaction log and recovery implications"
    - "Assuming high-cardinality column first is always optimal for composite indexes"
    - "Missing function-on-column preventing index usage"
    - "Ignoring implicit type conversion making index unusable"
    - "Assuming covering index always improves performance"
    - "Overlooking index bloat from MVCC in PostgreSQL"
    - "Missing visibility map requirements for index-only scans"
    - "Assuming LIKE 'prefix%' always uses index (collation matters)"
    - "Ignoring NULL handling differences across databases"
    - "Missing partial/filtered index predicate matching requirements"
    - "Assuming CREATE INDEX CONCURRENTLY never fails"
    - "Overlooking index usage statistics reset after database restart"
    - "Missing the impact of table clustering on index efficiency"
    - "Assuming index hints work the same across databases"
    - "Ignoring index fragmentation impact on scan performance"
    - "Missing OR condition impact on index selection"
    - "Assuming BRIN indexes work for all access patterns"
    - "Overlooking GIN pending list impact on query performance"
    - "Missing hash index limitations (no range queries, crash safety)"
  
  query_optimizer_internals:
    index_selection_complexity:
      - "Index intersection vs single index decision"
      - "Skip scan eligibility conditions"
      - "Loose index scan for GROUP BY"
      - "Index-only scan vs index scan cost comparison"
    statistics_dependency:
      - "Histogram bucket granularity impact"
      - "Multi-column statistics for correlation"
      - "NULL fraction in selectivity estimation"
      - "Most common values vs histogram interaction"
    cost_model_limitations:
      - "Sequential vs random I/O cost ratio assumptions"
      - "CPU cost for in-memory operations"
      - "Index maintenance cost in write queries"
      - "Parallel index scan cost estimation"

# =============================================================================
# ANTI-HARDCODING MEASURES
# =============================================================================

anti_hardcoding:
  canary_tokens: true
  randomize_paths: true
  dynamic_content: true
  randomize_identifiers: true
  
  index_issues:
    - "function_prevents_index"
    - "wrong_column_order"
    - "low_selectivity"
    - "missing_covering_column"
    - "unused_index"
    - "fragmented_index"
