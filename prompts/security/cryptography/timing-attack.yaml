id: "sec-crypto-timing-attack-001"
version: "2.0.0"
category: "security"
subcategory: "cryptography"

# === LLM GENERATION FRAMEWORK ===
generation_framework:
  multi_conversation_workflow:
    phase_1_research: "Research obscure timing side-channel vulnerability classes and measurement techniques"
    phase_2_creation: "Create multi-layered timing attack challenge with hidden side-channel vectors"
    phase_3_amplification: "Add defense bypass requirements and timing exploitation chains"
    phase_4_verification:
      base_validation: "Validate task requires advanced timing analysis and cryptographic expertise"
      enhanced_criteria:
        - "Has at least 5 interacting vulnerability chains"
        - "Has cascading exploitation paths that require chained attacks"
        - "Requires knowledge of compiler/interpreter internals for exploitation"
        - "Would take experienced security researchers 45+ minutes"
  
  complexity_targets:
    min_steps: 15
    max_steps: 50
    required_expertise:
      - "Side-channel analysis"
      - "Statistical timing measurement"
      - "Cryptographic implementation"
      - "Low-level systems programming"
      - "Cache architecture understanding"
    
  anti_shortcut_measures:
    - "Require statistical analysis of timing distributions"
    - "Demand constant-time implementation proofs"
    - "Test against microarchitectural timing leaks"
    - "Verify defense against adaptive attackers"

# SWE-bench_Pro style fields
problem_statement: |
  An authentication system is vulnerable to timing attacks. The password/token 
  comparison function leaks information through execution time differences.
  
  Timing leak sources:
  1. String comparison that exits early on mismatch
  2. Hash comparison using == operator
  3. HMAC verification with variable-time comparison
  4. Database lookup time reveals username existence
  5. Error handling paths have different timing
  6. Cache-based timing variations
  7. Branch prediction side channels
  8. Memory access pattern timing
  9. Cryptographic operation timing variance
  10. Network response time differences

requirements: |
  - Identify all timing side channels (explicit and implicit)
  - Implement constant-time comparison functions
  - Eliminate early-exit comparisons
  - Normalize execution paths across all branches
  - Add timing-safe cryptographic operations
  - Mitigate cache-based timing attacks
  - Handle microarchitectural side channels
  - Implement statistical timing analysis detection
  - Add response time normalization
  - Verify constant-time properties through testing

interface: |
  Input: Authentication code with timing vulnerabilities
  Output: Timing-safe implementation with verification tests
  Validation: Timing analysis shows constant execution time across all inputs

# === TOPIC UNIVERSE (100+ topics) ===
topic_universe:
  timing_attack_fundamentals:
    - "Basic string comparison timing leaks"
    - "Password verification timing attacks"
    - "HMAC-SHA256 timing side channels"
    - "Token validation timing vulnerabilities"
    - "Session ID comparison timing"
    - "API key verification timing"
    - "Certificate chain validation timing"
    - "Signature verification timing"
    - "Public key operation timing"
    - "Symmetric encryption timing"
    
  microarchitectural_timing:
    - "CPU cache timing attacks"
    - "L1 cache side channels"
    - "L2/L3 cache timing leaks"
    - "Cache line granularity attacks"
    - "Flush+Reload timing attacks"
    - "Prime+Probe cache attacks"
    - "Evict+Time cache timing"
    - "Cache bank conflict timing"
    - "TLB timing side channels"
    - "Memory hierarchy timing"
    - "DRAM row buffer timing"
    - "Memory controller timing"
    - "Prefetcher-based timing"
    - "Store buffer timing attacks"
    - "Load buffer timing leaks"
    
  branch_prediction_timing:
    - "Branch predictor side channels"
    - "BTB (Branch Target Buffer) attacks"
    - "PHT (Pattern History Table) timing"
    - "RSB (Return Stack Buffer) attacks"
    - "Spectre variant 1 timing"
    - "Spectre variant 2 timing"
    - "Branch misprediction timing"
    - "Indirect branch timing"
    - "Conditional branch timing"
    - "Loop branch timing"
    
  cryptographic_timing:
    - "RSA timing attacks (Kocher)"
    - "RSA blinding techniques"
    - "ECDSA timing vulnerabilities"
    - "ECDH key exchange timing"
    - "AES cache timing attacks"
    - "AES T-table timing"
    - "DES timing analysis"
    - "ChaCha20 timing safety"
    - "Poly1305 timing properties"
    - "GHASH timing in GCM"
    - "BCrypt timing considerations"
    - "Argon2 timing resistance"
    - "PBKDF2 iteration timing"
    - "Scrypt memory timing"
    - "Key derivation timing"
    
  network_timing:
    - "Remote timing attacks"
    - "Network jitter compensation"
    - "RTT-based timing analysis"
    - "TLS handshake timing"
    - "Certificate validation timing"
    - "OCSP response timing"
    - "DNS lookup timing"
    - "TCP handshake timing"
    - "HTTP response timing"
    - "WebSocket timing"
    - "gRPC timing analysis"
    - "REST API timing"
    - "GraphQL query timing"
    - "Database query timing"
    - "Cache hit/miss timing"
    
  statistical_analysis:
    - "Timing distribution analysis"
    - "Statistical hypothesis testing"
    - "Welch's t-test for timing"
    - "Mann-Whitney U test"
    - "Kolmogorov-Smirnov test"
    - "Timing variance analysis"
    - "Outlier detection in timing"
    - "Multi-modal timing detection"
    - "Timing correlation analysis"
    - "Cross-correlation timing"
    - "Autocorrelation analysis"
    - "Spectral analysis of timing"
    - "Machine learning timing classification"
    - "Deep learning timing attacks"
    - "Online timing analysis"
    
  platform_specific_timing:
    - "Intel CPU timing specifics"
    - "AMD CPU timing differences"
    - "ARM timing characteristics"
    - "Apple Silicon timing"
    - "RISC-V timing properties"
    - "VM timing side channels"
    - "Container timing isolation"
    - "SGX enclave timing"
    - "TrustZone timing"
    - "AWS Nitro timing"
    - "Azure confidential timing"
    - "GCP timing isolation"
    
  language_runtime_timing:
    - "Python interpreter timing"
    - "JavaScript engine timing"
    - "JVM timing characteristics"
    - ".NET CLR timing"
    - "Go runtime timing"
    - "Rust timing guarantees"
    - "C/C++ compiler timing"
    - "WASM timing properties"
    - "PHP timing issues"
    - "Ruby timing concerns"

# === ATTACK CHAINS (50+ chains) ===
attack_chains:
  remote_timing_exploitation:
    - name: "Remote Password Oracle"
      steps:
        - "Measure baseline network latency"
        - "Send authentication requests with varying passwords"
        - "Collect timing samples (1000+ per character)"
        - "Apply statistical analysis to identify timing differences"
        - "Recover password character by character"
        - "Bypass rate limiting with distributed requests"
      difficulty: "hard"
      cve_references: ["CVE-2003-0078", "CVE-2013-0169"]
      
    - name: "HMAC Timing Oracle"
      steps:
        - "Identify HMAC verification endpoint"
        - "Measure timing for known-invalid signatures"
        - "Vary signature bytes and measure timing changes"
        - "Use statistical methods to detect byte matches"
        - "Reconstruct valid HMAC byte by byte"
        - "Forge authenticated requests"
      difficulty: "expert"
      cve_references: ["CVE-2014-0076"]
      
    - name: "Session Token Enumeration"
      steps:
        - "Identify session validation timing differences"
        - "Generate candidate session tokens"
        - "Measure validation time for each candidate"
        - "Identify valid session prefixes"
        - "Narrow down to valid session"
        - "Hijack authenticated session"
      difficulty: "hard"
      
    - name: "Username Enumeration via Timing"
      steps:
        - "Measure login timing for known-invalid users"
        - "Measure timing for potentially valid usernames"
        - "Identify timing difference (database lookup)"
        - "Enumerate valid usernames"
        - "Target valid accounts for password attacks"
      difficulty: "medium"
      cve_references: ["CVE-2016-6210"]
      
    - name: "API Key Partial Validation"
      steps:
        - "Submit API requests with varying key prefixes"
        - "Measure response times"
        - "Identify prefix validation timing leak"
        - "Enumerate valid key prefixes"
        - "Reduce brute-force keyspace significantly"
      difficulty: "medium"
      
  cache_timing_attacks:
    - name: "Flush+Reload AES Key Recovery"
      steps:
        - "Map shared library into attacker process"
        - "Flush AES T-tables from cache"
        - "Trigger victim AES encryption"
        - "Reload T-table entries and measure time"
        - "Correlate cache hits with key bytes"
        - "Recover full AES key"
      difficulty: "expert"
      cve_references: ["CVE-2014-0160"]
      
    - name: "Prime+Probe RSA Attack"
      steps:
        - "Prime cache sets used by RSA"
        - "Wait for victim RSA operation"
        - "Probe cache sets to detect eviction"
        - "Correlate evictions with RSA operations"
        - "Recover private key bits"
      difficulty: "expert"
      
    - name: "Cache Timing ECDSA Nonce"
      steps:
        - "Monitor cache during ECDSA signing"
        - "Detect branches in scalar multiplication"
        - "Recover partial nonce information"
        - "Apply lattice attack with partial nonces"
        - "Recover ECDSA private key"
      difficulty: "expert"
      cve_references: ["CVE-2018-0495", "CVE-2019-15809"]
      
  speculative_execution_timing:
    - name: "Spectre v1 Bounds Check Bypass"
      steps:
        - "Identify bounds check before array access"
        - "Train branch predictor with in-bounds access"
        - "Supply out-of-bounds index"
        - "Speculatively access secret data"
        - "Leak data through cache timing"
      difficulty: "expert"
      cve_references: ["CVE-2017-5753"]
      
    - name: "Spectre v2 Branch Injection"
      steps:
        - "Identify indirect branch in victim"
        - "Poison BTB with malicious target"
        - "Trigger victim indirect branch"
        - "Speculatively execute at malicious target"
        - "Leak secrets through cache side channel"
      difficulty: "expert"
      cve_references: ["CVE-2017-5715"]
      
  database_timing:
    - name: "SQL Query Timing Attack"
      steps:
        - "Identify SQL injection point"
        - "Craft timing-based payload (SLEEP/BENCHMARK)"
        - "Measure response times"
        - "Extract data bit by bit via timing"
        - "Bypass WAF with timing obfuscation"
      difficulty: "medium"
      
    - name: "NoSQL Timing Injection"
      steps:
        - "Identify MongoDB query injection"
        - "Use $where clause with timing"
        - "Extract document data via timing"
        - "Enumerate collections and documents"
      difficulty: "medium"
      
  composite_attacks:
    - name: "Cross-VM Timing Attack"
      steps:
        - "Detect co-residency with target VM"
        - "Establish covert timing channel"
        - "Prime shared cache/memory"
        - "Monitor target crypto operations"
        - "Extract key material across VM boundary"
      difficulty: "expert"
      cve_references: ["CVE-2018-3615", "CVE-2018-3620"]
      
    - name: "Browser-Based Timing Attack"
      steps:
        - "Load malicious JavaScript on page"
        - "Use SharedArrayBuffer for precise timing"
        - "Perform cache timing measurements"
        - "Leak cross-origin data"
        - "Bypass same-origin policy via timing"
      difficulty: "hard"
      cve_references: ["CVE-2017-5754"]
      
    - name: "TLS Record Timing (Lucky 13)"
      steps:
        - "Identify CBC mode TLS connection"
        - "Send modified ciphertext records"
        - "Measure timing of MAC verification"
        - "Distinguish padding from MAC errors"
        - "Decrypt TLS traffic"
      difficulty: "expert"
      cve_references: ["CVE-2013-0169"]

# === DEFENSE BYPASS TECHNIQUES (100+) ===
defense_bypass_techniques:
  constant_time_bypass:
    - "Exploiting compiler optimization removing constant-time code"
    - "GCC/Clang dead code elimination attacks"
    - "Link-time optimization timing leaks"
    - "JIT compiler timing optimizations"
    - "Speculative execution bypassing constant-time"
    - "Memory access pattern leaks despite constant-time"
    - "Cache timing despite constant-time operations"
    - "Branch prediction leaks in constant-time code"
    - "Power analysis alongside timing"
    - "Electromagnetic emanation timing correlation"
    
  rate_limiting_bypass:
    - "Distributed timing measurement"
    - "Low-and-slow timing attacks"
    - "Timing coalescing across rate limits"
    - "IP rotation for measurement"
    - "Account rotation timing"
    - "API key rotation measurement"
    - "Captcha bypass timing"
    - "Bot detection evasion timing"
    - "Cloud function timing aggregation"
    - "CDN cache timing bypass"
    
  noise_filtering:
    - "Statistical noise removal"
    - "Kalman filter timing"
    - "Moving average timing"
    - "Median filtering"
    - "Percentile-based filtering"
    - "Machine learning denoising"
    - "Wavelet denoising"
    - "FFT-based filtering"
    - "Adaptive filtering"
    - "Cross-correlation filtering"
    
  jitter_bypass:
    - "High sample count overcome jitter"
    - "Timing amplification techniques"
    - "Request pipelining timing"
    - "Batch request timing"
    - "Time-locked timing measurement"
    - "GPS-synchronized timing"
    - "PTP (Precision Time Protocol) timing"
    - "RDTSC-based local timing"
    - "Performance counter timing"
    - "Hardware timestamp timing"
    
  virtualization_bypass:
    - "VM timing side channels"
    - "Hypervisor timing artifacts"
    - "Container timing leaks"
    - "Kubernetes pod timing"
    - "Docker networking timing"
    - "VMX timing transparency"
    - "Paravirtual timer attacks"
    - "TSC virtualization attacks"
    - "APIC timer timing"
    - "Real-time clock timing"
    
  software_countermeasure_bypass:
    - "Random delay insertion bypass"
    - "Fixed delay bypass via statistics"
    - "Response normalization attacks"
    - "Error path timing differentiation"
    - "Exception handling timing"
    - "Logging overhead timing"
    - "Audit trail timing"
    - "Memory allocation timing"
    - "Garbage collection timing"
    - "Thread scheduling timing"

# === REAL-WORLD SCENARIOS ===
real_world_scenarios:
  authentication_systems:
    - scenario: "OAuth2 Token Validation"
      description: "Token introspection endpoint leaks timing"
      complexity: "high"
      attack_vector: "Remote timing measurement of token validity"
      
    - scenario: "JWT Signature Verification"
      description: "HMAC comparison vulnerable to timing attack"
      complexity: "high"
      attack_vector: "Forge valid JWT signatures via timing oracle"
      
    - scenario: "API Gateway Authentication"
      description: "API key validation has timing leak"
      complexity: "medium"
      attack_vector: "Enumerate valid API keys"
      
    - scenario: "Multi-Factor Authentication"
      description: "TOTP validation timing reveals code validity"
      complexity: "medium"
      attack_vector: "Accelerate TOTP brute-force"
      
    - scenario: "Password Reset Token"
      description: "Reset token comparison is not constant-time"
      complexity: "medium"
      attack_vector: "Forge password reset tokens"
      
    - scenario: "Biometric Template Matching"
      description: "Template matching time varies with similarity"
      complexity: "high"
      attack_vector: "Reconstruct biometric templates"
      
  cryptographic_services:
    - scenario: "HSM Key Operations"
      description: "HSM response time varies with key usage"
      complexity: "expert"
      attack_vector: "Extract HSM key material via timing"
      
    - scenario: "TLS Certificate Validation"
      description: "Certificate chain validation timing varies"
      complexity: "high"
      attack_vector: "Bypass certificate pinning via timing"
      
    - scenario: "Key Derivation Service"
      description: "KDF iteration count detectable via timing"
      complexity: "medium"
      attack_vector: "Determine password strength parameters"
      
    - scenario: "Encryption Oracle"
      description: "Encryption time varies with plaintext"
      complexity: "high"
      attack_vector: "Recover plaintext via timing"
      
  database_systems:
    - scenario: "User Lookup Service"
      description: "Database query time reveals user existence"
      complexity: "low"
      attack_vector: "Username enumeration"
      
    - scenario: "Search Functionality"
      description: "Search timing reveals result count"
      complexity: "medium"
      attack_vector: "Information disclosure via search timing"
      
    - scenario: "Access Control Checks"
      description: "Permission check timing varies"
      complexity: "medium"
      attack_vector: "Enumerate accessible resources"
      
  financial_systems:
    - scenario: "Transaction Processing"
      description: "Transaction validation timing varies"
      complexity: "high"
      attack_vector: "Predict transaction approval"
      
    - scenario: "Fraud Detection"
      description: "Fraud check timing reveals decision"
      complexity: "high"
      attack_vector: "Bypass fraud detection via timing"
      
    - scenario: "Account Balance Check"
      description: "Balance check timing varies with amount"
      complexity: "medium"
      attack_vector: "Determine account balances"

# === DIFFICULTY CONFIGURATION ===
difficulty:
  estimated: "extreme"
  time_range: [7200, 32400]
  command_steps: [150, 700]
  
  difficulty_amplifiers:
    nightmare:
      multiplier: 4.0
      description: "CTF-final level difficulty requiring expert exploitation skills"
      requirements:
        - "7+ interacting vulnerabilities requiring chained exploitation"
        - "Requires understanding of target runtime/compiler internals"
        - "Time estimate: 180+ minutes for senior security researchers"
        - "Multiple protection bypass techniques required"
        - "Requires synthesizing reverse engineering, exploitation, and cryptography"
    
    nightmare_plus:
      multiplier: 8.0
      estimated_time: [43200, 172800]
      command_steps: [500, 2000]
      techniques_required: 20
      description: "Real-world 0-day exploitation requiring novel timing side-channel discovery and exploitation"
      requirements:
        - "15+ deeply interacting vulnerabilities across timing, cache, and speculative execution layers"
        - "Requires sub-microsecond timing measurement with statistical significance"
        - "Time estimate: 12-48 hours for senior security researchers with OSCP/OSWE/OSCE certifications"
        - "Custom timing measurement infrastructure and statistical analysis"
        - "Must bypass constant-time implementations, compiler optimizations, and timing normalization"
        - "Requires understanding of CPU microarchitecture, branch prediction, and speculative execution"
        - "Must demonstrate secret extraction through multiple timing obfuscation layers"
        - "Cross-VM or cross-process timing attack capability required"
  
  generation_targets:
    minimum_difficulty: "120-360 minutes for senior security researchers with offensive security certifications (OSCP/OSWE/OSCE)"
    quality_requirements: "Must require deep understanding of CPU microarchitecture, cache hierarchy, and statistical timing analysis"
  
  difficulty_levels:
    beginner:
      description: "Basic string comparison timing"
      time_estimate: 600
      prerequisites: ["Basic Python/C knowledge"]
      
    intermediate:
      description: "Network-based timing measurement"
      time_estimate: 1200
      prerequisites: ["Statistics", "Network programming"]
      
    advanced:
      description: "Cache timing attacks"
      time_estimate: 2400
      prerequisites: ["CPU architecture", "Low-level programming"]
      
    expert:
      description: "Speculative execution timing"
      time_estimate: 3600
      prerequisites: ["Microarchitecture", "Assembly", "Advanced statistics"]

# === MULTI-AGENT ORCHESTRATION ===
multi_agent_orchestration:
  required_agents: 8
  coordination_complexity: "extreme"
  
  specialized_agents:
    - name: "timing_analyst"
      role: "Design and execute precise timing measurements"
      expertise: ["RDTSC", "perf counters", "statistical analysis", "network timing"]
      
    - name: "microarchitecture_specialist"
      role: "Analyze CPU microarchitectural timing behavior"
      expertise: ["cache hierarchy", "branch prediction", "speculative execution", "memory ordering"]
      
    - name: "crypto_analyst"
      role: "Identify timing vulnerabilities in cryptographic implementations"
      expertise: ["constant-time code", "RSA timing", "ECDSA timing", "AES cache timing"]
      
    - name: "reverse_engineer"
      role: "Analyze binary code for timing leakage"
      expertise: ["disassembly", "branch analysis", "memory access patterns"]
      
    - name: "statistician"
      role: "Apply advanced statistical methods for timing analysis"
      expertise: ["hypothesis testing", "signal detection", "noise filtering", "machine learning"]
      
    - name: "network_specialist"
      role: "Execute remote timing attacks over network"
      expertise: ["latency compensation", "jitter filtering", "timing amplification"]
      
    - name: "exploit_developer"
      role: "Develop timing-based exploits"
      expertise: ["secret extraction", "authentication bypass", "key recovery"]
      
    - name: "defense_bypass_specialist"
      role: "Bypass timing attack countermeasures"
      expertise: ["constant-time bypass", "timing normalization evasion", "noise injection bypass"]
  
  cross_vulnerability_chains:
    - chain: "String comparison timing -> Byte-by-byte password recovery -> Account takeover"
      complexity: "high"
      
    - chain: "Cache timing -> AES T-table analysis -> Key extraction -> Data decryption"
      complexity: "extreme"
      
    - chain: "Branch prediction timing -> RSA private key recovery -> Certificate forgery"
      complexity: "extreme"
      
    - chain: "Database lookup timing -> Username enumeration -> Targeted password attack"
      complexity: "medium"
      
    - chain: "Speculative execution -> Cross-process secret leakage -> Privilege escalation"
      complexity: "extreme"

# === EXPLOIT CHAIN REQUIREMENTS ===
exploit_chain_requirements:
  minimum_chain_length: 5
  required_stages:
    - stage: "timing_channel_discovery"
      description: "Identify timing side-channel in target"
      techniques:
        - "Response time variance analysis"
        - "CPU cycle counting"
        - "Network latency measurement"
        - "Cache timing observation"
    
    - stage: "measurement_infrastructure"
      description: "Build reliable timing measurement system"
      techniques:
        - "High-resolution timer configuration"
        - "Network jitter compensation"
        - "Statistical sample collection"
        - "Noise reduction techniques"
    
    - stage: "signal_extraction"
      description: "Extract meaningful signal from timing data"
      techniques:
        - "Statistical hypothesis testing"
        - "Machine learning classification"
        - "Threshold determination"
        - "False positive elimination"
    
    - stage: "secret_recovery"
      description: "Recover secret data from timing information"
      techniques:
        - "Byte-by-byte extraction"
        - "Binary search optimization"
        - "Parallel secret recovery"
        - "Error correction"
    
    - stage: "exploit_execution"
      description: "Leverage recovered secrets for attack"
      techniques:
        - "Authentication bypass"
        - "Session hijacking"
        - "Cryptographic key use"
        - "Privilege escalation"

# === DEFENSIVE EVASION ===
defensive_evasion:
  security_controls_to_bypass:
    - control: "Constant-Time Implementations"
      bypass_techniques:
        - "Compiler optimization exploitation"
        - "JIT compilation timing variance"
        - "Speculative execution leakage"
        - "Memory access pattern timing"
        - "Cache-based timing despite constant operations"
      
    - control: "Response Time Normalization"
      bypass_techniques:
        - "Early termination timing before normalization"
        - "Concurrent request timing"
        - "Partial timing measurement"
        - "Side-channel timing before sleep"
      
    - control: "Rate Limiting"
      bypass_techniques:
        - "Distributed timing collection"
        - "Low-rate statistical analysis"
        - "Timing amplification techniques"
        - "Batch timing measurement"
      
    - control: "Timing Jitter Addition"
      bypass_techniques:
        - "Statistical jitter removal"
        - "Large sample size analysis"
        - "Outlier detection and removal"
        - "Machine learning noise filtering"
      
    - control: "Branch Prediction Hardening"
      bypass_techniques:
        - "Indirect branch timing"
        - "Return stack buffer attacks"
        - "Speculative store bypass"
        - "Branch collision attacks"

# === REAL-WORLD CORRELATION ===
real_world_correlation:
  cve_attack_patterns:
    - cve: "CVE-2003-0078"
      technique: "OpenSSL RSA timing attack"
      real_world_impact: "Private key recovery"
      
    - cve: "CVE-2013-0169"
      technique: "Lucky Thirteen TLS timing"
      real_world_impact: "TLS session decryption"
      
    - cve: "CVE-2016-6210"
      technique: "OpenSSH user enumeration timing"
      real_world_impact: "Username enumeration for targeted attacks"
      
    - cve: "CVE-2017-5753"
      technique: "Spectre Variant 1"
      real_world_impact: "Cross-process secret leakage"
      
    - cve: "CVE-2018-0495"
      technique: "ROHNP ECDSA cache timing"
      real_world_impact: "ECDSA private key recovery"

# === TRAP DENSITY ===
trap_configuration:
  total_traps: 16
  trap_interaction_depth: 5
  cross_domain_traps: true
  
  trap_categories:
    comparison_traps: 4
    lookup_traps: 3
    branch_traps: 3
    crypto_traps: 3
    memory_traps: 3

# === LLM TRAP CONFIGURATIONS (50+) ===
traps:
  comparison_traps:
    - type: "early_exit_comparison"
      description: "String == exits on first mismatch"
      trigger: "Using == for secret comparison"
      detection: "Timing variance correlated with match prefix length"
      
    - type: "hash_timing"
      description: "Hash comparison reveals how many bytes match"
      trigger: "Comparing hash strings with =="
      detection: "Timing increases with matching prefix"
      
    - type: "length_check_first"
      description: "Length check before comparison leaks length"
      trigger: "if len(a) != len(b): return False"
      detection: "Different timing for length mismatch vs content mismatch"
      
    - type: "short_circuit_evaluation"
      description: "Boolean short-circuit reveals partial results"
      trigger: "if check1() and check2(): ..."
      detection: "Timing varies based on first check result"
      
  lookup_traps:
    - type: "lookup_timing"
      description: "Missing user vs wrong password have different timing"
      trigger: "Not doing fake work for missing users"
      detection: "Valid username detection via timing"
      
    - type: "cache_lookup"
      description: "Cached entries return faster"
      trigger: "Using cache without timing normalization"
      detection: "Recently accessed items return faster"
      
    - type: "database_index"
      description: "Indexed vs non-indexed query timing differs"
      trigger: "Relying on database timing consistency"
      detection: "Index hit vs miss timing difference"
      
  branch_traps:
    - type: "branch_timing"
      description: "Different code paths for valid/invalid inputs"
      trigger: "Early return on validation failure"
      detection: "Success path timing differs from failure"
      
    - type: "exception_timing"
      description: "Exception handling takes longer than normal return"
      trigger: "Using exceptions for control flow"
      detection: "Error cases take longer"
      
    - type: "logging_timing"
      description: "Logging on error path adds delay"
      trigger: "Conditional logging on failures"
      detection: "Logged errors take longer"
      
  crypto_traps:
    - type: "modular_exponentiation"
      description: "RSA timing varies with exponent bits"
      trigger: "Square-and-multiply without blinding"
      detection: "Key bits recoverable via timing"
      
    - type: "table_lookup"
      description: "AES T-table lookups leak via cache"
      trigger: "Using T-table AES implementation"
      detection: "Cache timing reveals key bytes"
      
    - type: "conditional_swap"
      description: "Conditional operations on secret data"
      trigger: "if (secret_bit) swap(a, b)"
      detection: "Branch prediction reveals secret"
      
  memory_traps:
    - type: "memory_allocation"
      description: "malloc timing varies with allocation size"
      trigger: "Variable-size allocation based on input"
      detection: "Allocation timing reveals input properties"
      
    - type: "page_fault"
      description: "First access to page takes longer"
      trigger: "Lazy memory allocation"
      detection: "Page fault timing reveals access pattern"
      
    - type: "numa_timing"
      description: "NUMA memory access timing varies"
      trigger: "Cross-NUMA node memory access"
      detection: "Memory location affects timing"

# === COMPREHENSIVE TASK GENERATION TEMPLATE ===
instruction_template: |
  You are hardening a {{ scenario_type }} against timing attacks.
  The code is at {{ path }}.
  
  System details:
  - Platform: {{ platform }}
  - Language: {{ language }}
  - Framework: {{ framework }}
  
  Measured timing variance: {{ timing_variance_ms }} ms
  Authentication attempts logged: {{ attempt_count }}
  Statistical confidence required: {{ confidence_level }}%
  
  Attack model:
  - Attacker capability: {{ attacker_capability }}
  - Network position: {{ network_position }}
  - Sample budget: {{ sample_budget }}
  
  Your task:
  {{ task_steps }}
  
  Additional requirements:
  - All comparisons must be constant-time (verify with timing tests)
  - Error paths must have same timing as success paths
  - Cache access patterns must be secret-independent
  - No branch on secret data
  - Compiler must not optimize away constant-time code

# === REFERENCE SOLUTION (COMPREHENSIVE) ===
reference_solution: |
  #!/usr/bin/env python3
  """
  Comprehensive Timing Attack Mitigation Library
  
  This module provides constant-time implementations for security-critical
  operations to prevent timing side-channel attacks.
  
  Key principles:
  1. All operations on secrets must be constant-time
  2. Memory access patterns must be secret-independent
  3. No branches on secret data
  4. Compiler optimizations must be prevented
  5. Timing must be normalized across all paths
  """
  
  import hmac
  import hashlib
  import secrets
  import time
  import struct
  import os
  from typing import Optional, Tuple, Union, List, Callable, Any
  from dataclasses import dataclass, field
  from functools import wraps
  import threading
  import logging
  
  # ============================================================
  # CONSTANT-TIME PRIMITIVES
  # ============================================================
  
  def constant_time_compare(a: bytes, b: bytes) -> bool:
      """
      Compare two byte strings in constant time.
      
      This function prevents timing attacks by:
      1. Always comparing all bytes regardless of mismatches
      2. Using XOR to accumulate differences
      3. Not using any branches on the comparison result until final return
      
      Args:
          a: First byte string
          b: Second byte string
          
      Returns:
          True if strings are equal, False otherwise
          
      Security notes:
          - Length difference is handled by comparing a with itself
          - The final comparison (diff == 0) is still variable-time
            but only leaks the final boolean result, not byte positions
      """
      if not isinstance(a, bytes) or not isinstance(b, bytes):
          raise TypeError("Arguments must be bytes")
      
      # Handle length mismatch in constant time
      # We still do a full comparison but with dummy data
      if len(a) != len(b):
          # Compare a with itself to burn same amount of time
          b = a
          result = False
      else:
          result = True
      
      # XOR all bytes and accumulate (constant time)
      diff = 0
      for x, y in zip(a, b):
          diff |= x ^ y
      
      # Both length match AND content match required
      return result and diff == 0
  
  
  def constant_time_compare_strings(a: str, b: str) -> bool:
      """
      String version of constant-time compare.
      
      Converts strings to UTF-8 bytes before comparison.
      """
      return constant_time_compare(a.encode('utf-8'), b.encode('utf-8'))
  
  
  # Use hmac.compare_digest for production - it's constant time
  # and implemented in C for better performance
  safe_compare = hmac.compare_digest
  
  
  def constant_time_select(condition: bool, if_true: int, if_false: int) -> int:
      """
      Select between two integers in constant time.
      
      Avoids branches by using arithmetic operations.
      
      Args:
          condition: Boolean condition
          if_true: Value to return if condition is True
          if_false: Value to return if condition is False
          
      Returns:
          if_true if condition else if_false
      """
      # Convert boolean to 0 or 1
      c = int(condition)
      # Create mask: 0 if condition is False, -1 (all 1s) if True
      mask = -c
      # Select using mask
      return (if_true & mask) | (if_false & ~mask)
  
  
  def constant_time_bytes_select(condition: bool, if_true: bytes, if_false: bytes) -> bytes:
      """
      Select between two byte strings in constant time.
      
      Both byte strings must have the same length.
      """
      if len(if_true) != len(if_false):
          raise ValueError("Byte strings must have same length")
      
      c = int(condition)
      mask = -c & 0xFF
      
      result = bytearray(len(if_true))
      for i in range(len(if_true)):
          result[i] = (if_true[i] & mask) | (if_false[i] & ~mask & 0xFF)
      
      return bytes(result)
  
  
  def constant_time_lookup(table: List[int], index: int, table_size: int) -> int:
      """
      Look up value in table without leaking index via cache timing.
      
      This function accesses ALL table entries regardless of the actual index,
      preventing cache-based timing attacks.
      
      Args:
          table: List of integer values
          index: Index to look up (must be < table_size)
          table_size: Size of the table
          
      Returns:
          Value at the specified index
      """
      result = 0
      for i in range(table_size):
          # Create mask: -1 if i == index, 0 otherwise
          match = constant_time_compare(
              i.to_bytes(4, 'big'), 
              index.to_bytes(4, 'big')
          )
          mask = -int(match)
          # XOR with table entry (no-op if mask is 0)
          result |= table[i] & mask
      return result
  
  
  # ============================================================
  # TIMING-SAFE AUTHENTICATION
  # ============================================================
  
  @dataclass
  class AuthResult:
      """Result of authentication operation."""
      success: bool
      user_id: Optional[str] = None
      error: Optional[str] = None
      
      # Include timing metadata for debugging (not in production)
      _execution_time: Optional[float] = field(default=None, repr=False)
  
  
  class TimingSafeAuthenticator:
      """
      Authentication that prevents timing attacks.
      
      This class ensures that:
      1. Authentication time is constant regardless of outcome
      2. User enumeration is not possible via timing
      3. Password comparison is constant-time
      4. Error messages don't reveal authentication failure reason
      """
      
      # Pre-computed fake hash for timing normalization
      # Used when user doesn't exist to prevent user enumeration
      FAKE_HASH = hashlib.pbkdf2_hmac(
          'sha256',
          b'fake_password_for_timing_normalization',
          b'fake_salt_value_32_bytes_long!!',
          100000
      )
      FAKE_SALT = b'fake_salt_value_32_bytes_long!!'
      
      # Minimum execution time to normalize all operations
      MIN_EXECUTION_TIME = 0.1  # 100ms
      
      def __init__(self, user_store, min_execution_time: float = 0.1):
          """
          Initialize authenticator.
          
          Args:
              user_store: Object with get_user(username) method
              min_execution_time: Minimum time for any auth operation (seconds)
          """
          self.user_store = user_store
          self.min_execution_time = min_execution_time
          self._lock = threading.Lock()
      
      def authenticate(self, username: str, password: str) -> AuthResult:
          """
          Authenticate user in constant time.
          
          This method has the same execution time regardless of:
          - Whether the user exists
          - Whether the password is correct
          - The length of the username or password
          
          Args:
              username: User's username
              password: User's password
              
          Returns:
              AuthResult with success status
          """
          start_time = time.perf_counter()
          
          try:
              return self._do_authenticate(username, password, start_time)
          finally:
              # Ensure minimum execution time
              self._normalize_timing(start_time)
      
      def _do_authenticate(
          self, 
          username: str, 
          password: str,
          start_time: float
      ) -> AuthResult:
          """Internal authentication logic."""
          
          # Look up user - timing may vary here
          user = self.user_store.get_user(username)
          
          if user is None:
              # User doesn't exist - do fake work to normalize timing
              stored_hash = self.FAKE_HASH
              stored_salt = self.FAKE_SALT
              user_exists = False
              user_id = None
          else:
              stored_hash = user.password_hash
              stored_salt = user.salt
              user_exists = True
              user_id = user.id
          
          # ALWAYS compute the hash (constant time operation)
          # This happens whether user exists or not
          computed_hash = hashlib.pbkdf2_hmac(
              'sha256',
              password.encode('utf-8'),
              stored_salt,
              100000  # Same iteration count as fake hash
          )
          
          # Constant-time comparison of hashes
          hash_matches = hmac.compare_digest(computed_hash, stored_hash)
          
          # Both conditions must be true for success
          # This is constant-time because we always evaluate both
          success = user_exists and hash_matches
          
          # Same response structure regardless of failure reason
          # Attacker cannot distinguish "user not found" from "wrong password"
          if success:
              return AuthResult(
                  success=True,
                  user_id=user_id,
                  error=None
              )
          else:
              return AuthResult(
                  success=False,
                  user_id=None,
                  error="Invalid credentials"  # Generic error message
              )
      
      def _normalize_timing(self, start_time: float):
          """Ensure minimum execution time has elapsed."""
          elapsed = time.perf_counter() - start_time
          remaining = self.min_execution_time - elapsed
          
          if remaining > 0:
              time.sleep(remaining)
      
      def verify_token(self, token: str, expected: str) -> bool:
          """
          Constant-time token verification.
          
          Args:
              token: Token to verify
              expected: Expected token value
              
          Returns:
              True if tokens match, False otherwise
          """
          return hmac.compare_digest(
              token.encode('utf-8'),
              expected.encode('utf-8')
          )
      
      def verify_hmac(
          self, 
          message: bytes, 
          signature: bytes, 
          key: bytes
      ) -> bool:
          """
          Constant-time HMAC verification.
          
          Args:
              message: Message that was signed
              signature: HMAC signature to verify
              key: HMAC key
              
          Returns:
              True if signature is valid, False otherwise
          """
          expected = hmac.new(key, message, hashlib.sha256).digest()
          return hmac.compare_digest(signature, expected)
      
      def verify_api_key(self, provided_key: str, valid_keys: List[str]) -> bool:
          """
          Verify API key against list in constant time.
          
          Always checks against all keys to prevent timing leaks.
          
          Args:
              provided_key: API key to verify
              valid_keys: List of valid API keys
              
          Returns:
              True if key is valid, False otherwise
          """
          result = False
          provided_bytes = provided_key.encode('utf-8')
          
          # Always iterate through all keys
          for valid_key in valid_keys:
              valid_bytes = valid_key.encode('utf-8')
              
              # Pad shorter key to match length
              if len(provided_bytes) != len(valid_bytes):
                  # Still do comparison to burn time
                  match = hmac.compare_digest(valid_bytes, valid_bytes)
              else:
                  match = hmac.compare_digest(provided_bytes, valid_bytes)
              
              # Accumulate result without short-circuit
              result = result or match
          
          return result
  
  
  # ============================================================
  # TIMING-SAFE RATE LIMITER
  # ============================================================
  
  class TimingSafeRateLimiter:
      """
      Rate limiter that doesn't leak timing information.
      
      Conventional rate limiters may have different timing when:
      - Checking rate limit for new vs existing clients
      - Rate limit is exceeded vs not exceeded
      
      This implementation normalizes timing across all paths.
      """
      
      def __init__(self, max_attempts: int, window_seconds: int):
          """
          Initialize rate limiter.
          
          Args:
              max_attempts: Maximum attempts allowed in window
              window_seconds: Time window in seconds
          """
          self.max_attempts = max_attempts
          self.window_seconds = window_seconds
          self.attempts: dict = {}
          self._lock = threading.Lock()
      
      def check_rate_limit(self, identifier: str) -> Tuple[bool, int]:
          """
          Check rate limit in constant time.
          
          Args:
              identifier: Client identifier (IP, user ID, etc.)
              
          Returns:
              Tuple of (is_allowed, attempts_remaining)
          """
          current_time = time.time()
          
          with self._lock:
              # Always do the same work regardless of identifier existence
              attempts = self.attempts.get(identifier, [])
              
              # Filter old attempts (do this even if empty)
              recent = [t for t in attempts if current_time - t < self.window_seconds]
              
              # Calculate result
              count = len(recent)
              allowed = count < self.max_attempts
              remaining = max(0, self.max_attempts - count)
              
              if allowed:
                  recent.append(current_time)
              
              # Always update (even if not allowed, for consistency)
              self.attempts[identifier] = recent
              
              return allowed, remaining
      
      def cleanup(self):
          """Remove expired entries."""
          current_time = time.time()
          
          with self._lock:
              expired_keys = []
              for identifier, attempts in self.attempts.items():
                  recent = [t for t in attempts if current_time - t < self.window_seconds]
                  if not recent:
                      expired_keys.append(identifier)
                  else:
                      self.attempts[identifier] = recent
              
              for key in expired_keys:
                  del self.attempts[key]
  
  
  # ============================================================
  # TIMING-SAFE CRYPTOGRAPHIC OPERATIONS
  # ============================================================
  
  def generate_secure_token(length: int = 32) -> str:
      """
      Generate cryptographically secure token.
      
      Args:
          length: Number of random bytes (token will be 2x length in hex)
          
      Returns:
          Hex-encoded random token
      """
      return secrets.token_hex(length)
  
  
  def hash_password(password: str, iterations: int = 100000) -> Tuple[bytes, bytes]:
      """
      Hash password with random salt.
      
      Args:
          password: Password to hash
          iterations: PBKDF2 iterations
          
      Returns:
          Tuple of (hash, salt)
      """
      salt = secrets.token_bytes(32)
      hash_value = hashlib.pbkdf2_hmac(
          'sha256',
          password.encode('utf-8'),
          salt,
          iterations
      )
      return hash_value, salt
  
  
  def constant_time_modular_exp(base: int, exp: int, mod: int) -> int:
      """
      Constant-time modular exponentiation.
      
      Uses Montgomery ladder to prevent timing attacks on exponent bits.
      
      This is a simplified implementation. Production code should use
      libraries with timing-safe bignum operations.
      
      Args:
          base: Base value
          exp: Exponent
          mod: Modulus
          
      Returns:
          base^exp mod mod
      """
      # Montgomery ladder - always do both operations
      r0 = 1
      r1 = base % mod
      
      # Get bit length of exponent
      bit_length = exp.bit_length()
      
      # Process each bit from most significant to least
      for i in range(bit_length - 1, -1, -1):
          bit = (exp >> i) & 1
          
          # Always compute both branches
          if bit == 0:
              r1 = (r0 * r1) % mod
              r0 = (r0 * r0) % mod
          else:
              r0 = (r0 * r1) % mod
              r1 = (r1 * r1) % mod
      
      return r0
  
  
  # ============================================================
  # TIMING ANALYSIS AND DETECTION
  # ============================================================
  
  @dataclass
  class TimingMeasurement:
      """Record of timing measurement."""
      operation: str
      input_size: int
      execution_time_ns: int
      timestamp: float
  
  
  class TimingAnalyzer:
      """
      Analyze timing measurements to detect potential attacks.
      
      This class can be used to:
      1. Detect timing anomalies that might indicate attacks
      2. Verify that implementations are constant-time
      3. Monitor for timing side channels in production
      """
      
      def __init__(self, window_size: int = 1000):
          """
          Initialize analyzer.
          
          Args:
              window_size: Number of measurements to keep for analysis
          """
          self.window_size = window_size
          self.measurements: List[TimingMeasurement] = []
          self._lock = threading.Lock()
      
      def record(self, operation: str, input_size: int, execution_time_ns: int):
          """Record a timing measurement."""
          with self._lock:
              measurement = TimingMeasurement(
                  operation=operation,
                  input_size=input_size,
                  execution_time_ns=execution_time_ns,
                  timestamp=time.time()
              )
              self.measurements.append(measurement)
              
              # Keep only recent measurements
              if len(self.measurements) > self.window_size:
                  self.measurements = self.measurements[-self.window_size:]
      
      def check_constant_time(self, operation: str) -> Tuple[bool, dict]:
          """
          Check if operation has constant timing.
          
          Args:
              operation: Operation name to analyze
              
          Returns:
              Tuple of (is_constant_time, statistics)
          """
          with self._lock:
              # Filter measurements for this operation
              op_measurements = [
                  m for m in self.measurements if m.operation == operation
              ]
              
              if len(op_measurements) < 10:
                  return True, {"error": "Insufficient data"}
              
              # Group by input size
              by_size: dict = {}
              for m in op_measurements:
                  if m.input_size not in by_size:
                      by_size[m.input_size] = []
                  by_size[m.input_size].append(m.execution_time_ns)
              
              # Calculate statistics for each size
              stats = {}
              for size, times in by_size.items():
                  avg = sum(times) / len(times)
                  variance = sum((t - avg) ** 2 for t in times) / len(times)
                  stats[size] = {"avg": avg, "variance": variance, "count": len(times)}
              
              # Check if timing varies significantly with input size
              if len(stats) < 2:
                  return True, stats
              
              avgs = [s["avg"] for s in stats.values()]
              max_diff = max(avgs) - min(avgs)
              avg_time = sum(avgs) / len(avgs)
              
              # If max difference is > 10% of average, not constant-time
              is_constant = max_diff < avg_time * 0.1
              
              return is_constant, {
                  "size_stats": stats,
                  "max_difference": max_diff,
                  "average_time": avg_time,
                  "variation_percent": (max_diff / avg_time * 100) if avg_time > 0 else 0
              }
      
      def detect_timing_attack(self, operation: str) -> Tuple[bool, str]:
          """
          Detect potential timing attack patterns.
          
          Looks for:
          1. Unusual measurement patterns (many similar inputs)
          2. Sequential probing patterns
          3. Statistical anomalies
          
          Args:
              operation: Operation to analyze
              
          Returns:
              Tuple of (attack_detected, description)
          """
          with self._lock:
              op_measurements = [
                  m for m in self.measurements if m.operation == operation
              ]
              
              if len(op_measurements) < 100:
                  return False, "Insufficient data for analysis"
              
              # Check for unusual measurement frequency
              time_diffs = []
              for i in range(1, len(op_measurements)):
                  diff = op_measurements[i].timestamp - op_measurements[i-1].timestamp
                  time_diffs.append(diff)
              
              if time_diffs:
                  avg_diff = sum(time_diffs) / len(time_diffs)
                  
                  # Very rapid measurements might indicate attack
                  if avg_diff < 0.001:  # < 1ms between measurements
                      return True, f"Rapid measurement pattern detected (avg {avg_diff*1000:.2f}ms)"
              
              # Check for input size patterns (sequential probing)
              sizes = [m.input_size for m in op_measurements[-50:]]
              if len(set(sizes)) < 5:  # Very few unique sizes
                  return True, f"Repeated input sizes detected (only {len(set(sizes))} unique)"
              
              return False, "No attack pattern detected"
  
  
  # ============================================================
  # TIMING-SAFE DECORATOR
  # ============================================================
  
  def timing_safe(min_time_ms: float = 0):
      """
      Decorator to make function execution time constant.
      
      Args:
          min_time_ms: Minimum execution time in milliseconds
          
      Usage:
          @timing_safe(min_time_ms=100)
          def sensitive_operation(data):
              ...
      """
      def decorator(func: Callable) -> Callable:
          @wraps(func)
          def wrapper(*args, **kwargs) -> Any:
              start = time.perf_counter()
              
              try:
                  result = func(*args, **kwargs)
                  return result
              finally:
                  elapsed_ms = (time.perf_counter() - start) * 1000
                  
                  if elapsed_ms < min_time_ms:
                      remaining_s = (min_time_ms - elapsed_ms) / 1000
                      time.sleep(remaining_s)
          
          return wrapper
      return decorator
  
  
  # ============================================================
  # TESTING UTILITIES
  # ============================================================
  
  def measure_timing(func: Callable, args: tuple, iterations: int = 1000) -> List[int]:
      """
      Measure function execution time.
      
      Args:
          func: Function to measure
          args: Arguments to pass to function
          iterations: Number of measurements
          
      Returns:
          List of execution times in nanoseconds
      """
      times = []
      
      for _ in range(iterations):
          start = time.perf_counter_ns()
          func(*args)
          end = time.perf_counter_ns()
          times.append(end - start)
      
      return times
  
  
  def timing_test_constant_time(
      func: Callable,
      input_generator: Callable[[], tuple],
      iterations: int = 1000,
      threshold: float = 0.1
  ) -> Tuple[bool, dict]:
      """
      Test if function has constant-time execution.
      
      Args:
          func: Function to test
          input_generator: Function that generates test inputs
          iterations: Number of iterations per input
          threshold: Maximum allowed variation (as fraction of mean)
          
      Returns:
          Tuple of (is_constant_time, statistics)
      """
      all_times = []
      
      # Generate multiple different inputs
      for _ in range(10):
          args = input_generator()
          times = measure_timing(func, args, iterations)
          all_times.extend(times)
      
      # Calculate statistics
      mean = sum(all_times) / len(all_times)
      variance = sum((t - mean) ** 2 for t in all_times) / len(all_times)
      std_dev = variance ** 0.5
      
      max_time = max(all_times)
      min_time = min(all_times)
      
      # Check if variation is within threshold
      variation = (max_time - min_time) / mean if mean > 0 else 0
      is_constant = variation < threshold
      
      return is_constant, {
          "mean_ns": mean,
          "std_dev_ns": std_dev,
          "min_ns": min_time,
          "max_ns": max_time,
          "variation": variation,
          "iterations": len(all_times)
      }

# === TEST CASES ===
fail_to_pass:
  - "test_constant_time_comparison_no_early_exit"
  - "test_no_user_enumeration_via_timing"
  - "test_hmac_verification_constant_time"
  - "test_normalized_execution_time_all_paths"
  - "test_password_hash_comparison_constant_time"
  - "test_api_key_verification_constant_time"
  - "test_token_validation_constant_time"
  - "test_no_cache_timing_leaks"
  - "test_no_branch_timing_on_secrets"
  - "test_error_paths_same_timing_as_success"

pass_to_pass:
  - "test_valid_authentication_succeeds"
  - "test_invalid_password_rejected"
  - "test_missing_user_rejected"
  - "test_rate_limiting_works"
  - "test_token_generation_secure"

# === VARIABLES FOR TASK GENERATION ===
variables:
  scenario_type:
    type: string
    options:
      - "API authentication"
      - "login system"
      - "token validation"
      - "session verification"
      - "password reset"
      - "two-factor verification"
      - "OAuth token introspection"
      - "JWT signature verification"
      - "API key validation"
      - "certificate validation"
      - "HMAC verification"
      - "signature verification"
      - "encryption key comparison"
      - "biometric template matching"
      - "cryptographic key validation"
      
  path:
    type: path
    generator: random_path
    
  platform:
    type: string
    options:
      - "Linux x86_64"
      - "Linux ARM64"
      - "Windows x64"
      - "macOS ARM64"
      - "FreeBSD"
      - "Kubernetes container"
      - "AWS Lambda"
      - "Azure Functions"
      - "CloudFlare Workers"
      
  language:
    type: string
    options:
      - "Python 3.11"
      - "Python 3.12"
      - "Node.js 20"
      - "Go 1.21"
      - "Rust 1.74"
      - "Java 21"
      - "C# .NET 8"
      - "C/C++ (GCC 13)"
      - "C/C++ (Clang 17)"
      
  framework:
    type: string
    options:
      - "Django 4.2"
      - "FastAPI"
      - "Flask"
      - "Express.js"
      - "Spring Boot"
      - "ASP.NET Core"
      - "Gin (Go)"
      - "Actix-web (Rust)"
      - "Custom HTTP server"
      
  timing_variance_ms:
    type: float
    min: 0.1
    max: 100.0
    
  attempt_count:
    type: int
    min: 1000
    max: 10000000
    
  confidence_level:
    type: float
    options: [95.0, 99.0, 99.9, 99.99]
    
  attacker_capability:
    type: string
    options:
      - "Remote network access only"
      - "Same network segment"
      - "Co-located VM"
      - "Same physical machine"
      - "Browser-based JavaScript"
      - "Shared hosting environment"
      
  network_position:
    type: string
    options:
      - "Internet"
      - "Corporate LAN"
      - "Same data center"
      - "Same rack"
      - "Localhost"
      
  sample_budget:
    type: int
    min: 100
    max: 10000000
    
  task_steps:
    type: template
    value: |
      1. Identify all timing side channels in the authentication flow
      2. Analyze string/byte comparison implementations
      3. Check for early-exit patterns in validation logic
      4. Verify database lookup timing normalization
      5. Implement constant-time comparison using hmac.compare_digest
      6. Add timing normalization for all execution paths
      7. Eliminate user enumeration via timing
      8. Implement constant-time token verification
      9. Add rate limiting with constant-time checks
      10. Verify no compiler optimization removes constant-time code
      11. Test with statistical timing analysis
      12. Measure and verify timing distribution is uniform

# === ANTI-PATTERNS AND LLM FAILURE MODES ===
anti_patterns:
  llm_failure_modes:
    - "Applying textbook attack patterns without considering mitigations"
    - "Missing WAF/IDS bypass techniques for exploitation"
    - "Ignoring ASLR/PIE/NX and other modern protections"
    - "Not considering timing side-channel in crypto implementations"
    - "Missing second-order and stored attack vectors"
    - "Overlooking race conditions in authentication flows"
    - "Assuming standard libraries are secure without version checking"
    - "Missing JWT algorithm confusion and key confusion attacks"
    - "Ignoring deserialization gadget chain discovery complexity"
    - "Not recognizing compiler optimizations breaking constant-time guarantees"
    - "Missing JIT compilation timing variance in managed runtimes"
    - "Overlooking speculative execution timing leakage"
    - "Failing to account for network jitter in remote attacks"
    - "Not considering cache hierarchy effects on timing"
    - "Missing branch prediction-based timing channels"
    - "Ignoring memory access pattern timing leakage"
    - "Not recognizing TLB timing side-channels"
    - "Overlooking DRAM row buffer timing"
    - "Missing prefetcher-induced timing variations"
    - "Failing to identify exception handling timing"
    - "Not considering garbage collection timing impacts"
    - "Ignoring logging-induced timing variations"
    - "Missing database index hit/miss timing"
    - "Not recognizing cache timing in AES T-table implementations"
    - "Overlooking RSA modular exponentiation timing"
    - "Failing to identify ECDSA scalar multiplication timing"
    - "Not considering cross-VM timing attacks via shared cache"
    - "Missing browser-based high-resolution timing techniques"
    - "Ignoring SharedArrayBuffer timing measurement capabilities"

# === ANTI-HARDCODING MEASURES ===
anti_hardcoding:
  canary_tokens: true
  randomize_paths: true
  dynamic_content: true
  
  timing_sources:
    - "early_exit_string_compare"
    - "user_existence_timing"
    - "hash_comparison_timing"
    - "branch_timing_difference"
    - "cache_hit_miss_timing"
    - "memory_allocation_timing"
    - "exception_handling_timing"
    - "logging_timing"
    - "database_query_timing"
    - "network_response_timing"
    
  randomization_vectors:
    - "Vary password lengths"
    - "Vary username lengths"
    - "Vary token formats"
    - "Vary error message content"
    - "Vary execution path complexity"
    - "Vary data structure sizes"
    
  verification_requirements:
    - "Statistical significance (p < 0.05)"
    - "Minimum sample size (n > 1000)"
    - "Multiple timing measurements"
    - "Cross-platform verification"
    - "Compiler optimization testing"

# === CVE REFERENCES FOR INSPIRATION ===
cve_references:
  - id: "CVE-2003-0078"
    description: "OpenSSL timing-based attack on RSA keys"
    relevance: "Classic RSA timing attack"
    
  - id: "CVE-2013-0169"
    description: "Lucky Thirteen TLS CBC timing attack"
    relevance: "Padding oracle via timing"
    
  - id: "CVE-2014-0076"
    description: "OpenSSL ECDSA timing attack"
    relevance: "ECDSA nonce recovery via timing"
    
  - id: "CVE-2016-6210"
    description: "OpenSSH user enumeration timing"
    relevance: "Username enumeration via timing"
    
  - id: "CVE-2017-5753"
    description: "Spectre Variant 1"
    relevance: "Speculative execution timing"
    
  - id: "CVE-2017-5715"
    description: "Spectre Variant 2"
    relevance: "Branch target injection timing"
    
  - id: "CVE-2017-5754"
    description: "Meltdown"
    relevance: "Kernel memory timing leak"
    
  - id: "CVE-2018-0495"
    description: "ROHNP ECDSA timing attack"
    relevance: "Cache timing on ECDSA"
    
  - id: "CVE-2018-3615"
    description: "Foreshadow/L1TF"
    relevance: "L1 cache timing attack"

# === LANGUAGE-SPECIFIC CONSIDERATIONS ===
language_specific:
  python:
    constant_time_functions:
      - "hmac.compare_digest()"
      - "secrets.compare_digest()"
    timing_hazards:
      - "str comparison with =="
      - "bytes comparison with =="
      - "list comparison with =="
    recommendations:
      - "Use hmac.compare_digest for all secret comparisons"
      - "Use secrets module for token generation"
      - "Avoid string formatting with secrets"
      
  javascript:
    constant_time_functions:
      - "crypto.timingSafeEqual()"
    timing_hazards:
      - "=== comparison on strings"
      - "Buffer comparison with ==="
      - "Array comparison"
    recommendations:
      - "Use crypto.timingSafeEqual for all secret comparisons"
      - "Use crypto.randomBytes for token generation"
      
  go:
    constant_time_functions:
      - "subtle.ConstantTimeCompare()"
      - "subtle.ConstantTimeSelect()"
      - "subtle.ConstantTimeByteEq()"
    timing_hazards:
      - "bytes.Equal()"
      - "string comparison with =="
    recommendations:
      - "Use crypto/subtle package"
      - "Use crypto/rand for random generation"
      
  rust:
    constant_time_functions:
      - "constant_time_eq crate"
      - "subtle crate"
    timing_hazards:
      - "== comparison on &[u8]"
      - "String comparison"
    recommendations:
      - "Use subtle crate for constant-time operations"
      - "Use rand crate with OsRng"
      
  java:
    constant_time_functions:
      - "MessageDigest.isEqual()"
    timing_hazards:
      - "Arrays.equals()"
      - "String.equals()"
    recommendations:
      - "Use MessageDigest.isEqual for byte array comparison"
      - "Use SecureRandom for token generation"

# === TESTING METHODOLOGY ===
testing_methodology:
  statistical_tests:
    - name: "Welch's t-test"
      purpose: "Compare timing means of different inputs"
      threshold: "p-value < 0.05 indicates timing leak"
      
    - name: "Kolmogorov-Smirnov test"
      purpose: "Compare timing distributions"
      threshold: "Reject if distributions differ significantly"
      
    - name: "Dudect methodology"
      purpose: "Leakage detection in constant-time code"
      reference: "https://github.com/oreparaz/dudect"
      
  measurement_techniques:
    - name: "RDTSC timing"
      precision: "CPU cycle level"
      requirements: "Disable turbo boost, pin CPU frequency"
      
    - name: "perf_counter_ns"
      precision: "Nanosecond level"
      requirements: "Python 3.7+"
      
    - name: "QueryPerformanceCounter"
      precision: "Sub-microsecond"
      requirements: "Windows"
      
  sample_sizes:
    minimum: 10000
    recommended: 100000
    high_precision: 1000000
    
  environmental_controls:
    - "Disable CPU frequency scaling"
    - "Pin process to single CPU core"
    - "Minimize system activity"
    - "Account for cache warm-up"
    - "Run multiple trials"
