id: "algo-dp-state-explosion-001"
version: "2.0.0"
category: "algorithms"
subcategory: "dynamic-programming"

# =============================================================================
# LLM GENERATION FRAMEWORK
# =============================================================================
# This file is a comprehensive generation specification for LLMs to create
# unique, extremely challenging state space explosion tasks. The goal is to
# enable generation of 10,000+ fundamentally different, genuinely hard tasks
# that require deep understanding of DP state optimization.
# =============================================================================

generation_framework:
  overview: |
    This specification enables LLMs to generate DP state explosion tasks that are
    genuinely difficult. State explosion is a common DP problem where the state
    space grows exponentially or is unnecessarily large. Tasks should require
    understanding of state space reduction techniques.

  multi_conversation_workflow:
    phase_1_research:
      description: "LLM researches state explosion scenarios"
      activities:
        - "Study state space representation techniques"
        - "Research state equivalence and canonicalization"
        - "Investigate dimension reduction strategies"
        - "Analyze real-world DP memory issues"
        - "Study advanced DP optimization techniques"
      output: "Comprehensive state explosion patterns"
    
    phase_2_creation:
      description: "LLM creates task with state explosion issues"
      activities:
        - "Design DP with unnecessarily large state space"
        - "Create scenarios with redundant state dimensions"
        - "Embed equivalent states not being merged"
        - "Add unreachable states being computed"
        - "Include suboptimal recurrence formulations"
      output: "Complete task with state explosion traps"
    
    phase_3_amplification:
      description: "LLM adds difficulty multipliers"
      activities:
        - "Layer multiple state space issues"
        - "Add memory pressure that triggers OOM"
        - "Include performance requirements"
        - "Create correctness-critical optimizations"
        - "Add constraints that complicate solutions"
      output: "Amplified task"
    
    phase_4_verification:
      description: "LLM validates task is genuinely hard"
      validation_criteria:
        - "Cannot be fixed with more memory"
        - "Requires algorithmic insight"
        - "Has at least 5 interacting hidden traps"
        - "Would take experienced developers 30+ minutes"
        - "Has cascading failure modes that interact with each other"
        - "Requires multi-domain knowledge synthesis (algorithms + systems + performance)"
      output: "Verified task"

  quality_requirements:
    mandatory:
      - "Must require state space analysis"
      - "Must have non-obvious reduction opportunities"
      - "Must include at least 5 state explosion causes"
      - "Must have memory constraints that matter"
      - "Solution must maintain correctness"
      - "Must take 30+ minutes for experienced developers, 45+ for intermediate"

# =============================================================================
# EXHAUSTIVE TOPIC UNIVERSE
# =============================================================================

topic_universe:
  # ---------------------------------------------------------------------------
  # DP Problem Types (50 topics)
  # ---------------------------------------------------------------------------
  dp_problems:
    scheduling:
      - job_scheduling_weighted
      - job_scheduling_deadlines
      - task_assignment
      - resource_allocation
      - meeting_room_scheduling
      - cpu_scheduling
      - interval_scheduling_maximization
      - weighted_interval_scheduling
      - parallel_machine_scheduling
      - preemptive_scheduling
    
    knapsack_variants:
      - knapsack_01
      - knapsack_unbounded
      - knapsack_bounded
      - knapsack_multiple
      - knapsack_fractional_with_constraints
      - subset_sum
      - partition_problem
      - multi_constraint_knapsack
      - quadratic_knapsack
      - setup_knapsack
    
    sequence_problems:
      - longest_increasing_subsequence
      - longest_common_subsequence
      - longest_common_substring
      - edit_distance
      - sequence_alignment
      - optimal_bst
      - matrix_chain_multiplication
      - parenthesization
      - word_break
      - palindrome_partitioning
    
    graph_dp:
      - shortest_path_with_constraints
      - hamiltonian_path
      - traveling_salesman
      - vehicle_routing
      - minimum_spanning_arborescence
      - steiner_tree
      - tree_dp
      - tree_rerooting
      - tree_decomposition_dp
      - path_counting
    
    game_theory_dp:
      - minimax
      - alpha_beta_pruning
      - nim_variants
      - sprague_grundy
      - combinatorial_game_theory
      - two_player_games
      - stochastic_games
      - markov_decision_process
      - reinforcement_learning_dp
      - backward_induction
    
    specialized_dp:
      - bitmask_dp
      - digit_dp
      - probability_dp
      - expected_value_dp
      - dp_on_tree
      - dp_on_dag
      - dp_on_broken_profile
      - sos_dp
      - convex_hull_trick_dp
      - divide_and_conquer_dp

  # ---------------------------------------------------------------------------
  # State Space Topics (30 topics)
  # ---------------------------------------------------------------------------
  state_space:
    representation:
      - tuple_state
      - bitmask_state
      - matrix_state
      - tree_state
      - graph_state
      - set_state
      - multiset_state
      - permutation_state
      - partition_state
      - configuration_state
    
    dimensions:
      - position_dimension
      - time_dimension
      - resource_dimension
      - capacity_dimension
      - count_dimension
      - selection_dimension
      - ordering_dimension
      - connectivity_dimension
      - partition_dimension
      - level_dimension
    
    optimization_techniques:
      - state_compression
      - state_merging
      - state_pruning
      - state_canonicalization
      - rolling_array
      - space_time_tradeoff
      - meet_in_middle
      - iterative_dp
      - matrix_exponentiation
      - sparse_table

  # ---------------------------------------------------------------------------
  # Application Domains (25 topics)
  # ---------------------------------------------------------------------------
  domains:
    operations_research:
      - production_planning
      - inventory_management
      - supply_chain
      - facility_location
      - portfolio_optimization
      - project_scheduling
      - resource_constrained_scheduling
    
    bioinformatics:
      - sequence_alignment
      - rna_folding
      - protein_structure
      - phylogenetic_trees
      - gene_prediction
    
    computer_science:
      - compiler_optimization
      - register_allocation
      - instruction_scheduling
      - cache_optimization
      - query_optimization
      - automata_construction
    
    machine_learning:
      - viterbi_algorithm
      - forward_backward
      - beam_search
      - structured_prediction
      - sequence_labeling

# =============================================================================
# COMPLEXITY DIMENSIONS
# =============================================================================

complexity_dimensions:
  state_space_size:
    exponential_causes:
      - permutation_tracking
      - subset_tracking
      - combination_tracking
      - multiset_tracking
      - partition_tracking
    
    polynomial_causes:
      - unnecessary_dimensions
      - fine_grained_discretization
      - redundant_representation
      - non_canonical_states
    
    reduction_opportunities:
      - dimension_elimination
      - range_compression
      - equivalence_merging
      - symmetry_breaking
      - constraint_propagation

  memory_patterns:
    usage_patterns:
      - all_states_needed
      - only_previous_needed
      - only_some_previous_needed
      - dependency_structure_sparse
    
    allocation_patterns:
      - preallocate_all
      - lazy_allocation
      - hash_map_allocation
      - array_allocation
      - matrix_allocation

  computation_patterns:
    dependency_patterns:
      - linear_dependency
      - tree_dependency
      - dag_dependency
      - cyclic_dependency
    
    optimization_patterns:
      - bottom_up
      - top_down
      - bidirectional
      - iterative_refinement

# =============================================================================
# TRAP TAXONOMY
# =============================================================================

trap_taxonomy:
  # ---------------------------------------------------------------------------
  # Unnecessary State Dimensions (8 types)
  # ---------------------------------------------------------------------------
  unnecessary_dimensions:
    order_tracking:
      trap_id: "UD001"
      name: "Tracking Order When Only Set Matters"
      description: "State includes order of selections when only set matters"
      example: |
        # Task: Select items with max value, sum <= capacity
        # Wrong: state = (i, capacity, [list of selected indices])
        # Right: state = (i, remaining_capacity)
        # Order doesn't affect future decisions
      detection_difficulty: "medium"
      manifestation: "Factorial state space"
      fix: "Only track what affects future decisions"
      
    path_tracking:
      trap_id: "UD002"
      name: "Full Path in State"
      description: "State includes entire path, not just endpoint"
      example: |
        # Wrong: state = (current_node, full_path_taken)
        # Right: state = (current_node, relevant_summary)
        # Full path is n! states
      detection_difficulty: "medium"
      manifestation: "Exponential path storage"
      fix: "Track only decision-relevant information"
      
    history_tracking:
      trap_id: "UD003"
      name: "Full History in State"
      description: "State includes complete history"
      example: |
        # Wrong: state = (position, [all moves made])
        # Right: state = (position) or (position, moves_count)
      detection_difficulty: "easy"
      manifestation: "Unbounded state growth"
      fix: "Summarize history to relevant features"
      
    fine_discretization:
      trap_id: "UD004"
      name: "Over-Fine Discretization"
      description: "Continuous values discretized too finely"
      example: |
        # Time from 0.0 to 1000000.0, tracked to 0.001 precision
        # 1 billion time states!
        # Could use coarser discretization or events
      detection_difficulty: "medium"
      manifestation: "Huge dimension range"
      fix: "Use coarser discretization or event-driven"
      
    redundant_dimension:
      trap_id: "UD005"
      name: "Redundant Computed Dimension"
      description: "State dimension derivable from others"
      example: |
        # state = (items_selected, total_value, remaining_capacity)
        # total_value = sum of selected item values
        # Redundant! Can compute from items_selected
      detection_difficulty: "medium"
      manifestation: "Multiplied state space"
      fix: "Derive computed values, don't store"
      
    separate_equivalent:
      trap_id: "UD006"
      name: "Equivalent States Kept Separate"
      description: "States that should merge kept distinct"
      example: |
        # {A, B} selected and {B, A} selected are equivalent
        # But tracked as different states
      detection_difficulty: "hard"
      manifestation: "Factorial redundancy"
      fix: "Canonicalize state representation"
      
    symmetric_states:
      trap_id: "UD007"
      name: "Symmetric States Not Merged"
      description: "Symmetric configurations counted separately"
      example: |
        # Chess position mirrored horizontally is equivalent
        # But both states in DP table
      detection_difficulty: "hard"
      manifestation: "Symmetry multiplier"
      fix: "Use canonical symmetric form"
      
    identity_in_state:
      trap_id: "UD008"
      name: "Object Identity in State"
      description: "State uses object identity not value"
      example: |
        # state = (node_object, ...)
        # Different node objects with same value = different states
      detection_difficulty: "hard"
      manifestation: "State explosion with object creation"
      fix: "Use value-based state representation"

  # ---------------------------------------------------------------------------
  # Unreachable State Computation (6 types)
  # ---------------------------------------------------------------------------
  unreachable_states:
    invalid_combinations:
      trap_id: "US001"
      name: "Computing Invalid Combinations"
      description: "DP computes states that violate constraints"
      example: |
        # Knapsack: computing (item, capacity) where capacity < 0
        # These states will never be used
      detection_difficulty: "easy"
      manifestation: "Wasted computation and memory"
      fix: "Prune invalid states early"
      
    unreachable_from_start:
      trap_id: "US002"
      name: "States Unreachable from Start"
      description: "States that can't be reached from initial state"
      example: |
        # Starting at (0,0), state (1000, 1000) may be unreachable
        # with step size 1 and time limit 100
      detection_difficulty: "medium"
      manifestation: "Computing unused states"
      fix: "Forward propagation or reachability analysis"
      
    unreachable_to_goal:
      trap_id: "US003"
      name: "States Unreachable to Goal"
      description: "States from which goal is unreachable"
      example: |
        # If goal needs 100 more steps but only 50 remain
        # Current state is useless
      detection_difficulty: "medium"
      manifestation: "Computing dead-end states"
      fix: "Backward reachability or pruning"
      
    dominated_states:
      trap_id: "US004"
      name: "Dominated States Computed"
      description: "States dominated by better states computed"
      example: |
        # State A has more value and more capacity than B
        # B is dominated, never optimal
      detection_difficulty: "hard"
      manifestation: "Redundant dominated states"
      fix: "Pareto pruning"
      
    proven_suboptimal:
      trap_id: "US005"
      name: "Proven Suboptimal States"
      description: "States provably not on optimal path"
      example: |
        # Bounding shows state can't improve on current best
        # But still computed in DP
      detection_difficulty: "hard"
      manifestation: "Computing suboptimal branches"
      fix: "Branch and bound integration"
      
    constraint_violated:
      trap_id: "US006"
      name: "Constraint Violated States"
      description: "States where constraint already violated"
      example: |
        # Already over budget in state, no point continuing
        # But DP keeps computing
      detection_difficulty: "easy"
      manifestation: "Wasted constraint-violated states"
      fix: "Early constraint checking"

  # ---------------------------------------------------------------------------
  # Suboptimal Recurrence (6 types)
  # ---------------------------------------------------------------------------
  suboptimal_recurrence:
    redundant_recomputation:
      trap_id: "SR001"
      name: "Redundant Subproblem Computation"
      description: "Same subproblem computed multiple times"
      example: |
        # fib(n) = fib(n-1) + fib(n-2) without memoization
        # Exponential recomputation
      detection_difficulty: "easy"
      manifestation: "Exponential time"
      fix: "Memoization"
      
    inefficient_transition:
      trap_id: "SR002"
      name: "Inefficient State Transition"
      description: "Transitions that could be optimized"
      example: |
        # For each state, checking all possible next states
        # When only few are valid
      detection_difficulty: "medium"
      manifestation: "O(S²) instead of O(S)"
      fix: "Optimize transition enumeration"
      
    non_optimal_substructure:
      trap_id: "SR003"
      name: "Missing Optimal Substructure"
      description: "Problem lacks optimal substructure"
      example: |
        # Trying DP on problem that doesn't have it
        # Longest path in general graph
      detection_difficulty: "hard"
      manifestation: "Wrong answers"
      fix: "Verify optimal substructure property"
      
    wrong_order:
      trap_id: "SR004"
      name: "Wrong Computation Order"
      description: "Computing in order that misses dependencies"
      example: |
        # Computing dp[i][j] before dp[i-1][j-1] is ready
        # In bottom-up DP
      detection_difficulty: "medium"
      manifestation: "Uninitialized values used"
      fix: "Topological order computation"
      
    missing_case:
      trap_id: "SR005"
      name: "Missing Recurrence Case"
      description: "Recurrence missing edge case"
      example: |
        # dp[0] not handled, or boundary not set
      detection_difficulty: "easy"
      manifestation: "Wrong base cases"
      fix: "Handle all base cases"
      
    expensive_min_max:
      trap_id: "SR006"
      name: "Expensive Min/Max in Recurrence"
      description: "Computing min/max over large range"
      example: |
        # dp[i] = min(dp[j] + cost[j][i]) for j in 0..i-1
        # O(n) per state = O(n²) total
        # Could use segment tree for O(n log n)
      detection_difficulty: "hard"
      manifestation: "Quadratic instead of linearithmic"
      fix: "Use efficient data structures"

  # ---------------------------------------------------------------------------
  # Memory Allocation Traps (6 types)
  # ---------------------------------------------------------------------------
  memory_allocation:
    preallocate_all:
      trap_id: "MA001"
      name: "Preallocating Entire State Space"
      description: "Allocating memory for all possible states"
      example: |
        # dp = [[0] * 10000000 for _ in range(10000)]
        # 100 billion cells!
      detection_difficulty: "easy"
      manifestation: "OOM on large inputs"
      fix: "Lazy allocation or rolling array"
      
    sparse_as_dense:
      trap_id: "MA002"
      name: "Sparse DP as Dense Array"
      description: "Sparse DP stored in dense array"
      example: |
        # Only 1% of states reachable
        # But allocating 100% of memory
      detection_difficulty: "medium"
      manifestation: "99% memory waste"
      fix: "Use hash map for sparse DP"
      
    keeping_all_layers:
      trap_id: "MA003"
      name: "Keeping All DP Layers"
      description: "Keeping all previous layers when only some needed"
      example: |
        # dp[i] only depends on dp[i-1]
        # But keeping dp[0..i-1]
      detection_difficulty: "easy"
      manifestation: "O(n) space instead of O(1)"
      fix: "Rolling array with 2 layers"
      
    storing_full_solution:
      trap_id: "MA004"
      name: "Storing Full Solution in State"
      description: "Storing complete solution not just value"
      example: |
        # dp[(i,j)] = (value, [full path])
        # Path can be O(n) per state = O(n³) total
      detection_difficulty: "medium"
      manifestation: "Cubic memory"
      fix: "Reconstruct solution from transitions"
      
    object_overhead:
      trap_id: "MA005"
      name: "Object Overhead Per State"
      description: "Using objects with high overhead"
      example: |
        # Python dict per state instead of array
        # 50+ bytes overhead per dict
      detection_difficulty: "medium"
      manifestation: "Memory bloat from overhead"
      fix: "Use arrays and indices"
      
    copy_per_state:
      trap_id: "MA006"
      name: "Copying Data Per State"
      description: "Copying large data for each state"
      example: |
        # new_state = copy(old_state)
        # Copy O(n) per transition = O(n²) per state
      detection_difficulty: "hard"
      manifestation: "Quadratic memory from copies"
      fix: "Immutable/persistent structures"

  # ---------------------------------------------------------------------------
  # Bitmask DP Traps (6 types)
  # ---------------------------------------------------------------------------
  bitmask_traps:
    unnecessary_bitmask:
      trap_id: "BM001"
      name: "Bitmask When Simpler Suffices"
      description: "Using bitmask when count suffices"
      example: |
        # Tracking which items selected with bitmask
        # When only count matters
        # 2^n vs n states
      detection_difficulty: "medium"
      manifestation: "Exponential instead of polynomial"
      fix: "Use count instead of mask"
      
    redundant_bits:
      trap_id: "BM002"
      name: "Redundant Bits in Mask"
      description: "Mask includes derivable information"
      example: |
        # Mask for items + mask for capacities
        # Capacities derivable from items
      detection_difficulty: "medium"
      manifestation: "Squared exponential states"
      fix: "Derive redundant information"
      
    ordering_in_mask:
      trap_id: "BM003"
      name: "Order Encoded in Bitmask"
      description: "Using ordered structure when set suffices"
      example: |
        # List [1,2,3] vs [2,1,3] vs [3,2,1]
        # When only set {1,2,3} matters
      detection_difficulty: "medium"
      manifestation: "Factorial explosion"
      fix: "Use set representation"
      
    too_many_bits:
      trap_id: "BM004"
      name: "Too Many Bits in Mask"
      description: "Bitmask exceeds practical limits"
      example: |
        # 30 items = 2^30 = 1 billion states
        # 40 items = 2^40 = 1 trillion states
      detection_difficulty: "easy"
      manifestation: "Impractical state count"
      fix: "Different algorithmic approach"
      
    subset_iteration:
      trap_id: "BM005"
      name: "Inefficient Subset Iteration"
      description: "Iterating all subsets of a mask"
      example: |
        # For each mask, iterate all 2^popcount(mask) subsets
        # Total 3^n iterations
      detection_difficulty: "hard"
      manifestation: "O(3^n) complexity"
      fix: "Use SOS DP or smarter iteration"
      
    profile_dp_explosion:
      trap_id: "BM006"
      name: "Profile DP State Explosion"
      description: "Profile/broken profile with too many states"
      example: |
        # Profile DP on wide grid
        # 2^width states per row
      detection_difficulty: "medium"
      manifestation: "Exponential in width"
      fix: "Rotate grid or different approach"

# =============================================================================
# EDGE CASE CATALOG
# =============================================================================

edge_cases:
  size_edge_cases:
    - empty_input
    - single_element
    - two_elements
    - small_input_under_10
    - medium_input_100_1000
    - large_input_over_10000
    - maximum_input_size
    - power_of_two_sizes
    - prime_number_sizes

  constraint_edge_cases:
    - zero_capacity
    - infinite_capacity
    - capacity_equals_total
    - no_valid_selections
    - all_selections_valid
    - exactly_one_solution
    - many_optimal_solutions
    - tight_constraints
    - loose_constraints

  value_edge_cases:
    - all_zeros
    - all_ones
    - all_same_value
    - strictly_increasing
    - strictly_decreasing
    - negative_values
    - very_large_values
    - floating_point_values
    - mixed_signs

  structure_edge_cases:
    - linear_dependency
    - tree_dependency
    - dag_dependency
    - independent_subproblems
    - fully_dependent
    - circular_dependency_attempt

# =============================================================================
# ANTI-PATTERNS
# =============================================================================

anti_patterns:
  llm_failure_modes:
    - "Pattern matching on similar-looking problems without analyzing state structure"
    - "Applying textbook DP solutions without considering state space size"
    - "Missing opportunities for state dimension elimination"
    - "Ignoring state equivalence and canonicalization opportunities"
    - "Assuming bitmask DP is always applicable for subset problems"
    - "Skipping analysis of which state dimensions are truly necessary"
    - "Over-relying on memoization without understanding state space size"
    - "Missing meet-in-the-middle optimization opportunities"
    - "Ignoring rolling array optimization for linear dependencies"
    - "Failing to recognize coordinate compression applicability"
    - "Not considering sparse DP for low-density state spaces"
    - "Missing algebraic structure that enables matrix exponentiation"
    - "Overlooking symmetry that reduces effective state space"
    - "Failing to identify FPT structure in parameterized problems"
    - "Not recognizing when greedy subsolutions enable DP optimization"
    - "Missing opportunities for divide-and-conquer DP optimization"
    - "Ignoring Knuth's optimization for monotonic DP"
    - "Overlooking convex hull trick for linear DP optimization"
    - "Failing to apply SOS (Sum over Subsets) DP when applicable"
    - "Not recognizing profile/broken profile DP for grid problems"
    - "Missing tree decomposition opportunities for graph DP"
    - "Ignoring connection between DP and shortest paths"
    - "Failing to prove state space lower bounds to verify optimality"
    - "Not considering external memory algorithms for huge state spaces"
    - "Missing parallelization opportunities in independent subproblems"

  task_anti_patterns:
    obvious_explosion:
      description: "State space obviously huge"
      why_bad: "No analysis needed"
      
    simple_fix:
      description: "Obvious single optimization"
      why_bad: "Too easy"
      
    no_memory_constraint:
      description: "Memory not actually limited"
      why_bad: "No urgency to optimize"

# =============================================================================
# DIFFICULTY AMPLIFIERS
# =============================================================================

difficulty_amplifiers:
  nightmare:
    multiplier: 3.0
    description: "Extreme difficulty requiring expert-level multi-domain synthesis"
    requirements:
      - "7+ interacting traps across multiple domains"
      - "Requires understanding of hardware-level effects"
      - "Time estimate: 90+ minutes for senior engineers"
      - "Multiple red herrings that waste investigation time"
      - "Solution requires synthesizing knowledge from 3+ distinct areas"

  nightmare_plus:
    multiplier: 5.0
    estimated_time: [28800, 172800]  # 8-48 hours
    command_steps: [300, 1200]
    techniques_required: 12
    description: "Research paper difficulty requiring novel state space optimization"
    requirements:
      - "10+ deeply interacting traps across state representation/memory/correctness domains"
      - "Requires novel state compression or canonicalization techniques"
      - "Must synthesize knowledge from combinatorics, algebra, and algorithm design"
      - "Requires formal proof of state equivalence relations"
      - "Time estimate: 8-48 hours for competitive programmers with ICPC/IOI medal experience"
      - "Multiple state space reduction opportunities that interact non-obviously"
      - "Must discover non-trivial algebraic structure in state space"
      - "Requires FPT algorithm design for parameterized state space"
      - "Solution involves novel encoding schemes for exponential compression"

# =============================================================================
# MULTI-AGENT ORCHESTRATION COMPLEXITY
# =============================================================================

multi_agent_orchestration:
  description: "Coordinating 4-7 specialized agents for complex state space analysis"
  
  specialized_agents:
    state_space_analyzer:
      role: "Analyze and enumerate state space structure"
      capabilities:
        - "State dimension identification"
        - "Reachability analysis"
        - "State equivalence detection"
        - "Symmetry identification"
      handoff_triggers:
        - "State space appears larger than necessary"
        - "Memory limits exceeded"
    
    compression_specialist:
      role: "Design state compression schemes"
      capabilities:
        - "Coordinate compression techniques"
        - "Rolling array optimization"
        - "Bitmask state encoding"
        - "Meet-in-the-middle decomposition"
      handoff_triggers:
        - "Exponential state space identified"
        - "Memory optimization needed"
    
    algebraic_analyzer:
      role: "Find algebraic structure for optimization"
      capabilities:
        - "Group-theoretic symmetry detection"
        - "Polynomial identity testing for states"
        - "Linear algebra state representation"
        - "Generating function analysis"
      handoff_triggers:
        - "Symmetry suspected in state space"
        - "Counting problem structure"
    
    fpt_designer:
      role: "Design fixed-parameter tractable algorithms"
      capabilities:
        - "Parameter identification"
        - "Bounded search tree techniques"
        - "Kernelization"
        - "Color-coding technique"
      handoff_triggers:
        - "Problem is NP-hard but may be FPT"
        - "Relevant parameter identified"
    
    memory_optimizer:
      role: "Optimize memory usage of DP solution"
      capabilities:
        - "Space-time tradeoff analysis"
        - "Cache-friendly state ordering"
        - "Sparse state representation"
        - "External memory algorithms"
      handoff_triggers:
        - "Memory usage exceeds limits"
        - "Cache performance issues"

  cross_algorithm_attack_chains:
    chain_1:
      name: "Redundant Dimension → State Explosion → OOM → Computation Failure"
      stages:
        - "State includes unnecessary information"
        - "State space grows exponentially"
        - "Memory allocation fails"
        - "DP cannot complete"
    
    chain_2:
      name: "Missing Equivalence → Duplicate States → Wasted Work → Timeout"
      stages:
        - "Equivalent states not recognized"
        - "Same subproblem solved multiple times"
        - "Time complexity multiplied"
        - "Algorithm exceeds time limit"
    
    chain_3:
      name: "Wrong Order → Dependency Violation → Incorrect Values → Wrong Answer"
      stages:
        - "States computed in wrong order"
        - "Dependencies not satisfied"
        - "DP values computed from uninitialized states"
        - "Final answer is incorrect"

# =============================================================================
# THEORETICAL COMPLEXITY REQUIREMENTS
# =============================================================================

theoretical_complexity_requirements:
  amortized_analysis:
    techniques_required:
      - "Aggregate method for state transitions"
      - "Potential method for lazy state computation"
      - "Accounting for sparse state access"
    application_scenarios:
      - "DP with sparse state access patterns"
      - "Lazy evaluation of states"

  parameterized_complexity:
    concepts_required:
      - "Fixed-parameter tractability (FPT)"
      - "Treewidth and pathwidth"
      - "Kernelization lower bounds"
      - "Color-coding technique"
    application_scenarios:
      - "DP on graphs with bounded treewidth"
      - "Subset sum variants"
      - "Steiner tree problems"

  algebraic_techniques:
    concepts:
      - "Group-theoretic enumeration"
      - "Burnside's lemma for symmetry"
      - "Generating functions for counting"
      - "Matrix exponentiation for recurrences"
    applications:
      - "Counting distinct configurations up to symmetry"
      - "Linear recurrence with O(log n) matrix power"
      - "Polynomial multiplication for convolution DP"

  compression_theory:
    concepts:
      - "Information-theoretic lower bounds on state"
      - "Succinct data structures"
      - "Rank/select for implicit state"
    techniques:
      - "Coordinate compression"
      - "Implicit state representation"
      - "Succinct encoding schemes"

# =============================================================================
# ADVERSARIAL INPUT DESIGN
# =============================================================================

adversarial_input_design:
  worst_case_input_generation:
    state_maximizers:
      description: "Inputs causing maximum distinct states"
      technique: "Ensure all state dimensions are fully utilized"
      
    memory_exhaustion:
      description: "Inputs causing OOM before completion"
      technique: "Input size just exceeding memory capacity"
      
    timeout_triggers:
      description: "Inputs causing exponential state exploration"
      technique: "Ensure no early termination possible"

  anti_optimization_inputs:
    anti_pruning:
      description: "Inputs defeating pruning heuristics"
      technique: "All states have equal potential"
    
    anti_symmetry:
      description: "Inputs with no exploitable symmetry"
      technique: "Asymmetric structure"
    
    dense_transitions:
      description: "Inputs with maximum transition density"
      technique: "Every state transition is valid"

# =============================================================================
# FORMAL PROOF REQUIREMENTS
# =============================================================================

formal_proof_requirements:
  correctness_proofs:
    state_equivalence:
      requirements:
        - "Prove equivalence relation is well-defined"
        - "Prove equivalence preserves optimal substructure"
        - "Prove canonicalization is consistent"
      
    completeness:
      requirements:
        - "Prove all necessary states are explored"
        - "Prove pruned states cannot affect optimum"
        - "Prove state transition coverage"
      
    optimality:
      requirements:
        - "Prove solution is globally optimal"
        - "Prove state compression preserves optimality"
        - "Prove no better solution exists in pruned space"

  complexity_proofs:
    state_space_bounds:
      requirements:
        - "Prove upper bound on distinct states"
        - "Prove tightness with matching lower bound"
        - "Prove memory usage bounds"
      
    time_complexity:
      requirements:
        - "Prove transition time bounds"
        - "Prove total computation bound"
        - "Analyze cache complexity"

  optimization_amplifiers:
    multiple_issues:
      description: "Multiple state explosion causes"
      amplification: "Must fix all issues"
      
    correctness_critical:
      description: "Optimization must preserve correctness"
      amplification: "Can't use approximations"
      
    time_constraint:
      description: "Must also meet time constraint"
      amplification: "Balance space and time"

  analysis_amplifiers:
    hidden_redundancy:
      description: "State redundancy not obvious"
      amplification: "Must discover equivalences"
      
    interacting_dimensions:
      description: "Dimensions interact non-obviously"
      amplification: "Can't reduce independently"

# =============================================================================
# VARIATION ENGINES
# =============================================================================

variation_engines:
  problem_type_variations:
    reduce_dimensions:
      description: "Eliminate unnecessary dimensions"
      
    compress_ranges:
      description: "Compress dimension ranges"
      
    merge_states:
      description: "Merge equivalent states"
      
    prune_unreachable:
      description: "Prune unreachable states"

  domain_variations:
    scheduling:
      context: "Job scheduling with resources"
      
    knapsack:
      context: "Multi-constraint knapsack"
      
    sequence:
      context: "Sequence optimization"
      
    graph:
      context: "Graph DP with constraints"

# =============================================================================
# SWE-bench_Pro style fields
# =============================================================================

problem_statement: |
  A dynamic programming solution for a scheduling optimization problem is running 
  out of memory on production inputs. The algorithm is correct but the state space 
  grows exponentially, causing OOM errors.
  
  Hidden complexity factors:
  1. The DP state includes unnecessary dimensions
  2. States that appear different are actually equivalent
  3. Many unreachable states are being computed
  4. The recurrence relation can be simplified

requirements: |
  - Analyze and reduce the DP state space
  - Identify and eliminate redundant state dimensions
  - Implement state equivalence compression
  - Add pruning for unreachable states
  - Maintain solution correctness while reducing memory

interface: |
  Input: List of tasks with (duration, deadline, profit)
  Output: Maximum profit achievable, selected task indices
  Constraint: Memory usage must stay under 1GB for 1000 tasks

difficulty:
  estimated: "nightmare_plus"
  time_range: [5400, 18000]  # 90-300 minutes for competitive programmers with ICPC/IOI medal experience
  command_steps: [60, 200]
  techniques_required: 12
  trap_count: "10+ deeply interacting traps across correctness/performance/edge-case domains"
  target_audience: "Competitive programmers with ICPC/IOI medal experience"

traps:
  - type: "unnecessary_dimensions"
    description: "State tracks order of selection when only set matters"
    trigger: "Including permutation info in state"
  
  - type: "equivalent_states"
    description: "Different paths to same state are not recognized"
    trigger: "Not canonicalizing state representation"
  
  - type: "unreachable_states"
    description: "Computing states that violate constraints"
    trigger: "Not pruning invalid states early"
  
  - type: "suboptimal_recurrence"
    description: "Recurrence computes more than necessary"
    trigger: "Not recognizing simpler formulation"

  - type: "exponential_bitmask"
    description: "Using bitmask DP when count suffices, causing 2^n instead of O(n) states"
    trigger: "Tracking which items selected when only count matters"

  - type: "redundant_computed_dimension"
    description: "State includes dimension derivable from others"
    trigger: "Storing total_value when computable from selected items"

  - type: "missing_coordinate_compression"
    description: "Using full value range when only O(n) distinct values exist"
    trigger: "Not compressing coordinate space"

  - type: "wrong_iteration_order"
    description: "Computing states in wrong order causing dependency violations"
    trigger: "Not analyzing DAG structure of dependencies"

  - type: "missing_rolling_array"
    description: "Storing all DP layers when only previous layer needed"
    trigger: "Not recognizing linear dependency structure"

  - type: "factorial_permutation_state"
    description: "Tracking permutation order when subset suffices"
    trigger: "n! states instead of 2^n by unnecessary ordering"

  - type: "missed_algebraic_structure"
    description: "Not recognizing matrix exponentiation opportunity"
    trigger: "Linear recurrence solved iteratively instead of O(log n)"

instruction_template: |
  You are optimizing a {{ scenario_type }} DP algorithm.
  The code is at {{ path }}.
  
  The algorithm runs out of memory on large inputs. Your task:
  {{ task_steps }}
  
  Problem size: {{ task_count }} tasks
  Memory limit: {{ memory_limit_mb }} MB
  Current memory usage: {{ current_memory_mb }} MB (exceeds limit)

reference_solution: |
  #!/usr/bin/env python3
  from typing import List, Tuple, Dict
  from dataclasses import dataclass
  
  @dataclass(frozen=True)
  class Task:
      id: int
      duration: int
      deadline: int
      profit: int
  
  def schedule_tasks_optimized(tasks: List[Task]) -> Tuple[int, List[int]]:
      n = len(tasks)
      if n <= 20:
          return _bitmask_dp(tasks)
      else:
          return _memory_efficient_dp(tasks)
  
  def _bitmask_dp(tasks: List[Task]) -> Tuple[int, List[int]]:
      n = len(tasks)
      sorted_tasks = sorted(enumerate(tasks), key=lambda x: x[1].deadline)
      dp = {(0, 0): (0, [])}
      max_deadline = max(t.deadline for t in tasks)
      
      for time in range(max_deadline + 1):
          new_states = {}
          for (t, mask), (profit, selected) in dp.items():
              if t != time:
                  continue
              key = (t, mask)
              if key not in new_states or new_states[key][0] < profit:
                  new_states[key] = (profit, selected)
              for idx, task in sorted_tasks:
                  if mask & (1 << idx):
                      continue
                  new_time = time + task.duration
                  if new_time <= task.deadline:
                      new_mask = mask | (1 << idx)
                      new_profit = profit + task.profit
                      new_selected = selected + [task.id]
                      key = (new_time, new_mask)
                      if key not in new_states or new_states[key][0] < new_profit:
                          new_states[key] = (new_profit, new_selected)
          dp.update(new_states)
      
      best_profit, best_selected = 0, []
      for (t, mask), (profit, selected) in dp.items():
          if profit > best_profit:
              best_profit, best_selected = profit, selected
      return best_profit, best_selected
  
  def _memory_efficient_dp(tasks: List[Task]) -> Tuple[int, List[int]]:
      max_deadline = max(t.deadline for t in tasks)
      dp = {0: (0, -1, -1)}
      sorted_tasks = sorted(
          enumerate(tasks), 
          key=lambda x: x[1].profit / x[1].duration,
          reverse=True
      )
      
      for idx, task in sorted_tasks:
          new_dp = dict(dp)
          for d in range(task.duration, task.deadline + 1):
              prev_d = d - task.duration
              if prev_d in dp:
                  new_profit = dp[prev_d][0] + task.profit
                  if d not in new_dp or new_dp[d][0] < new_profit:
                      new_dp[d] = (new_profit, idx, prev_d)
          dp = new_dp
      
      best_d = max(dp.keys(), key=lambda d: dp[d][0])
      best_profit = dp[best_d][0]
      selected = []
      d = best_d
      while d > 0 and dp[d][1] >= 0:
          selected.append(tasks[dp[d][1]].id)
          d = dp[d][2]
      
      return best_profit, selected[::-1]

fail_to_pass:
  - "test_large_input_memory"
  - "test_state_space_reduction"
  - "test_equivalent_state_merging"
  - "test_1000_tasks_under_1gb"

pass_to_pass:
  - "test_basic_scheduling"
  - "test_empty_input"
  - "test_single_task"

variables:
  - name: scenario_type
    type: string
    options: ["job scheduling", "resource allocation", "task optimization", "project planning"]
  - name: path
    type: path
    generator: random_path
  - name: task_count
    type: int
    min: 100
    max: 1000
  - name: memory_limit_mb
    type: int
    min: 512
    max: 1024
  - name: current_memory_mb
    type: int
    min: 2000
    max: 8000
  - name: task_steps
    type: template
    value: |
      1. Analyze current state space complexity
      2. Identify redundant state dimensions
      3. Implement state canonicalization
      4. Add pruning for unreachable states
      5. Verify memory usage stays under limit
      6. Ensure solution correctness is maintained

anti_hardcoding:
  canary_tokens: true
  randomize_paths: true
  dynamic_content: true
  explosion_causes:
    - permutation_in_state
    - duplicate_equivalent_states
    - no_pruning
    - suboptimal_recurrence

generation_targets:
  unique_tasks: 10000
  minimum_difficulty: "experienced developer needs 30+ minutes, requires deep domain expertise"
  trap_coverage: "all trap types used at least 100 times"

# =============================================================================
# ADDITIONAL STATE EXPLOSION PATTERNS
# =============================================================================

additional_explosion_patterns:
  # ---------------------------------------------------------------------------
  # DP Optimization Techniques (Comprehensive)
  # ---------------------------------------------------------------------------
  optimization_techniques:
    rolling_array:
      description: "Use O(k) space instead of O(n) when only k previous rows needed"
      applicable_when:
        - "dp[i] depends only on dp[i-1]"
        - "dp[i][j] depends only on dp[i-1][*]"
        - "Fixed window of previous states needed"
      implementation:
        python: "Use modulo indexing: dp[i % 2] instead of dp[i]"
        cpp: "std::array<std::vector<int>, 2> for alternating rows"
      memory_reduction: "O(n) to O(1) or O(n²) to O(n)"
      
    coordinate_compression:
      description: "Map sparse values to dense indices"
      applicable_when:
        - "State values are sparse in large range"
        - "Only relative order matters"
        - "Values can be discretized"
      implementation:
        python: "sorted(set(values)), then bisect for mapping"
        cpp: "std::sort + std::unique + std::lower_bound"
      memory_reduction: "O(max_value) to O(distinct_values)"
      
    meet_in_middle:
      description: "Split problem, solve halves, combine"
      applicable_when:
        - "Exponential in n, but manageable in n/2"
        - "Solutions can be combined efficiently"
        - "2^(n/2) is acceptable"
      memory_reduction: "O(2^n) to O(2^(n/2))"
      
    lazy_evaluation:
      description: "Compute states only when accessed"
      applicable_when:
        - "Many states never accessed"
        - "Access pattern unpredictable"
        - "Can afford computation on access"
      memory_reduction: "O(total_states) to O(accessed_states)"
      
    matrix_exponentiation:
      description: "Convert linear recurrence to matrix form"
      applicable_when:
        - "Linear recurrence relation"
        - "Need very large index"
        - "State size is small"
      memory_reduction: "O(n) to O(state_size²)"
      time_reduction: "O(n) to O(state_size³ * log n)"

  # ---------------------------------------------------------------------------
  # Common DP State Compression Patterns
  # ---------------------------------------------------------------------------
  compression_patterns:
    bitmask_to_popcount:
      description: "When only count matters, not which items"
      before: "dp[mask] for all 2^n subsets"
      after: "dp[count] for 0 to n"
      reduction: "Exponential to linear"
      
    permutation_to_set:
      description: "When order doesn't matter"
      before: "dp[permutation] for all n! orderings"
      after: "dp[set] for all 2^n subsets"
      reduction: "Factorial to exponential"
      
    set_to_count:
      description: "When only cardinality matters"
      before: "dp[set] for all subsets"
      after: "dp[size] for 0 to n"
      reduction: "Exponential to linear"
      
    path_to_endpoint:
      description: "When only current position matters"
      before: "dp[full_path]"
      after: "dp[current_position]"
      reduction: "Factorial to polynomial"
      
    tree_to_depth:
      description: "When only depth matters, not structure"
      before: "dp[tree_structure]"
      after: "dp[depth]"
      reduction: "Catalan to linear"

  # ---------------------------------------------------------------------------
  # State Explosion Detection Heuristics
  # ---------------------------------------------------------------------------
  detection_heuristics:
    suspicious_patterns:
      - "State contains list/array that grows with input"
      - "State contains tuple of all previous decisions"
      - "State space product of all dimensions is huge"
      - "Bitmask with n > 20"
      - "Multiple nested for loops in state transition"
      
    warning_signs:
      - "Memory usage grows faster than expected"
      - "Timeout on small-looking inputs"
      - "Exponential growth in profile"
      - "Same subproblem solved many times"
      
    analysis_steps:
      step_1: "Identify all state dimensions"
      step_2: "Calculate theoretical state count"
      step_3: "Check which dimensions are necessary"
      step_4: "Look for equivalent states"
      step_5: "Identify unreachable states"

  # ---------------------------------------------------------------------------
  # Memory Profiling for State Explosion
  # ---------------------------------------------------------------------------
  profiling_techniques:
    python:
      memory_profiler: "from memory_profiler import profile"
      tracemalloc: "tracemalloc.start(); tracemalloc.get_traced_memory()"
      sys_getsizeof: "sys.getsizeof(obj) for individual objects"
      objgraph: "objgraph.show_most_common_types() for type distribution"
      
    cpp:
      valgrind: "valgrind --tool=massif ./program"
      heaptrack: "heaptrack ./program"
      address_sanitizer: "compile with -fsanitize=address"
      
    java:
      jvisualvm: "Visual memory profiler"
      jmap: "jmap -histo:live <pid>"
      jprofiler: "Commercial profiler"
      
    common_metrics:
      - "Peak memory usage"
      - "Memory growth rate"
      - "Object count by type"
      - "Allocation hotspots"

# =============================================================================
# TASK COMBINATION MATRIX
# =============================================================================

combination_matrix:
  primary_explosion_cause:
    method: "Select 1-2 primary causes from trap_taxonomy"
    options:
      - unnecessary_dimensions
      - unreachable_states
      - suboptimal_recurrence
      - memory_allocation
      - bitmask_traps
    diversity_requirement: "Must not repeat within 100 generated tasks"
    
  secondary_issues:
    method: "Select 2-3 secondary issues that compound difficulty"
    examples:
      - "Unnecessary dimension + memory allocation issue"
      - "Bitmask explosion + no pruning"
      - "Equivalent states + wrong recurrence"
    
  optimization_required:
    method: "Select technique needed to solve"
    options:
      - rolling_array
      - coordinate_compression
      - meet_in_middle
      - state_canonicalization
      - dimension_elimination
    
  domain_selection:
    method: "Select realistic domain from domains"
    realism_requirement: "Context must be believable"
    
  difficulty_tuning:
    easy_mode: "Single obvious explosion cause"
    medium_mode: "Two interacting causes"
    hard_mode: "Multiple causes, non-obvious solution"
    expert_mode: "Requires advanced technique like meet-in-middle"

# =============================================================================
# EXTENDED EDGE CASES
# =============================================================================

extended_edge_cases:
  extreme_size_cases:
    - n_equals_0_empty
    - n_equals_1_trivial
    - n_equals_2_minimum_interesting
    - n_at_bitmask_limit_20
    - n_just_over_bitmask_limit_21
    - n_at_meet_in_middle_limit_40
    - n_requiring_polynomial_solution_1000
    - n_requiring_linear_solution_1000000
    
  state_space_boundary_cases:
    - exactly_at_memory_limit
    - just_over_memory_limit
    - exponential_but_fits
    - polynomial_but_large_constant
    - sparse_states_in_huge_space
    
  optimization_trigger_cases:
    - rolling_array_applicable
    - coordinate_compression_needed
    - meet_in_middle_required
    - matrix_exponentiation_optimal
    - no_optimization_needed
    
  correctness_critical_cases:
    - single_optimal_solution
    - multiple_optimal_solutions
    - no_feasible_solution
    - all_solutions_equivalent
    - optimal_at_boundary
