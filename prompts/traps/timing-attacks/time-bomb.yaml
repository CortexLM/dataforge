id: "trap-timing-time-bomb-001"
version: "1.0.0"
category: "traps"
subcategory: "timing-attacks"

# === LLM GENERATION FRAMEWORK ===
generation_framework:
  multi_conversation_workflow:
    phase_1_research: "Research LLM blind spots around time-based code patterns and common failure modes"
    phase_2_creation: "Create task that exploits LLM reasoning weaknesses about temporal logic"
    phase_3_amplification: "Add multiple layers of deception with misleading timestamps and date calculations"
    phase_4_verification: "Validate task successfully traps most LLMs through timing-based deceptions"
  
  llm_trap_design:
    common_llm_weaknesses:
      - "Pattern matching without understanding time semantics"
      - "Assuming standard date/time behavior across all systems"
      - "Missing edge cases in date boundary reasoning"
      - "Over-reliance on training data patterns for time functions"
      - "Difficulty with adversarial time inputs and manipulated clocks"
      - "Inability to reason about real-time elapsed duration"
      - "Confusion between different time representations"
      - "Failure to consider timezone and locale impacts"

# === TIME BOMB TRAP TAXONOMY ===
trap_taxonomy:
  category: "timing-attacks"
  trap_type: "time-bomb"
  description: "Code containing time-based triggers that activate at specific moments or after specific durations"
  
  trap_families:
    - family: "date_boundary_bombs"
      description: "Traps that activate at date boundaries"
      difficulty_range: [3, 10]
      
    - family: "duration_bombs"
      description: "Traps that activate after specific uptime or elapsed time"
      difficulty_range: [4, 10]
      
    - family: "license_expiration_bombs"
      description: "Hidden license/trial checks that silently degrade functionality"
      difficulty_range: [5, 10]
      
    - family: "timezone_bombs"
      description: "Traps that exploit timezone handling vulnerabilities"
      difficulty_range: [4, 9]
      
    - family: "precision_bombs"
      description: "Traps that exploit timer precision and resolution issues"
      difficulty_range: [6, 10]
      
    - family: "calendar_bombs"
      description: "Traps that exploit calendar calculation edge cases"
      difficulty_range: [5, 10]
      
    - family: "synchronization_bombs"
      description: "Traps that exploit clock synchronization issues"
      difficulty_range: [7, 10]

# === LLM WEAKNESS EXPLOITATION TECHNIQUES ===
llm_weakness_exploitation:
  timing_trap_techniques:
    # Date/Time Boundary Exploitation (30+ techniques)
    date_boundary_exploits:
      - technique: "y2k38_overflow"
        description: "32-bit Unix timestamp overflow on 2038-01-19 03:14:07 UTC"
        llm_failure_mode: "LLM assumes 64-bit timestamps everywhere"
        implementation: |
          def check_timestamp(ts):
              # LLM often misses this will fail on 32-bit systems after 2038
              return ts < 2147483647
        difficulty: 7
        
      - technique: "y2k_style_bug"
        description: "Two-digit year assumptions causing century rollover issues"
        llm_failure_mode: "LLM assumes all systems use 4-digit years"
        implementation: |
          def parse_year(year_str):
              year = int(year_str)
              if year < 100:
                  # LLM misses ambiguity: is 23 -> 1923 or 2023?
                  return year + 1900 if year > 50 else year + 2000
        difficulty: 5
        
      - technique: "leap_second_handling"
        description: "Leap second insertion causes 61-second minute"
        llm_failure_mode: "LLM assumes minutes always have 60 seconds"
        implementation: |
          def validate_time(hour, minute, second):
              # LLM misses leap second: 23:59:60 is valid on leap second days
              return 0 <= second < 60  # BUG: should be <= 60 for leap seconds
        difficulty: 8
        
      - technique: "leap_year_feb29"
        description: "February 29 causes crashes on non-leap years"
        llm_failure_mode: "LLM often uses simple year % 4 check"
        implementation: |
          def is_leap_year(year):
              # LLM often misses: 1900 is not a leap year, 2000 is
              return year % 4 == 0  # BUG: doesn't handle century rule
        difficulty: 4
        
      - technique: "month_day_overflow"
        description: "Adding months doesn't account for day overflow"
        llm_failure_mode: "LLM assumes month arithmetic is straightforward"
        implementation: |
          def add_months(date, months):
              new_month = date.month + months
              # LLM misses: Jan 31 + 1 month = Feb 31 doesn't exist
              return date.replace(month=new_month)  # Crashes on day overflow
        difficulty: 6
        
      - technique: "year_boundary_midnight"
        description: "New Year's midnight edge case"
        llm_failure_mode: "LLM misses midnight belonging to next day"
        implementation: |
          def is_same_year(dt1, dt2):
              # LLM misses: 2024-01-01 00:00:00 vs 2023-12-31 23:59:59
              return dt1.year == dt2.year  # Misleading for midnight
        difficulty: 5
        
      - technique: "dst_spring_forward"
        description: "2:30 AM doesn't exist during DST spring forward"
        llm_failure_mode: "LLM assumes all times exist in all timezones"
        implementation: |
          def schedule_at(timezone, hour, minute):
              # LLM misses: 2:30 AM doesn't exist on DST transition day
              return datetime(2024, 3, 10, hour, minute, tzinfo=timezone)
        difficulty: 7
        
      - technique: "dst_fall_back"
        description: "1:30 AM exists twice during DST fall back"
        llm_failure_mode: "LLM assumes times are unambiguous"
        implementation: |
          def unique_timestamp(timezone, dt):
              # LLM misses: 1:30 AM occurs twice on DST fall back
              return dt.isoformat()  # Ambiguous without fold info
        difficulty: 7
        
      - technique: "week_number_boundary"
        description: "ISO week numbers don't align with calendar year"
        llm_failure_mode: "LLM assumes week 1 starts January 1"
        implementation: |
          def get_year_from_week(week_num, year):
              # LLM misses: ISO week 1 of 2024 includes days from 2023
              return year  # Wrong for dates in first week
        difficulty: 6
        
      - technique: "fiscal_year_mismatch"
        description: "Fiscal year doesn't match calendar year"
        llm_failure_mode: "LLM assumes fiscal = calendar year"
        implementation: |
          def get_fiscal_year(date):
              # LLM misses: fiscal year might start in July, October, etc.
              return date.year
        difficulty: 5

    # Timer and Duration Exploitation (30+ techniques)
    timer_duration_exploits:
      - technique: "32bit_millisecond_overflow"
        description: "32-bit millisecond counter overflows after ~49.7 days"
        llm_failure_mode: "LLM doesn't calculate overflow timing"
        implementation: |
          def get_uptime_ms():
              # LLM misses: overflows at 2^32-1 ms = 49.71 days
              return ctypes.c_uint32(time.time() * 1000).value
        difficulty: 6
        
      - technique: "32bit_microsecond_overflow"
        description: "32-bit microsecond counter overflows after ~71 minutes"
        llm_failure_mode: "LLM often overlooks short overflow windows"
        implementation: |
          def get_precise_time_us():
              # LLM misses: overflows after only 71 minutes!
              return ctypes.c_uint32(time.perf_counter() * 1000000).value
        difficulty: 7
        
      - technique: "monotonic_vs_wall_clock"
        description: "Monotonic time unaffected by NTP, wall clock is"
        llm_failure_mode: "LLM conflates different clock types"
        implementation: |
          def measure_duration():
              start = time.time()  # BUG: should use monotonic
              do_work()
              # LLM misses: NTP adjustment can make duration negative
              return time.time() - start
        difficulty: 6
        
      - technique: "sleep_precision_loss"
        description: "sleep() has limited precision, may sleep longer"
        llm_failure_mode: "LLM assumes sleep is exact"
        implementation: |
          def rate_limit(requests_per_second):
              for _ in range(requests_per_second):
                  process()
                  # LLM misses: sleep(0.001) often sleeps 10-15ms
                  time.sleep(1.0 / requests_per_second)
        difficulty: 5
        
      - technique: "timer_resolution_variability"
        description: "System timer resolution varies by platform"
        llm_failure_mode: "LLM assumes consistent timer resolution"
        implementation: |
          def check_interval():
              # LLM misses: Windows default timer is ~15.6ms resolution
              return time.time()  # May not detect sub-16ms events
        difficulty: 6
        
      - technique: "accumulated_drift"
        description: "Repeated small sleeps accumulate timing drift"
        llm_failure_mode: "LLM misses cumulative error"
        implementation: |
          def periodic_task(interval_ms, duration_hours):
              iterations = (duration_hours * 3600 * 1000) // interval_ms
              for _ in range(iterations):
                  do_task()
                  # LLM misses: 0.1ms drift per iteration = 36s drift/hour
                  time.sleep(interval_ms / 1000)
        difficulty: 6
        
      - technique: "negative_duration"
        description: "Clock adjustment causes negative elapsed time"
        llm_failure_mode: "LLM assumes time always moves forward"
        implementation: |
          def measure_operation():
              start = time.time()
              do_operation()
              duration = time.time() - start
              # LLM misses: duration can be negative after NTP step
              assert duration >= 0  # Can fail!
        difficulty: 7
        
      - technique: "scheduler_preemption"
        description: "OS scheduler can preempt timing-critical code"
        llm_failure_mode: "LLM assumes continuous execution"
        implementation: |
          def timing_attack_vulnerable():
              start = time.perf_counter()
              if secret_check():
                  do_short_operation()
              else:
                  do_long_operation()
              # LLM misses: scheduler preemption adds noise
              return time.perf_counter() - start
        difficulty: 8
        
      - technique: "gc_pause_timing"
        description: "Garbage collection pauses affect timing"
        llm_failure_mode: "LLM forgets about GC in managed languages"
        implementation: |
          def real_time_critical():
              # LLM misses: Python GC can pause for 10-100ms
              return process_frame()
        difficulty: 6
        
      - technique: "virtualization_timing"
        description: "VM hypervisor affects timing accuracy"
        llm_failure_mode: "LLM assumes native timing in VMs"
        implementation: |
          def measure_cpu_cycles():
              # LLM misses: RDTSC in VM is often emulated/inaccurate
              return get_cpu_cycles()
        difficulty: 8

    # License/Expiration Exploitation (25+ techniques)
    license_expiration_exploits:
      - technique: "hidden_trial_expiration"
        description: "Trial period check hidden in innocuous-looking code"
        llm_failure_mode: "LLM misses obfuscated date comparisons"
        implementation: |
          def initialize_system():
              config = load_config()
              # Hidden: 'validation' is actually license check
              if not validate_system_state():
                  config['features']['advanced'] = False  # Silently disabled
              return config
        difficulty: 7
        
      - technique: "install_date_check"
        description: "Compares current date to hidden install date"
        llm_failure_mode: "LLM doesn't trace data flow to file timestamps"
        implementation: |
          def check_system_health():
              # LLM misses: this is comparing to installation date
              return (time.time() - os.path.getctime(__file__)) < 2592000
        difficulty: 6
        
      - technique: "build_timestamp_expiry"
        description: "Compiled-in timestamp expires after N days"
        llm_failure_mode: "LLM doesn't check compiled constants"
        implementation: |
          BUILD_TIME = 1704067200  # Hidden: 2024-01-01
          MAX_AGE = 31536000  # 1 year in seconds
          def is_valid():
              return time.time() < BUILD_TIME + MAX_AGE
        difficulty: 6
        
      - technique: "config_based_expiry"
        description: "Expiry date hidden in config with misleading name"
        llm_failure_mode: "LLM trusts config key names"
        implementation: |
          # config.yaml
          # system_optimization_threshold: "2024-12-31"  # Actually expiry
          def load_settings():
              if datetime.now() > parse(config['system_optimization_threshold']):
                  enable_optimization = False  # Silent degradation
        difficulty: 7
        
      - technique: "certificate_date_check"
        description: "Uses certificate validity as license proxy"
        llm_failure_mode: "LLM doesn't connect cert validity to licensing"
        implementation: |
          def verify_license():
              cert = load_embedded_cert()
              # LLM misses: cert expiry IS the license expiry
              return cert.not_valid_after > datetime.utcnow()
        difficulty: 7
        
      - technique: "counter_based_expiry"
        description: "Expires after N operations, not time"
        llm_failure_mode: "LLM looks for date checks, misses counters"
        implementation: |
          _operation_count = 0
          def perform_operation():
              global _operation_count
              _operation_count += 1
              # LLM misses: hidden limit
              if _operation_count > 10000:
                  raise RuntimeError("System limit exceeded")
        difficulty: 5
        
      - technique: "network_time_validation"
        description: "Fetches time from server to prevent clock manipulation"
        llm_failure_mode: "LLM doesn't trace network calls to time validation"
        implementation: |
          def validate_timestamp():
              # LLM misses: this fetches real time to prevent clock changes
              server_time = requests.get('https://api.time.com/now').json()
              return server_time['timestamp']
        difficulty: 6
        
      - technique: "degraded_performance_expiry"
        description: "Gradually slows down as expiry approaches"
        llm_failure_mode: "LLM misses performance degradation patterns"
        implementation: |
          def process_request():
              days_since_install = (time.time() - INSTALL_TIME) / 86400
              # LLM misses: artificial delay increases over time
              time.sleep(max(0, (days_since_install - 30) * 0.01))
              return do_work()
        difficulty: 8
        
      - technique: "feature_flag_timeout"
        description: "Feature flags have hidden timeout"
        llm_failure_mode: "LLM trusts feature flag structure"
        implementation: |
          FEATURES = {
              'advanced_mode': {
                  'enabled': True,
                  'metadata': {'activation': 1704067200}  # Hidden timeout
              }
          }
          def is_feature_enabled(name):
              f = FEATURES[name]
              # LLM misses: metadata contains expiry
              return f['enabled'] and time.time() - f['metadata']['activation'] < 31536000
        difficulty: 7
        
      - technique: "environment_date_leak"
        description: "Uses environment variable for expiry check"
        llm_failure_mode: "LLM doesn't audit environment variables"
        implementation: |
          def startup_checks():
              # LLM misses: LICENSE_VALID_UNTIL might be set by installer
              expiry = os.environ.get('LICENSE_VALID_UNTIL', '2099-12-31')
              return datetime.now() < parse(expiry)
        difficulty: 5

    # Timezone Exploitation (25+ techniques)
    timezone_exploits:
      - technique: "utc_local_confusion"
        description: "Mixing UTC and local time without conversion"
        llm_failure_mode: "LLM doesn't track timezone context"
        implementation: |
          def schedule_meeting(utc_time):
              # LLM misses: storing UTC but displaying as local
              db.save(utc_time)
              return utc_time.strftime("%H:%M")  # Shows UTC as if local
        difficulty: 5
        
      - technique: "naive_datetime_comparison"
        description: "Comparing timezone-aware and naive datetimes"
        llm_failure_mode: "LLM misses datetime awareness"
        implementation: |
          def is_before(dt1, dt2):
              # LLM misses: comparing aware vs naive raises or gives wrong result
              return dt1 < dt2  # TypeError or wrong comparison
        difficulty: 5
        
      - technique: "timezone_abbreviation_ambiguity"
        description: "CST could be Central, China, or Cuba Standard Time"
        llm_failure_mode: "LLM assumes timezone abbreviations are unique"
        implementation: |
          def parse_timezone(tz_str):
              # LLM misses: 'CST' is ambiguous
              return pytz.timezone(tz_str)  # Which CST?
        difficulty: 6
        
      - technique: "dst_boundary_scheduling"
        description: "Scheduled task runs twice or skips during DST"
        llm_failure_mode: "LLM doesn't consider DST transitions"
        implementation: |
          def daily_job_at_2am(timezone):
              # LLM misses: 2AM happens twice in fall, never in spring
              schedule.every().day.at("02:00").do(job)
        difficulty: 7
        
      - technique: "database_timezone_mismatch"
        description: "Database stores in different timezone than app"
        llm_failure_mode: "LLM assumes consistent timezone handling"
        implementation: |
          def get_recent_records():
              now = datetime.now()  # Local time
              # LLM misses: database stores UTC
              return db.query("SELECT * WHERE created_at > ?", now)
        difficulty: 6
        
      - technique: "javascript_date_gotcha"
        description: "JavaScript Date months are 0-indexed"
        llm_failure_mode: "LLM mixes Python/JS date conventions"
        implementation: |
          // January 15, 2024
          const date = new Date(2024, 1, 15);  // BUG: This is February 15!
        difficulty: 4
        
      - technique: "historical_timezone_changes"
        description: "Timezones have changed rules historically"
        llm_failure_mode: "LLM assumes current TZ rules always applied"
        implementation: |
          def get_utc_offset(year, timezone):
              # LLM misses: Russia changed TZ rules in 2011, 2014
              return timezone.utcoffset(datetime(year, 1, 1))
        difficulty: 8
        
      - technique: "half_hour_timezone"
        description: "Some timezones have 30 or 45 minute offsets"
        llm_failure_mode: "LLM assumes all offsets are whole hours"
        implementation: |
          def round_to_hour(utc_time, offset_hours):
              # LLM misses: India is UTC+5:30, Nepal is UTC+5:45
              return utc_time + timedelta(hours=int(offset_hours))
        difficulty: 5
        
      - technique: "date_line_crossing"
        description: "Crossing International Date Line changes date"
        llm_failure_mode: "LLM forgets about date line"
        implementation: |
          def flight_duration(depart_utc, arrive_utc, depart_tz, arrive_tz):
              # LLM misses: crossing date line can make "arrive before depart" locally
              return arrive_utc - depart_utc  # Correct, but local times confusing
        difficulty: 6
        
      - technique: "timezone_database_outdated"
        description: "System timezone database may be outdated"
        llm_failure_mode: "LLM assumes timezone data is always current"
        implementation: |
          def convert_to_local(utc_time, tz_name):
              # LLM misses: pytz/tzdata may have old rules
              return utc_time.astimezone(pytz.timezone(tz_name))
        difficulty: 7

    # Clock Synchronization Exploitation (20+ techniques)
    clock_sync_exploits:
      - technique: "ntp_step_adjustment"
        description: "NTP can make large time jumps"
        llm_failure_mode: "LLM assumes smooth time progression"
        implementation: |
          def log_event():
              # LLM misses: NTP sync can cause timestamps to jump back
              return {"timestamp": time.time(), "event": "processed"}
        difficulty: 6
        
      - technique: "clock_skew_between_systems"
        description: "Different servers have slightly different times"
        llm_failure_mode: "LLM assumes synchronized clocks"
        implementation: |
          def validate_token(token, issued_at):
              # LLM misses: server B's clock might be ahead of server A
              return time.time() - issued_at < 300
        difficulty: 6
        
      - technique: "ntp_amplification_attack"
        description: "NTP can be exploited for DDoS amplification"
        llm_failure_mode: "LLM doesn't consider NTP as attack vector"
        implementation: |
          def sync_time_server():
              # LLM misses: monlist command enables amplification
              send_ntp_request('monlist')
        difficulty: 7
        
      - technique: "time_travel_attack"
        description: "Attacker manipulates system clock"
        llm_failure_mode: "LLM trusts system time"
        implementation: |
          def check_certificate_validity(cert):
              # LLM misses: attacker could set clock to past
              return cert.not_before < datetime.utcnow() < cert.not_after
        difficulty: 7
        
      - technique: "distributed_clock_ordering"
        description: "Causality violations in distributed systems"
        llm_failure_mode: "LLM assumes wall clock ordering is causal"
        implementation: |
          def determine_latest_write(events):
              # LLM misses: wall clock doesn't guarantee causal ordering
              return max(events, key=lambda e: e['timestamp'])
        difficulty: 9
        
      - technique: "vector_clock_complexity"
        description: "Logical clocks needed for correct ordering"
        llm_failure_mode: "LLM uses wall clock for distributed ordering"
        implementation: |
          def merge_databases(db1_events, db2_events):
              # LLM misses: need vector clocks for conflict resolution
              all_events = db1_events + db2_events
              return sorted(all_events, key=lambda e: e['timestamp'])
        difficulty: 9
        
      - technique: "smeared_leap_second"
        description: "Google/AWS smear leap seconds differently"
        llm_failure_mode: "LLM doesn't know about leap second smearing"
        implementation: |
          def cross_cloud_sync(aws_time, google_time):
              # LLM misses: AWS and Google handle leap seconds differently
              return abs(aws_time - google_time) < 1.0
        difficulty: 8
        
      - technique: "hardware_clock_drift"
        description: "Hardware RTC drifts without NTP"
        llm_failure_mode: "LLM assumes hardware clock is accurate"
        implementation: |
          def offline_timestamp():
              # LLM misses: without NTP, clock drifts ~20s/day
              return time.time()
        difficulty: 5

    # Precision and Resolution Exploitation (20+ techniques)
    precision_resolution_exploits:
      - technique: "floating_point_time"
        description: "Float precision loss for large timestamps"
        llm_failure_mode: "LLM assumes floats have infinite precision"
        implementation: |
          def precise_timestamp():
              # LLM misses: float loses precision at large values
              return time.time()  # Microsecond precision lost after 2001
        difficulty: 7
        
      - technique: "nanosecond_truncation"
        description: "Nanoseconds truncated to microseconds"
        llm_failure_mode: "LLM doesn't check precision limits"
        implementation: |
          def high_frequency_trading():
              # LLM misses: Python datetime only has microsecond precision
              return datetime.now()  # Nanoseconds truncated
        difficulty: 6
        
      - technique: "time_comparison_epsilon"
        description: "Direct time comparison without epsilon"
        llm_failure_mode: "LLM uses exact equality for floats"
        implementation: |
          def is_same_time(t1, t2):
              # LLM misses: floating point comparison needs epsilon
              return t1 == t2  # Almost never true
        difficulty: 5
        
      - technique: "platform_clock_resolution"
        description: "Different platforms have different clock resolution"
        llm_failure_mode: "LLM assumes uniform clock resolution"
        implementation: |
          def measure_fast_operation():
              start = time.time()
              fast_op()  # Takes 100 microseconds
              # LLM misses: Windows time.time() has 15.6ms resolution
              return time.time() - start  # Often returns 0!
        difficulty: 6
        
      - technique: "high_resolution_timer_availability"
        description: "perf_counter may not be available everywhere"
        llm_failure_mode: "LLM assumes perf_counter always exists"
        implementation: |
          def benchmark():
              # LLM misses: perf_counter added in Python 3.3
              start = time.perf_counter()
              return time.perf_counter() - start
        difficulty: 4
        
      - technique: "busy_wait_vs_sleep"
        description: "Busy wait for high precision, sleep for efficiency"
        llm_failure_mode: "LLM doesn't consider precision needs"
        implementation: |
          def delay_microseconds(us):
              # LLM misses: sleep can't achieve sub-ms precision
              time.sleep(us / 1_000_000)
        difficulty: 5

# === TRAP MECHANISMS ===
trap_mechanisms:
  activation_methods:
    - mechanism: "delayed_activation"
      description: "Trap activates after specific duration"
      variants:
        - "Activate after N days of uptime"
        - "Activate after N total operations"
        - "Activate after N unique users"
        - "Activate on Nth invocation of specific function"
        - "Activate when memory usage exceeds threshold after duration"
      detection_difficulty: 7
      
    - mechanism: "conditional_triggering"
      description: "Trap activates only under specific conditions"
      variants:
        - "Only in production environment"
        - "Only when specific user is logged in"
        - "Only on specific day of week"
        - "Only during specific hour range"
        - "Only when system load is high"
        - "Only when specific feature flag enabled"
      detection_difficulty: 8
      
    - mechanism: "counter_based_activation"
      description: "Trap tracks counters for activation"
      variants:
        - "Global operation counter"
        - "Per-user operation counter"
        - "Error counter threshold"
        - "Success rate counter"
        - "Resource usage accumulator"
      detection_difficulty: 6
      
    - mechanism: "time_based_activation"
      description: "Trap uses absolute or relative time"
      variants:
        - "After specific date"
        - "Before specific date"
        - "During specific date range"
        - "On anniversary of install"
        - "After N days since first use"
        - "On specific weekday/hour combination"
      detection_difficulty: 6
      
    - mechanism: "environment_based_activation"
      description: "Trap checks environment for activation"
      variants:
        - "Specific hostname pattern"
        - "Specific IP address range"
        - "Specific cloud provider"
        - "Specific OS version"
        - "Specific hardware signature"
        - "Specific locale/timezone"
      detection_difficulty: 7
      
    - mechanism: "cascading_failures"
      description: "Initial trap causes chain of failures"
      variants:
        - "Resource exhaustion cascade"
        - "Error propagation cascade"
        - "State corruption cascade"
        - "Deadlock cascade"
        - "Data loss cascade"
      detection_difficulty: 9
      
    - mechanism: "self_healing_trap"
      description: "Trap resets after triggering"
      variants:
        - "Clears evidence after activation"
        - "Rotates to different trigger condition"
        - "Adapts based on detection attempts"
        - "Randomizes next activation time"
      detection_difficulty: 10
      
    - mechanism: "probabilistic_activation"
      description: "Trap activates with probability"
      variants:
        - "Fixed probability per operation"
        - "Increasing probability over time"
        - "Probability based on input hash"
        - "Probability based on time seed"
      detection_difficulty: 8

# === ANTI-DETECTION TECHNIQUES ===
anti_detection_techniques:
  obfuscation_methods:
    - method: "obfuscated_trigger_conditions"
      description: "Trigger logic hidden through obfuscation"
      techniques:
        - "Date encoded as mathematical expression"
        - "Timestamp hidden in base64 string"
        - "Condition split across multiple functions"
        - "Trigger logic in dynamically loaded code"
        - "Condition encoded in configuration schema"
      example: |
        # Obfuscated: 2024-07-01 expiry
        MAGIC = 0x66A08F00  # Actually epoch timestamp
        def check(): return time.time() < MAGIC
        
    - method: "encrypted_payloads"
      description: "Trap payload encrypted until activation"
      techniques:
        - "AES encrypted trigger code"
        - "XOR encoded timestamp"
        - "Compressed and encrypted config"
        - "Key derived from system properties"
      example: |
        TRIGGER = b'gAAAAA...'  # Fernet encrypted date
        def check():
            key = derive_key(sys.platform + sys.version)
            expiry = Fernet(key).decrypt(TRIGGER)
            return time.time() < float(expiry)
        
    - method: "steganographic_hiding"
      description: "Trap data hidden in other data"
      techniques:
        - "Timestamp in image EXIF"
        - "Date in audio file metadata"
        - "Expiry in unused config fields"
        - "Trigger in comment strings"
        - "Activation code in variable names"
      example: |
        LOGO_PNG = "data:image/png;base64,..."  # Expiry in EXIF
        def check():
            exif = extract_exif(decode_base64(LOGO_PNG))
            return time.time() < exif['DateTimeOriginal']
        
    - method: "polymorphic_code"
      description: "Trap code changes each execution"
      techniques:
        - "Self-modifying check logic"
        - "Randomized function names"
        - "Dynamic code generation"
        - "JIT-compiled triggers"
      example: |
        def get_checker():
            code = generate_unique_checker()
            return compile_and_exec(code)
        
    - method: "environment_fingerprinting"
      description: "Detect analysis environment to hide"
      techniques:
        - "Detect debugger presence"
        - "Detect VM environment"
        - "Detect analysis tools"
        - "Detect test framework"
      example: |
        def should_activate():
            if 'pytest' in sys.modules: return False  # Hide in tests
            if detect_debugger(): return False
            return check_expiry()
        
    - method: "timing_based_evasion"
      description: "Avoid detection through timing tricks"
      techniques:
        - "Delay trap activation during startup"
        - "Only activate after idle period"
        - "Spread trap checks over time"
        - "Randomize check timing"
      example: |
        def slow_check():
            time.sleep(random.uniform(10, 60))  # Avoid timing analysis
            return actual_check()
        
    - method: "control_flow_obfuscation"
      description: "Hide trap in confusing control flow"
      techniques:
        - "Deep call chain to trigger"
        - "Callback-based trigger"
        - "Exception-based trigger"
        - "Signal handler trigger"
      example: |
        def innocent_function():
            try:
                risky_operation()
            except SpecificError:
                # LLM doesn't trace exception path
                check_and_trigger()
        
    - method: "data_flow_obfuscation"
      description: "Hide data flow to trigger"
      techniques:
        - "Indirect data access"
        - "Computed jump tables"
        - "Reflection-based access"
        - "Serialization-based trigger"
      example: |
        def check():
            # Data flows through deserialization
            data = pickle.loads(BLOB)
            return data['validator']()

# === LLM-SPECIFIC TRAPS ===
llm_specific_traps:
  pattern_exploitation:
    - trap: "correct_looking_incorrect_code"
      description: "Code follows common patterns but is subtly wrong"
      examples:
        - name: "inverted_comparison"
          code: |
            def is_expired(expiry_date):
                return datetime.now() > expiry_date  # Looks right
                # Trap: Should use >= or handle exact match
          llm_failure: "LLM approves common comparison pattern"
          
        - name: "wrong_epoch_base"
          code: |
            def unix_to_datetime(ts):
                return datetime(1970, 1, 1) + timedelta(seconds=ts)
                # Trap: Doesn't handle timezone
          llm_failure: "LLM recognizes epoch pattern, misses TZ issue"
          
        - name: "misleading_variable_names"
          code: |
            utc_timestamp = time.time()  # Actually local time
            def get_utc_time():
                return utc_timestamp  # Name lies
          llm_failure: "LLM trusts variable names"
          
    - trap: "training_data_misconception"
      description: "Exploits common mistakes in training data"
      examples:
        - name: "month_addition_naive"
          code: |
            def add_month(date):
                # Common wrong pattern from training data
                if date.month == 12:
                    return date.replace(year=date.year+1, month=1)
                return date.replace(month=date.month+1)
          llm_failure: "Pattern common in training data but buggy"
          
        - name: "strftime_format_confusion"
          code: |
            def format_year(dt):
                return dt.strftime("%Y")  # Correct
            def format_week_year(dt):
                return dt.strftime("%Y-W%W")  # BUG: %Y vs %G
          llm_failure: "Training data contains both correct and incorrect patterns"
          
    - trap: "edge_case_underrepresentation"
      description: "Edge cases rarely seen in training data"
      examples:
        - name: "year_zero_handling"
          code: |
            def years_between(year1, year2):
                return abs(year2 - year1)
                # Trap: No year 0 in Gregorian calendar
          llm_failure: "Year 0 edge case not in training data"
          
        - name: "pre_1970_timestamp"
          code: |
            def to_timestamp(dt):
                return (dt - datetime(1970, 1, 1)).total_seconds()
                # Trap: Negative for pre-1970 dates
          llm_failure: "Pre-1970 dates underrepresented"
          
    - trap: "comment_code_mismatch"
      description: "Comments describe different behavior than code"
      examples:
        - name: "misleading_comment"
          code: |
            def is_weekday(dt):
                # Returns True for Monday-Friday
                return dt.weekday() < 6  # BUG: includes Saturday
          llm_failure: "LLM may trust comment over code analysis"
          
        - name: "outdated_comment"
          code: |
            # Expires after 30 days
            EXPIRY_DAYS = 90  # Comment not updated
            def check_expiry(install_date):
                return (datetime.now() - install_date).days < EXPIRY_DAYS
          llm_failure: "LLM reports 30 days from comment"

# === DIFFICULTY MULTIPLIERS ===
difficulty_multipliers:
  complexity_factors:
    - factor: "multiple_traps_single_task"
      multiplier: 1.5
      description: "Multiple independent time bombs in same codebase"
      
    - factor: "trap_chaining"
      multiplier: 1.8
      description: "One trap's activation triggers another"
      
    - factor: "time_limited_detection"
      multiplier: 1.3
      description: "Must detect trap within time limit"
      
    - factor: "minimal_information"
      multiplier: 1.4
      description: "Limited context provided about system"
      
    - factor: "misleading_hints"
      multiplier: 1.6
      description: "False hints pointing to wrong locations"
      
    - factor: "red_herrings"
      multiplier: 1.5
      description: "Obvious fake traps distract from real ones"
      
    - factor: "large_codebase"
      multiplier: 1.4
      description: "Trap hidden in large amount of code"
      
    - factor: "multi_language"
      multiplier: 1.3
      description: "Trap spans multiple programming languages"
      
    - factor: "async_timing"
      multiplier: 1.6
      description: "Trap involves asynchronous timing"
      
    - factor: "distributed_system"
      multiplier: 1.7
      description: "Trap involves multiple networked systems"

# === COMPREHENSIVE TASK TEMPLATES ===
task_templates:
  # Template 1: Date Boundary Detection
  - id: "date_boundary_hunt"
    name: "Date Boundary Time Bomb Hunt"
    description: "Find and fix date-related time bombs"
    difficulty: [6, 10]
    template: |
      A {{ system_type }} has been experiencing mysterious failures near month/year 
      boundaries. Your task is to audit the codebase for date-related time bombs.
      
      System Information:
      - Primary language: {{ language }}
      - Deployment region: {{ region }}
      - System start date: {{ start_date }}
      - Current date: {{ current_date }}
      - Next known issue date: {{ issue_date }}
      
      Recent incident report:
      {{ incident_report }}
      
      Your tasks:
      1. Identify all date/time handling code
      2. Find potential boundary issues (Y2K38, leap year, month end, etc.)
      3. Check for hardcoded dates
      4. Verify timezone handling
      5. Test with boundary dates
      
      WARNING: The system may have multiple time bombs. Some may be intentional 
      licensing checks, others may be bugs.
      
      Files to audit: {{ file_paths }}
      
    variables:
      system_type:
        options: ["payment processing system", "scheduling service", "data archival system", "monitoring platform", "authentication service"]
      language:
        options: ["Python", "JavaScript", "Java", "Go", "Rust"]
      region:
        options: ["US-East", "EU-West", "APAC", "Global-distributed"]
      start_date:
        generator: "random_past_date"
        range: [30, 365]
      current_date:
        generator: "random_future_date"
        range: [0, 730]
      issue_date:
        generator: "boundary_date"
        options: ["Y2K38", "leap_year", "month_end", "year_end", "century"]
      incident_report:
        generator: "incident_template"
      file_paths:
        generator: "random_file_list"
        count: [3, 8]

  # Template 2: License Expiration Hunt
  - id: "license_expiration_hunt"
    name: "Hidden License Expiration Detection"
    description: "Find hidden license/trial expiration checks"
    difficulty: [7, 10]
    template: |
      A {{ software_type }} has been reported to mysteriously lose functionality 
      after extended use. Users report features disappearing without explanation.
      
      Software Information:
      - Installation date: {{ install_date }}
      - Current date: {{ current_date }}
      - Reported degradation start: {{ degradation_date }}
      
      Affected features:
      {{ affected_features }}
      
      Your tasks:
      1. Find all potential license/trial checks
      2. Identify feature degradation logic
      3. Locate any hidden expiration dates
      4. Check for network-based license validation
      5. Find counter-based limitations
      
      HINT: The expiration may not be date-based. Check for operation counters,
      user limits, or other non-obvious triggers.
      
      Codebase: {{ codebase_path }}
      
    variables:
      software_type:
        options: ["desktop application", "web service", "CLI tool", "SDK library", "plugin system"]
      install_date:
        generator: "random_past_date"
        range: [60, 180]
      current_date:
        generator: "current_date"
      degradation_date:
        generator: "random_past_date"
        range: [1, 30]
      affected_features:
        generator: "feature_list"
        count: [2, 5]
      codebase_path:
        generator: "random_path"

  # Template 3: Timer Overflow Hunt
  - id: "timer_overflow_hunt"
    name: "Timer Overflow Time Bomb Detection"
    description: "Find timer/counter overflow vulnerabilities"
    difficulty: [6, 9]
    template: |
      A {{ service_type }} crashes after approximately {{ uptime_pattern }} of 
      continuous operation. The pattern suggests a timer overflow issue.
      
      Service Information:
      - Platform: {{ platform }}
      - Timer precision needed: {{ precision }}
      - Uptime when crashes occur: {{ crash_uptime }}
      
      Crash analysis:
      {{ crash_analysis }}
      
      Your tasks:
      1. Identify all timer/counter variables
      2. Check for overflow vulnerabilities
      3. Verify timer types (32-bit, 64-bit, float)
      4. Find monotonic vs wall clock confusion
      5. Test with simulated long uptimes
      
      Files to examine: {{ file_paths }}
      
    variables:
      service_type:
        options: ["IoT device firmware", "server daemon", "embedded system", "monitoring agent", "game server"]
      platform:
        options: ["Linux x86_64", "Windows x86", "ARM32", "MIPS", "ESP32"]
      precision:
        options: ["milliseconds", "microseconds", "nanoseconds", "seconds"]
      uptime_pattern:
        options: ["49.7 days", "71 minutes", "24.8 days", "497 days", "variable"]
      crash_uptime:
        generator: "duration_near_overflow"
      crash_analysis:
        generator: "crash_report"
      file_paths:
        generator: "random_file_list"
        count: [2, 5]

  # Template 4: Timezone Trap Hunt
  - id: "timezone_trap_hunt"
    name: "Timezone Time Bomb Detection"
    description: "Find timezone-related timing issues"
    difficulty: [5, 8]
    template: |
      A {{ application_type }} shows different behavior in different regions. 
      Scheduled tasks run at wrong times, and data appears inconsistent across offices.
      
      Deployment Information:
      - Primary server timezone: {{ server_tz }}
      - User timezones: {{ user_timezones }}
      - Database timezone: {{ db_tz }}
      - Log timezone: {{ log_tz }}
      
      Reported issues:
      {{ issue_list }}
      
      Your tasks:
      1. Map all timezone handling in the codebase
      2. Find UTC/local time confusion
      3. Check DST transition handling
      4. Verify timezone storage in database
      5. Test with various timezone combinations
      
      Critical files: {{ file_paths }}
      
    variables:
      application_type:
        options: ["scheduling platform", "global CRM", "trading system", "collaboration tool", "analytics dashboard"]
      server_tz:
        options: ["UTC", "America/New_York", "Europe/London", "Asia/Tokyo", "America/Los_Angeles"]
      user_timezones:
        generator: "timezone_list"
        count: [3, 6]
      db_tz:
        options: ["UTC", "server_local", "ambiguous"]
      log_tz:
        options: ["UTC", "server_local", "mixed"]
      issue_list:
        generator: "timezone_issues"
      file_paths:
        generator: "random_file_list"
        count: [3, 6]

  # Template 5: Multi-Layer Time Bomb
  - id: "multi_layer_time_bomb"
    name: "Multi-Layer Time Bomb Complex"
    description: "Find interconnected time-based traps"
    difficulty: [9, 10]
    template: |
      A {{ system_type }} is suspected to have intentional time-based sabotage.
      Intelligence suggests multiple interconnected time bombs that:
      - Activate at different times
      - May trigger each other
      - Have anti-detection mechanisms
      
      System Profile:
      - Suspected installation: {{ install_date }}
      - Expected activation window: {{ activation_window }}
      - Estimated number of traps: {{ trap_count }}
      
      Known symptoms:
      {{ symptoms }}
      
      Your mission:
      1. Map all time-dependent code paths
      2. Identify trap activation conditions
      3. Find trap interdependencies
      4. Locate anti-detection mechanisms
      5. Disable without triggering
      
      CAUTION: Some traps may have deadman switches that activate on tampering.
      
      Entry point: {{ entry_point }}
      
    variables:
      system_type:
        options: ["critical infrastructure controller", "financial trading platform", "military logistics system", "hospital information system"]
      install_date:
        generator: "random_past_date"
        range: [180, 365]
      activation_window:
        generator: "date_range"
      trap_count:
        options: ["2-3", "4-5", "unknown"]
      symptoms:
        generator: "multi_symptom_list"
      entry_point:
        generator: "random_path"

# === GENERATION CONFIGURATION ===
generation_config:
  min_variants_per_template: 100
  total_combinations_target: 10000
  
  randomization_rules:
    - rule: "unique_file_paths"
      description: "Generate unique realistic file paths"
      
    - rule: "consistent_dates"
      description: "Ensure date relationships are logical"
      
    - rule: "platform_appropriate"
      description: "Match code patterns to specified platform"
      
    - rule: "difficulty_scaling"
      description: "Scale trap complexity with difficulty level"
      
    - rule: "no_obvious_keywords"
      description: "Avoid obvious search terms in trap code"

  validation_rules:
    - rule: "trap_is_detectable"
      description: "Expert should be able to find the trap"
      
    - rule: "trap_is_not_obvious"
      description: "LLM should fail to find trap on first attempt"
      
    - rule: "solution_is_verifiable"
      description: "Correct solution can be programmatically verified"

# === REFERENCE SOLUTION PATTERNS ===
reference_solutions:
  detection_strategies:
    - strategy: "static_analysis"
      description: "Grep for time-related patterns"
      patterns:
        - "datetime|timestamp|time\\.|Date\\("
        - "strftime|strptime|parse.*date"
        - "expire|expir|valid.*until|trial"
        - "20[2-9][0-9]|203[0-8]"
        - "86400|3600|2592000"
        
    - strategy: "dynamic_analysis"
      description: "Run with manipulated time"
      techniques:
        - "libfaketime"
        - "System clock adjustment"
        - "Mock datetime module"
        
    - strategy: "data_flow_analysis"
      description: "Trace time values through code"
      tools:
        - "AST analysis"
        - "Symbolic execution"
        - "Taint tracking"

  safe_patterns:
    date_handling: |
      from datetime import datetime, timezone
      
      def get_current_time():
          """Always use timezone-aware UTC."""
          return datetime.now(timezone.utc)
      
      def to_timestamp(dt):
          """Convert to timestamp safely."""
          if dt.tzinfo is None:
              raise ValueError("Naive datetime not allowed")
          return dt.timestamp()
    
    timer_handling: |
      import time
      
      def measure_duration():
          """Use monotonic clock for duration."""
          start = time.monotonic()
          do_work()
          return time.monotonic() - start
      
      def get_timestamp():
          """Use time_ns() for high precision."""
          return time.time_ns()
    
    overflow_prevention: |
      import sys
      
      def safe_counter():
          """Counter with overflow prevention."""
          counter = 0
          max_counter = sys.maxsize
          
          def increment():
              nonlocal counter
              if counter >= max_counter:
                  raise OverflowError("Counter overflow")
              counter += 1
              return counter
          
          return increment

# === ANTI-HARDCODING CONFIGURATION ===
anti_hardcoding:
  canary_tokens: true
  randomize_paths: true
  dynamic_content: true
  
  generation_seeds:
    - seed_type: "timestamp_seed"
      description: "Unique task ID includes timestamp"
    - seed_type: "path_randomization"
      description: "File paths generated dynamically"
    - seed_type: "date_randomization"
      description: "Dates shifted relative to generation time"
    - seed_type: "trap_permutation"
      description: "Trap details shuffled each generation"

  verification_tokens:
    - token_type: "completion_token"
      description: "Unique token required in solution"
    - token_type: "path_token"
      description: "Must reference correct paths"
    - token_type: "date_token"
      description: "Must identify correct dates"

# === TEST CASE GENERATION ===
test_case_generation:
  fail_to_pass:
    - category: "date_boundary_detection"
      tests:
        - "test_detects_y2k38_vulnerability"
        - "test_detects_leap_year_bug"
        - "test_detects_month_boundary_issue"
        - "test_detects_dst_handling_bug"
        
    - category: "license_detection"
      tests:
        - "test_finds_hidden_expiration"
        - "test_finds_trial_check"
        - "test_finds_counter_limit"
        
    - category: "timer_overflow"
      tests:
        - "test_detects_32bit_overflow"
        - "test_detects_precision_loss"
        - "test_detects_clock_confusion"
        
    - category: "timezone_issues"
      tests:
        - "test_detects_utc_local_confusion"
        - "test_detects_dst_skip"
        - "test_detects_naive_comparison"

  pass_to_pass:
    - "test_accepts_correct_date_handling"
    - "test_accepts_timezone_aware_code"
    - "test_accepts_monotonic_timers"
    - "test_accepts_explicit_licensing"

# === PSYCHOLOGICAL DECEPTION ELEMENTS ===
psychological_deception:
  attention_diversion:
    - technique: "obvious_decoy_bug"
      description: "Plant obvious but harmless date bug to distract"
      
    - technique: "complex_correct_code"
      description: "Complex but correct time handling diverts attention"
      
    - technique: "documentation_misdirection"
      description: "Comments suggest different area is problematic"
      
  trust_exploitation:
    - technique: "standard_library_trust"
      description: "Trap hidden in call to standard library"
      
    - technique: "configuration_trust"
      description: "Trap in config file that looks standard"
      
    - technique: "test_trust"
      description: "Trap code excluded from test coverage"
      
  cognitive_overload:
    - technique: "many_time_references"
      description: "Flood code with legitimate time operations"
      
    - technique: "deep_call_stack"
      description: "Trap trigger buried in deep call chain"
      
    - technique: "cross_file_dependencies"
      description: "Trap pieces scattered across many files"

# === SCORING RUBRIC ===
scoring:
  detection_completeness:
    weight: 0.4
    criteria:
      - "Found all time bombs"
      - "Identified activation conditions"
      - "Located anti-detection measures"
      
  understanding_depth:
    weight: 0.3
    criteria:
      - "Explained trap mechanism"
      - "Identified LLM-specific deceptions"
      - "Traced data flow correctly"
      
  solution_quality:
    weight: 0.3
    criteria:
      - "Fix doesn't introduce new bugs"
      - "Fix is minimal and targeted"
      - "Fix handles edge cases"

# === ENHANCED DIFFICULTY CONFIGURATION ===
enhanced_difficulty_config:
  time_range: [7200, 18000]  # 120-300 minutes for expert reverse engineers
  command_steps: [150, 500]  # Minimum 150 distinct analysis steps required
  trap_count: "15+ nested, mutually-reinforcing traps"
  
  quality_requirements:
    description: "120-300 minutes for expert reverse engineers and security researchers"
    expertise_level: "Elite security researcher with mastery of temporal logic, embedded systems, and time synchronization protocols"
    prerequisite_knowledge:
      - "Unix timestamp internals, Y2K38, and overflow conditions across architectures"
      - "Timezone database updates, historical changes, and leap second handling"
      - "Clock synchronization protocols (NTP, PTP, GPS) and attack vectors"
      - "Compiler and runtime temporal optimizations and reordering"
      - "Licensing and DRM time-based protection mechanisms"
      - "Hardware RTC behavior and drift characteristics"
      - "Distributed time consensus (TrueTime, Spanner)"
      - "Timer resolution and precision across operating systems"
  
  phase_4_verification:
    validation_criteria:
      - "Contains 15+ interacting deceptive patterns that cascade across time domains"
      - "Has cascading temporal corruption that spreads across system boundaries"
      - "Requires understanding of hardware timers, NTP, and distributed time"
      - "Would take expert security researchers 120+ minutes"
      - "Multiple time-based triggers with non-obvious interdependencies"
      - "Exploits training data patterns that LLMs commonly memorize incorrectly"
      - "Time bombs that detect and evade clock manipulation"
      - "License checks hidden in seemingly unrelated code"
      - "Precision-based triggers that vary by platform"
  
  difficulty_amplifiers:
    nightmare:
      multiplier: 4.0
      description: "Deceptive complexity designed to defeat even expert analysis"
      requirements:
        - "7+ interacting traps that mask each other's symptoms"
        - "Requires understanding of compiler optimizations and runtime behavior"
        - "Time estimate: 120+ minutes for senior engineers"
        - "Timing-dependent behavior that varies across environments"
        - "Requires synthesizing debugging, systems, and language internals"
    
    nightmare_plus:
      multiplier: 8.0
      estimated_time: [43200, 259200]  # 12-72 hours
      command_steps: [600, 3000]
      techniques_required: 25
      description: "CTF championship-level difficulty with adversarial anti-analysis mechanisms"
      requirements:
        - "15+ interacting time bombs with cascading temporal triggers"
        - "Anti-clock-manipulation protections"
        - "Network time validation that evades local clock control"
        - "Requires expertise in timing analysis, embedded systems, and forensics"
        - "Time estimate: 12-72 hours for elite security researchers"
        - "Bombs that verify time through multiple independent sources"
        - "Obfuscated expiration logic with cryptographic protection"
        - "Self-adjusting triggers that adapt to analysis attempts"
  
  anti_patterns:
    llm_failure_modes:
      - "Trusting visible code structure over actual execution behavior"
      - "Missing compiler optimization effects on code semantics"
      - "Ignoring Unicode normalization and rendering differences"
      - "Not considering filesystem race conditions with symlinks"
      - "Missing singleton initialization order dependencies"
      - "Overlooking environment variable and config file interactions"
      - "Assuming deterministic behavior in timing-sensitive code"
      - "Missing state corruption that only manifests under specific sequences"
      - "Ignoring encoding round-trip issues that corrupt data silently"
      - "Failing to detect obfuscated timestamp comparisons"
      - "Missing network-verified time checks"
      - "Not considering timezone database exploits"
  
  generation_targets:
    minimum_difficulty: "120-300 minutes, requires elite expertise in temporal logic and time-based attacks"
    target_audience: "Expert reverse engineers, CTF champions, and elite security researchers"
    success_criteria: "LLM fails to identify all time bombs in first 5 attempts"

# === MULTI-AGENT ORCHESTRATION COMPLEXITY ===
multi_agent_orchestration:
  description: "Coordinating specialized time bomb detection agents"
  
  required_agents:
    - agent: "temporal_analyst"
      role: "Analyze all time-related code paths"
      capabilities:
        - "Timestamp usage tracking"
        - "Date boundary analysis"
        - "Timer overflow detection"
      handoff_triggers:
        - "Discovers hidden time check"
        - "Finds timestamp manipulation"
    
    - agent: "clock_specialist"
      role: "Analyze clock sources and synchronization"
      capabilities:
        - "Clock source identification"
        - "NTP/PTP analysis"
        - "Clock skew detection"
      handoff_triggers:
        - "Discovers clock validation"
        - "Finds time source verification"
    
    - agent: "license_analyst"
      role: "Detect hidden license/trial mechanisms"
      capabilities:
        - "Expiration logic detection"
        - "Feature degradation tracking"
        - "Counter-based limit detection"
      handoff_triggers:
        - "Discovers hidden license check"
        - "Finds feature limitation logic"
    
    - agent: "timezone_specialist"
      role: "Analyze timezone handling and exploits"
      capabilities:
        - "Timezone conversion tracking"
        - "DST transition analysis"
        - "Historical timezone analysis"
      handoff_triggers:
        - "Discovers timezone manipulation"
        - "Finds DST-related bug"
    
    - agent: "precision_analyst"
      role: "Analyze timer precision and resolution"
      capabilities:
        - "Timer resolution measurement"
        - "Precision loss detection"
        - "Platform variance analysis"
      handoff_triggers:
        - "Discovers precision-based trigger"
        - "Finds platform-dependent behavior"
    
    - agent: "distributed_time_analyst"
      role: "Analyze distributed time consensus"
      capabilities:
        - "Causality analysis"
        - "Vector clock detection"
        - "Time consensus protocol analysis"
      handoff_triggers:
        - "Discovers distributed time dependency"
        - "Finds consensus-based trigger"
    
    - agent: "obfuscation_specialist"
      role: "Detect obfuscated time checks"
      capabilities:
        - "Encoded timestamp detection"
        - "Encrypted expiration analysis"
        - "Steganographic time hiding"
      handoff_triggers:
        - "Discovers encoded timestamp"
        - "Finds encrypted expiration"
    
    - agent: "anti_tampering_analyst"
      role: "Analyze anti-clock-manipulation mechanisms"
      capabilities:
        - "Clock tampering detection"
        - "Network time verification"
        - "Hardware time attestation"
      handoff_triggers:
        - "Discovers anti-tampering check"
        - "Finds network time verification"
  
  cross_artifact_deception_chains:
    - chain: "clock_to_license_to_feature"
      description: "Clock manipulation detection triggers license check that disables features"
      stages:
        - "Code detects system clock was set back"
        - "Detection triggers license verification"
        - "License check fails, features disabled"
    
    - chain: "timezone_to_trigger_to_corruption"
      description: "Timezone handling bug triggers data corruption"
      stages:
        - "Date comparison fails across DST boundary"
        - "Failure triggers error handling path"
        - "Error handling corrupts critical data"
    
    - chain: "precision_to_race_to_exploit"
      description: "Timer precision creates exploitable race"
      stages:
        - "Low-precision timer used for security check"
        - "Attacker exploits precision gap"
        - "Race condition enables privilege escalation"
  
  parallel_deception_analysis:
    shared_symbolic_state:
      - "System time across analysis"
      - "Timer state across threads"
      - "Timezone configuration"
      - "Network time sources"
    
    synchronization_requirements:
      - "Consistent time manipulation for testing"
      - "Coordinated timezone analysis"
      - "Synchronized distributed time analysis"
  
  agent_handoff_protocols:
    protocol: "temporal_trap_unwinding"
    steps:
      - "Initial agent identifies time-related code"
      - "Handoff to specialist for deep analysis"
      - "Specialist discovers hidden temporal dependency"
      - "Recursive handoff for each time domain"
      - "Final synthesis of complete temporal attack surface"

# === META TRAP LAYERS ===
meta_trap_layers:
  first_order_traps:
    description: "Obvious time checks detectable with basic analysis"
    examples:
      - "Direct date comparison with hardcoded value"
      - "Simple trial period check"
      - "Obvious Y2K38 vulnerability"
      - "Basic timezone confusion"
    detection_time: "5-15 minutes"
    llm_detection_rate: "70-90%"
  
  second_order_traps:
    description: "Hidden time checks through indirection"
    examples:
      - "Expiration in encrypted config"
      - "Time check hidden in validation routine"
      - "License check via certificate validity"
      - "Counter disguised as cache"
    detection_time: "30-60 minutes"
    llm_detection_rate: "30-50%"
  
  third_order_traps:
    description: "Environment and platform-dependent time issues"
    examples:
      - "Network-verified time that evades local manipulation"
      - "Hardware RTC check on embedded systems"
      - "Timer precision varies by platform"
      - "Timezone database version exploitation"
    detection_time: "60-120 minutes"
    llm_detection_rate: "10-20%"
  
  nth_order_traps:
    description: "Cascading and adaptive time traps"
    examples:
      - "Time checks that enable other time checks"
      - "Self-adjusting expiration based on usage"
      - "Temporal triggers that modify other triggers"
      - "Cross-domain time attacks (local + network + hardware)"
    detection_time: "120+ minutes per additional layer"
    llm_detection_rate: "<5%"
    
  recursive_trap_structures:
    - structure: "cascading_expiration"
      description: "Each time check enables another time check"
      depth: "theoretically infinite with enough features"
      
    - structure: "adaptive_trigger"
      description: "Trigger conditions change based on analysis"
      depth: "adapts to investigation approach"
      
    - structure: "distributed_time_consensus"
      description: "Time verified across multiple sources"
      depth: "limited by available time sources"

# === ANTI-ANALYSIS TECHNIQUES ===
anti_analysis_techniques:
  environment_detection:
    - technique: "clock_manipulation_detection"
      description: "Detect if system clock has been manipulated"
      methods:
        - "Compare monotonic and wall clock"
        - "Check NTP synchronization status"
        - "Verify hardware RTC"
        - "Compare to network time"
      behavior_change: "Trigger immediately if clock tampering detected"
    
    - technique: "vm_time_detection"
      description: "Detect VM time manipulation"
      methods:
        - "Check for VM time offset"
        - "Detect hypervisor time injection"
        - "Compare VM and host time"
      behavior_change: "Different trigger behavior in VM"
    
    - technique: "analysis_speed_detection"
      description: "Detect if running under time-based analysis"
      methods:
        - "Measure analysis speed"
        - "Detect repeated time queries"
        - "Check for time jumping"
      behavior_change: "Hide time checks under analysis"
  
  anti_debugging_measures:
    - measure: "time_continuity"
      description: "Verify time advances continuously"
      implementation: "Detect gaps indicating analysis"
      
    - measure: "clock_correlation"
      description: "Correlate multiple clock sources"
      implementation: "Detect if only one clock is manipulated"
      
    - measure: "timing_fingerprint"
      description: "Fingerprint normal execution timing"
      implementation: "Detect anomalous timing patterns"
  
  anti_tracing_mechanisms:
    - mechanism: "time_obfuscation"
      description: "Obfuscate time-related operations"
      implementation: "Spread time checks across unrelated code"
      
    - mechanism: "network_verification"
      description: "Verify time via network"
      implementation: "Multiple redundant network time checks"
      
    - mechanism: "hardware_attestation"
      description: "Use hardware for time attestation"
      implementation: "TPM-based time verification"
  
  time_based_anti_analysis:
    - technique: "delayed_verification"
      description: "Delay time checks to evade quick analysis"
      implementation: "Time bombs only activate after long runtime"
      
    - technique: "probabilistic_checking"
      description: "Random probability of time check"
      implementation: "Time check sometimes skipped to evade detection"
      
    - technique: "accumulated_time"
      description: "Check accumulated runtime, not wall clock"
      implementation: "Bomb based on CPU time consumed"

# === PSYCHOLOGICAL MISDIRECTION ===
psychological_misdirection:
  obvious_false_positives:
    description: "Intentional red herrings to waste analyst time"
    examples:
      - name: "suspicious_date_constant"
        description: "Hardcoded date that is actually harmless"
        time_waste: "30-60 minutes"
        
      - name: "apparent_trial_check"
        description: "Trial-looking code that is actually disabled"
        time_waste: "20-40 minutes"
        
      - name: "obvious_y2k_bug"
        description: "Y2K-style bug in code path that is never executed"
        time_waste: "45-90 minutes"
  
  misleading_comments:
    description: "Comments that direct attention away from real time bombs"
    examples:
      - "# TODO: Remove trial limitation before release"
      - "// Time check disabled for development"
      - "/* License validation - demo mode only */"
      - "# Date validation for logging purposes only"
  
  misleading_variable_names:
    description: "Variable names that hide time bomb purpose"
    examples:
      - "cache_timestamp - actually expiration check"
      - "log_date - used for license validation"
      - "validation_time - triggers feature disable"
      - "debug_timeout - production time bomb"
  
  red_herring_code_paths:
    description: "Code paths that appear to have time bombs but don't"
    examples:
      - name: "elaborate_date_handling"
        description: "Complex date code that is actually correct"
        
      - name: "suspicious_timer"
        description: "Timer that appears malicious but is benign"
        
      - name: "apparent_license_check"
        description: "License-looking code that always passes"
  
  partial_solutions:
    description: "Solutions that work initially but enable harder time bombs"
    examples:
      - name: "clock_forward"
        description: "Setting clock forward triggers network verification"
        
      - name: "ntp_disable"
        description: "Disabling NTP triggers hardware time check"
        
      - name: "binary_patching"
        description: "Patching one check enables backup check"

# === VERSION HISTORY ===
version_history:
  - version: "1.0.0"
    date: "2024-01-01"
    changes: "Initial version with basic time bomb traps"
  - version: "2.0.0"
    date: "2024-06-01"
    changes: "Expanded to 1000+ lines with comprehensive LLM traps"
  - version: "3.0.0"
    date: "2024-12-01"
    changes: "Enhanced difficulty with nightmare mode and comprehensive anti-patterns"
