//! Unified output format for collected and generated benchmark tasks.
//!
//! This module provides a standardized format for exporting benchmark tasks
//! from various sources (GitHub issues, synthetic generation, etc.) into a
//! consistent directory structure suitable for evaluation.
//!
//! # Directory Structure
//!
//! Each exported task creates the following structure:
//! ```text
//! output_dir/
//! └── task_id/
//!     ├── task.yaml          # Task specification
//!     ├── workdir/           # Working directory for task execution
//!     ├── test.sh            # Test script for verification
//!     ├── Dockerfile         # Container definition
//!     ├── .solution/         # Hidden solution (optionally encrypted)
//!     └── .canary            # Anti-memorization canary token
//! ```

use crate::error::ExportError;
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs::{self, File};
use std::io::Write;
use std::path::{Path, PathBuf};

// ============================================================================
// Task Source Types
// ============================================================================

/// Origin source of a benchmark task.
///
/// Tracks where a task was collected or generated from,
/// enabling provenance tracking and source-specific handling.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "kebab-case")]
pub enum TaskSource {
    /// Task collected from a GitHub repository issue.
    GitHubIssue {
        /// Repository owner/name (e.g., "rust-lang/rust")
        repo: String,
        /// Issue number
        issue_number: u64,
    },
    /// Task collected from a GitHub pull request.
    GitHubPullRequest {
        /// Repository owner/name
        repo: String,
        /// PR number
        pr_number: u64,
    },
    /// Task synthetically generated by the system.
    Synthetic {
        /// Generator identifier (e.g., "ideation-v1")
        generator: String,
        /// Generation timestamp
        generated_at: DateTime<Utc>,
    },
    /// Task from an internal benchmark collection.
    Internal {
        /// Collection identifier
        collection_id: String,
    },
    /// Task from external benchmark dataset.
    ExternalDataset {
        /// Dataset name
        dataset: String,
        /// Entry identifier within dataset
        entry_id: String,
    },
    /// Custom or unknown source.
    Custom {
        /// Source type identifier
        source_type: String,
        /// Additional metadata
        metadata: HashMap<String, String>,
    },
}

impl TaskSource {
    /// Creates a GitHub issue source.
    pub fn github_issue(repo: impl Into<String>, issue_number: u64) -> Self {
        Self::GitHubIssue {
            repo: repo.into(),
            issue_number,
        }
    }

    /// Creates a GitHub PR source.
    pub fn github_pr(repo: impl Into<String>, pr_number: u64) -> Self {
        Self::GitHubPullRequest {
            repo: repo.into(),
            pr_number,
        }
    }

    /// Creates a synthetic source.
    pub fn synthetic(generator: impl Into<String>) -> Self {
        Self::Synthetic {
            generator: generator.into(),
            generated_at: Utc::now(),
        }
    }

    /// Creates an internal source.
    pub fn internal(collection_id: impl Into<String>) -> Self {
        Self::Internal {
            collection_id: collection_id.into(),
        }
    }

    /// Creates an external dataset source.
    pub fn external_dataset(dataset: impl Into<String>, entry_id: impl Into<String>) -> Self {
        Self::ExternalDataset {
            dataset: dataset.into(),
            entry_id: entry_id.into(),
        }
    }

    /// Returns a human-readable description of the source.
    pub fn description(&self) -> String {
        match self {
            Self::GitHubIssue { repo, issue_number } => {
                format!("GitHub Issue: {}#{}", repo, issue_number)
            }
            Self::GitHubPullRequest { repo, pr_number } => {
                format!("GitHub PR: {}#{}", repo, pr_number)
            }
            Self::Synthetic {
                generator,
                generated_at,
            } => {
                format!(
                    "Synthetic: {} ({})",
                    generator,
                    generated_at.format("%Y-%m-%d")
                )
            }
            Self::Internal { collection_id } => format!("Internal: {}", collection_id),
            Self::ExternalDataset { dataset, entry_id } => {
                format!("External: {}:{}", dataset, entry_id)
            }
            Self::Custom {
                source_type,
                metadata: _,
            } => format!("Custom: {}", source_type),
        }
    }
}

// ============================================================================
// Verification Scripts
// ============================================================================

/// Test scripts for verifying task completion.
///
/// Contains two categories of tests:
/// - `fail_to_pass`: Tests that initially fail and should pass after correct implementation
/// - `pass_to_pass`: Tests that should pass before and after implementation (regression tests)
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct VerificationScripts {
    /// Tests that should fail initially and pass after correct implementation.
    pub fail_to_pass: Vec<String>,
    /// Tests that should pass throughout (regression tests).
    pub pass_to_pass: Vec<String>,
}

impl VerificationScripts {
    /// Creates a new empty VerificationScripts instance.
    pub fn new() -> Self {
        Self {
            fail_to_pass: Vec::new(),
            pass_to_pass: Vec::new(),
        }
    }

    /// Adds fail-to-pass test commands.
    pub fn with_fail_to_pass<I, S>(mut self, tests: I) -> Self
    where
        I: IntoIterator<Item = S>,
        S: Into<String>,
    {
        self.fail_to_pass.extend(tests.into_iter().map(Into::into));
        self
    }

    /// Adds pass-to-pass test commands.
    pub fn with_pass_to_pass<I, S>(mut self, tests: I) -> Self
    where
        I: IntoIterator<Item = S>,
        S: Into<String>,
    {
        self.pass_to_pass.extend(tests.into_iter().map(Into::into));
        self
    }

    /// Returns true if there are any verification tests.
    pub fn has_tests(&self) -> bool {
        !self.fail_to_pass.is_empty() || !self.pass_to_pass.is_empty()
    }

    /// Generates a shell test script content from the verification scripts.
    pub fn generate_test_script(&self) -> String {
        let mut script = String::from("#!/bin/bash\n");
        script.push_str("set -e\n\n");
        script.push_str("# Verification test script\n");
        script.push_str("# Generated by synth-bench unified exporter\n\n");

        script.push_str("PASS=0\n");
        script.push_str("FAIL=0\n\n");

        script.push_str("run_test() {\n");
        script.push_str("    local name=\"$1\"\n");
        script.push_str("    local cmd=\"$2\"\n");
        script.push_str("    echo \"Running: $name\"\n");
        script.push_str("    if eval \"$cmd\"; then\n");
        script.push_str("        echo \"  PASS: $name\"\n");
        script.push_str("        ((PASS++))\n");
        script.push_str("    else\n");
        script.push_str("        echo \"  FAIL: $name\"\n");
        script.push_str("        ((FAIL++))\n");
        script.push_str("    fi\n");
        script.push_str("}\n\n");

        script.push_str("echo \"=== Fail-to-Pass Tests ===\"\n");
        for (i, test) in self.fail_to_pass.iter().enumerate() {
            let escaped = test.replace('"', r#"\""#);
            script.push_str(&format!(
                "run_test \"fail_to_pass_{}\" \"{}\"\n",
                i + 1,
                escaped
            ));
        }
        script.push('\n');

        script.push_str("echo \"=== Pass-to-Pass Tests ===\"\n");
        for (i, test) in self.pass_to_pass.iter().enumerate() {
            let escaped = test.replace('"', r#"\""#);
            script.push_str(&format!(
                "run_test \"pass_to_pass_{}\" \"{}\"\n",
                i + 1,
                escaped
            ));
        }
        script.push('\n');

        script.push_str("echo \"\"\n");
        script.push_str("echo \"=== Summary ===\"\n");
        script.push_str("echo \"Passed: $PASS\"\n");
        script.push_str("echo \"Failed: $FAIL\"\n\n");

        script.push_str("if [ $FAIL -gt 0 ]; then\n");
        script.push_str("    exit 1\n");
        script.push_str("fi\n");
        script.push_str("exit 0\n");

        script
    }
}

// ============================================================================
// Task Output
// ============================================================================

/// Unified output format for benchmark tasks.
///
/// Represents a complete task specification ready for export,
/// including all metadata, verification scripts, and solution information.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskOutput {
    /// Unique task identifier.
    pub id: String,
    /// Source origin of the task.
    pub source_origin: TaskSource,
    /// Repository URL (if applicable).
    pub repo: Option<String>,
    /// Commit hash (if applicable).
    pub commit: Option<String>,
    /// Task instruction/problem statement.
    pub instruction: String,
    /// Difficulty level (easy/medium/hard).
    pub difficulty: String,
    /// Primary category.
    pub category: String,
    /// Tags for filtering and classification.
    pub tags: Vec<String>,
    /// Verification test scripts.
    pub verification: VerificationScripts,
    /// Anti-memorization canary identifier.
    pub canary_id: String,
    /// Hidden solution (if available).
    #[serde(skip_serializing_if = "Option::is_none")]
    pub solution: Option<String>,
    /// Dockerfile content for task environment.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub dockerfile: Option<String>,
    /// Additional working directory files.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub workdir_files: Option<HashMap<String, String>>,
    /// Task creation timestamp.
    pub created_at: DateTime<Utc>,
}

impl TaskOutput {
    /// Creates a new TaskOutput with required fields.
    pub fn new(
        id: impl Into<String>,
        source_origin: TaskSource,
        instruction: impl Into<String>,
        category: impl Into<String>,
        canary_id: impl Into<String>,
    ) -> Self {
        Self {
            id: id.into(),
            source_origin,
            repo: None,
            commit: None,
            instruction: instruction.into(),
            difficulty: "medium".to_string(),
            category: category.into(),
            tags: Vec::new(),
            verification: VerificationScripts::new(),
            canary_id: canary_id.into(),
            solution: None,
            dockerfile: None,
            workdir_files: None,
            created_at: Utc::now(),
        }
    }

    /// Sets the repository URL.
    pub fn with_repo(mut self, repo: impl Into<String>) -> Self {
        self.repo = Some(repo.into());
        self
    }

    /// Sets the commit hash.
    pub fn with_commit(mut self, commit: impl Into<String>) -> Self {
        self.commit = Some(commit.into());
        self
    }

    /// Sets the difficulty level.
    pub fn with_difficulty(mut self, difficulty: impl Into<String>) -> Self {
        self.difficulty = difficulty.into();
        self
    }

    /// Sets the tags.
    pub fn with_tags<I, S>(mut self, tags: I) -> Self
    where
        I: IntoIterator<Item = S>,
        S: Into<String>,
    {
        self.tags = tags.into_iter().map(Into::into).collect();
        self
    }

    /// Sets the verification scripts.
    pub fn with_verification(mut self, verification: VerificationScripts) -> Self {
        self.verification = verification;
        self
    }

    /// Sets the hidden solution.
    pub fn with_solution(mut self, solution: impl Into<String>) -> Self {
        self.solution = Some(solution.into());
        self
    }

    /// Sets the Dockerfile content.
    pub fn with_dockerfile(mut self, dockerfile: impl Into<String>) -> Self {
        self.dockerfile = Some(dockerfile.into());
        self
    }

    /// Adds working directory files.
    pub fn with_workdir_files(mut self, files: HashMap<String, String>) -> Self {
        self.workdir_files = Some(files);
        self
    }

    /// Writes the task.yaml file to the specified directory.
    pub fn write_task_yaml(&self, dir: &Path) -> Result<PathBuf, ExportError> {
        let yaml_path = dir.join("task.yaml");
        let yaml_content =
            serde_yaml::to_string(self).map_err(|e| ExportError::Serialization(e.to_string()))?;
        fs::write(&yaml_path, yaml_content)?;
        Ok(yaml_path)
    }

    /// Writes the test.sh script to the specified directory.
    pub fn write_test_script(&self, dir: &Path) -> Result<PathBuf, ExportError> {
        let script_path = dir.join("test.sh");
        let script_content = self.verification.generate_test_script();
        let mut file = File::create(&script_path)?;
        file.write_all(script_content.as_bytes())?;

        // Make script executable on Unix
        #[cfg(unix)]
        {
            use std::os::unix::fs::PermissionsExt;
            let mut perms = fs::metadata(&script_path)?.permissions();
            perms.set_mode(0o755);
            fs::set_permissions(&script_path, perms)?;
        }

        Ok(script_path)
    }

    /// Writes the Dockerfile to the specified directory.
    pub fn write_dockerfile(&self, dir: &Path) -> Result<PathBuf, ExportError> {
        let dockerfile_path = dir.join("Dockerfile");
        let content = self.dockerfile.clone().unwrap_or_else(|| {
            // Default minimal Dockerfile
            r#"FROM ubuntu:22.04

RUN apt-get update && apt-get install -y \
    bash \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /workspace
COPY workdir/ /workspace/

CMD ["/bin/bash"]
"#
            .to_string()
        });
        fs::write(&dockerfile_path, content)?;
        Ok(dockerfile_path)
    }

    /// Writes the solution to the specified directory.
    ///
    /// If `encrypted` is true, the solution is base64 encoded.
    /// In a production system, this would use proper encryption.
    pub fn write_solution(
        &self,
        dir: &Path,
        encrypted: bool,
    ) -> Result<Option<PathBuf>, ExportError> {
        let Some(solution) = &self.solution else {
            return Ok(None);
        };

        let solution_dir = dir.join(".solution");
        fs::create_dir_all(&solution_dir)?;

        let solution_path = solution_dir.join("solution.txt");
        let content = if encrypted {
            use base64::Engine;
            base64::engine::general_purpose::STANDARD.encode(solution)
        } else {
            solution.clone()
        };

        fs::write(&solution_path, content)?;
        Ok(Some(solution_path))
    }

    /// Writes the canary file to the specified directory.
    pub fn write_canary(&self, dir: &Path) -> Result<PathBuf, ExportError> {
        let canary_path = dir.join(".canary");
        fs::write(&canary_path, &self.canary_id)?;
        Ok(canary_path)
    }
}

// ============================================================================
// Task Output Directory
// ============================================================================

/// Represents the full output directory structure for a task.
#[derive(Debug, Clone)]
pub struct TaskOutputDirectory {
    /// Base path of the task directory.
    pub base_path: PathBuf,
    /// Path to task.yaml.
    pub task_yaml: PathBuf,
    /// Path to workdir/.
    pub workdir: PathBuf,
    /// Path to test.sh.
    pub test_script: PathBuf,
    /// Path to Dockerfile.
    pub dockerfile: PathBuf,
    /// Path to .solution/ (if exists).
    pub solution_dir: Option<PathBuf>,
    /// Path to .canary.
    pub canary_file: PathBuf,
}

impl TaskOutputDirectory {
    /// Creates a new TaskOutputDirectory from a base path and task.
    pub fn new(base_path: impl Into<PathBuf>) -> Self {
        let base = base_path.into();
        Self {
            task_yaml: base.join("task.yaml"),
            workdir: base.join("workdir"),
            test_script: base.join("test.sh"),
            dockerfile: base.join("Dockerfile"),
            solution_dir: None,
            canary_file: base.join(".canary"),
            base_path: base,
        }
    }

    /// Sets the solution directory path.
    pub fn with_solution_dir(mut self) -> Self {
        self.solution_dir = Some(self.base_path.join(".solution"));
        self
    }

    /// Returns true if all required files exist.
    pub fn is_complete(&self) -> bool {
        self.task_yaml.exists()
            && self.workdir.exists()
            && self.test_script.exists()
            && self.dockerfile.exists()
            && self.canary_file.exists()
    }
}

// ============================================================================
// Export Result
// ============================================================================

/// Result of a unified export operation.
#[derive(Debug, Clone)]
pub struct ExportResult {
    /// Output directory path.
    pub output_dir: PathBuf,
    /// Number of tasks successfully exported.
    pub exported_count: usize,
    /// Task IDs that were successfully exported.
    pub exported_ids: Vec<String>,
    /// Task IDs that failed to export with error messages.
    pub failed: Vec<(String, String)>,
    /// Export timestamp.
    pub exported_at: DateTime<Utc>,
}

// ============================================================================
// Unified Exporter
// ============================================================================

/// Exporter for unified task output format.
///
/// Creates a standardized directory structure for each task,
/// suitable for evaluation frameworks and dataset distribution.
///
/// # Example
///
/// ```ignore
/// use synth_bench::export::unified_format::{UnifiedExporter, TaskOutput, TaskSource};
///
/// let exporter = UnifiedExporter::new("./output")
///     .with_encrypt_solutions(true);
///
/// let task = TaskOutput::new(
///     "task-001",
///     TaskSource::synthetic("ideation-v1"),
///     "Fix the bug in the parser",
///     "debugging",
///     "CANARY_123",
/// );
///
/// let result = exporter.export(vec![task])?;
/// println!("Exported {} tasks", result.exported_count);
/// ```
pub struct UnifiedExporter {
    /// Output directory for exported tasks.
    output_dir: PathBuf,
    /// Whether to encrypt solutions.
    encrypt_solutions: bool,
}

impl UnifiedExporter {
    /// Creates a new UnifiedExporter with the specified output directory.
    pub fn new(output_dir: impl Into<PathBuf>) -> Self {
        Self {
            output_dir: output_dir.into(),
            encrypt_solutions: false,
        }
    }

    /// Sets whether to encrypt solution files.
    pub fn with_encrypt_solutions(mut self, encrypt: bool) -> Self {
        self.encrypt_solutions = encrypt;
        self
    }

    /// Returns the output directory path.
    pub fn output_dir(&self) -> &Path {
        &self.output_dir
    }

    /// Exports a collection of tasks to the unified format.
    ///
    /// Creates the directory structure for each task:
    /// - task_id/task.yaml
    /// - task_id/workdir/
    /// - task_id/test.sh
    /// - task_id/Dockerfile
    /// - task_id/.solution/ (if solution available)
    /// - task_id/.canary
    pub fn export(&self, tasks: Vec<TaskOutput>) -> Result<ExportResult, ExportError> {
        if tasks.is_empty() {
            return Err(ExportError::NoTasks);
        }

        // Create output directory
        fs::create_dir_all(&self.output_dir)?;

        let mut exported_ids = Vec::new();
        let mut failed = Vec::new();

        for task in tasks {
            match self.export_single_task(&task) {
                Ok(_) => exported_ids.push(task.id.clone()),
                Err(e) => failed.push((task.id.clone(), e.to_string())),
            }
        }

        if exported_ids.is_empty() && !failed.is_empty() {
            return Err(ExportError::DatasetCreationFailed(format!(
                "All tasks failed to export: {:?}",
                failed
            )));
        }

        Ok(ExportResult {
            output_dir: self.output_dir.clone(),
            exported_count: exported_ids.len(),
            exported_ids,
            failed,
            exported_at: Utc::now(),
        })
    }

    /// Exports a single task to its directory structure.
    fn export_single_task(&self, task: &TaskOutput) -> Result<TaskOutputDirectory, ExportError> {
        let task_dir = self.output_dir.join(&task.id);
        fs::create_dir_all(&task_dir)?;

        // Create workdir
        let workdir = task_dir.join("workdir");
        fs::create_dir_all(&workdir)?;

        // Write workdir files if any
        if let Some(files) = &task.workdir_files {
            for (filename, content) in files {
                let file_path = workdir.join(filename);
                if let Some(parent) = file_path.parent() {
                    fs::create_dir_all(parent)?;
                }
                fs::write(&file_path, content)?;
            }
        }

        // Write all task files
        task.write_task_yaml(&task_dir)?;
        task.write_test_script(&task_dir)?;
        task.write_dockerfile(&task_dir)?;
        task.write_canary(&task_dir)?;

        // Write solution if available
        let solution_dir = if task.solution.is_some() {
            task.write_solution(&task_dir, self.encrypt_solutions)?;
            Some(task_dir.join(".solution"))
        } else {
            None
        };

        Ok(TaskOutputDirectory {
            base_path: task_dir.clone(),
            task_yaml: task_dir.join("task.yaml"),
            workdir,
            test_script: task_dir.join("test.sh"),
            dockerfile: task_dir.join("Dockerfile"),
            solution_dir,
            canary_file: task_dir.join(".canary"),
        })
    }
}

// ============================================================================
// Tests
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    fn create_test_task(id: &str) -> TaskOutput {
        TaskOutput::new(
            id,
            TaskSource::synthetic("test-generator"),
            "Fix the bug in the authentication module",
            "debugging",
            format!("CANARY_{}", id),
        )
        .with_difficulty("medium")
        .with_tags(["rust", "authentication"])
        .with_verification(
            VerificationScripts::new()
                .with_fail_to_pass(["cargo test auth_test"])
                .with_pass_to_pass(["cargo test basic_test"]),
        )
        .with_solution("Use Option<T> instead of unwrap()")
    }

    #[test]
    fn test_task_source_github_issue() {
        let source = TaskSource::github_issue("rust-lang/rust", 12345);
        assert!(matches!(
            source,
            TaskSource::GitHubIssue {
                issue_number: 12345,
                ..
            }
        ));
        assert!(source.description().contains("rust-lang/rust#12345"));
    }

    #[test]
    fn test_task_source_github_pr() {
        let source = TaskSource::github_pr("tokio-rs/tokio", 9999);
        assert!(matches!(
            source,
            TaskSource::GitHubPullRequest {
                pr_number: 9999,
                ..
            }
        ));
        assert!(source.description().contains("tokio-rs/tokio#9999"));
    }

    #[test]
    fn test_task_source_synthetic() {
        let source = TaskSource::synthetic("ideation-v1");
        assert!(matches!(source, TaskSource::Synthetic { .. }));
        assert!(source.description().contains("ideation-v1"));
    }

    #[test]
    fn test_task_source_internal() {
        let source = TaskSource::internal("benchmark-v2");
        assert!(matches!(source, TaskSource::Internal { .. }));
        assert!(source.description().contains("benchmark-v2"));
    }

    #[test]
    fn test_task_source_external_dataset() {
        let source = TaskSource::external_dataset("swe-bench", "entry-123");
        assert!(matches!(source, TaskSource::ExternalDataset { .. }));
        assert!(source.description().contains("swe-bench:entry-123"));
    }

    #[test]
    fn test_verification_scripts_new() {
        let scripts = VerificationScripts::new();
        assert!(scripts.fail_to_pass.is_empty());
        assert!(scripts.pass_to_pass.is_empty());
        assert!(!scripts.has_tests());
    }

    #[test]
    fn test_verification_scripts_with_tests() {
        let scripts = VerificationScripts::new()
            .with_fail_to_pass(["test1", "test2"])
            .with_pass_to_pass(["test3"]);

        assert_eq!(scripts.fail_to_pass.len(), 2);
        assert_eq!(scripts.pass_to_pass.len(), 1);
        assert!(scripts.has_tests());
    }

    #[test]
    fn test_verification_scripts_generate_test_script() {
        let scripts = VerificationScripts::new()
            .with_fail_to_pass(["cargo test fail_test"])
            .with_pass_to_pass(["cargo test pass_test"]);

        let script = scripts.generate_test_script();

        assert!(script.starts_with("#!/bin/bash"));
        assert!(script.contains("Fail-to-Pass Tests"));
        assert!(script.contains("Pass-to-Pass Tests"));
        assert!(script.contains("cargo test fail_test"));
        assert!(script.contains("cargo test pass_test"));
        assert!(script.contains("exit 0"));
    }

    #[test]
    fn test_task_output_new() {
        let task = TaskOutput::new(
            "task-001",
            TaskSource::synthetic("test"),
            "Fix the bug",
            "debugging",
            "CANARY_001",
        );

        assert_eq!(task.id, "task-001");
        assert_eq!(task.instruction, "Fix the bug");
        assert_eq!(task.category, "debugging");
        assert_eq!(task.canary_id, "CANARY_001");
        assert_eq!(task.difficulty, "medium");
    }

    #[test]
    fn test_task_output_builder_methods() {
        let task = TaskOutput::new(
            "task-002",
            TaskSource::github_issue("org/repo", 100),
            "Implement feature",
            "software-engineering",
            "CANARY_002",
        )
        .with_repo("https://github.com/org/repo")
        .with_commit("abc123")
        .with_difficulty("hard")
        .with_tags(["feature", "enhancement"])
        .with_solution("Use the builder pattern");

        assert_eq!(task.repo, Some("https://github.com/org/repo".to_string()));
        assert_eq!(task.commit, Some("abc123".to_string()));
        assert_eq!(task.difficulty, "hard");
        assert_eq!(task.tags, vec!["feature", "enhancement"]);
        assert!(task.solution.is_some());
    }

    #[test]
    fn test_task_output_write_task_yaml() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let task = create_test_task("task-yaml-test");

        let path = task
            .write_task_yaml(temp_dir.path())
            .expect("should write yaml");

        assert!(path.exists());
        let content = fs::read_to_string(&path).expect("should read file");
        assert!(content.contains("task-yaml-test"));
        assert!(content.contains("debugging"));
    }

    #[test]
    fn test_task_output_write_test_script() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let task = create_test_task("task-script-test");

        let path = task
            .write_test_script(temp_dir.path())
            .expect("should write script");

        assert!(path.exists());
        let content = fs::read_to_string(&path).expect("should read file");
        assert!(content.contains("#!/bin/bash"));
        assert!(content.contains("cargo test auth_test"));
    }

    #[test]
    fn test_task_output_write_dockerfile() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let task = create_test_task("task-docker-test");

        let path = task
            .write_dockerfile(temp_dir.path())
            .expect("should write Dockerfile");

        assert!(path.exists());
        let content = fs::read_to_string(&path).expect("should read file");
        assert!(content.contains("FROM"));
    }

    #[test]
    fn test_task_output_write_dockerfile_custom() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let task = create_test_task("task-docker-custom")
            .with_dockerfile("FROM rust:1.70\nWORKDIR /app\n");

        let path = task
            .write_dockerfile(temp_dir.path())
            .expect("should write Dockerfile");

        let content = fs::read_to_string(&path).expect("should read file");
        assert!(content.contains("FROM rust:1.70"));
    }

    #[test]
    fn test_task_output_write_solution_unencrypted() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let task = create_test_task("task-solution-test");

        let path = task
            .write_solution(temp_dir.path(), false)
            .expect("should write solution");

        assert!(path.is_some());
        let solution_path = path.unwrap();
        assert!(solution_path.exists());
        let content = fs::read_to_string(&solution_path).expect("should read file");
        assert!(content.contains("Option<T>"));
    }

    #[test]
    fn test_task_output_write_solution_encrypted() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let task = create_test_task("task-solution-encrypted");

        let path = task
            .write_solution(temp_dir.path(), true)
            .expect("should write solution");

        assert!(path.is_some());
        let solution_path = path.unwrap();
        let content = fs::read_to_string(&solution_path).expect("should read file");
        // Should be base64 encoded
        assert!(!content.contains("Option<T>"));
    }

    #[test]
    fn test_task_output_write_solution_none() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let task = TaskOutput::new(
            "task-no-solution",
            TaskSource::synthetic("test"),
            "No solution provided",
            "debugging",
            "CANARY",
        );

        let path = task
            .write_solution(temp_dir.path(), false)
            .expect("should handle no solution");

        assert!(path.is_none());
    }

    #[test]
    fn test_task_output_write_canary() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let task = create_test_task("task-canary-test");

        let path = task
            .write_canary(temp_dir.path())
            .expect("should write canary");

        assert!(path.exists());
        let content = fs::read_to_string(&path).expect("should read file");
        assert!(content.contains("CANARY_task-canary-test"));
    }

    #[test]
    fn test_task_output_directory_new() {
        let dir = TaskOutputDirectory::new("/tmp/test-task");

        assert_eq!(dir.base_path, PathBuf::from("/tmp/test-task"));
        assert_eq!(dir.task_yaml, PathBuf::from("/tmp/test-task/task.yaml"));
        assert_eq!(dir.workdir, PathBuf::from("/tmp/test-task/workdir"));
        assert_eq!(dir.test_script, PathBuf::from("/tmp/test-task/test.sh"));
        assert_eq!(dir.dockerfile, PathBuf::from("/tmp/test-task/Dockerfile"));
        assert!(dir.solution_dir.is_none());
    }

    #[test]
    fn test_task_output_directory_with_solution() {
        let dir = TaskOutputDirectory::new("/tmp/test-task").with_solution_dir();

        assert!(dir.solution_dir.is_some());
        assert_eq!(
            dir.solution_dir,
            Some(PathBuf::from("/tmp/test-task/.solution"))
        );
    }

    #[test]
    fn test_unified_exporter_new() {
        let exporter = UnifiedExporter::new("/tmp/export");

        assert_eq!(exporter.output_dir(), Path::new("/tmp/export"));
        assert!(!exporter.encrypt_solutions);
    }

    #[test]
    fn test_unified_exporter_with_encrypt() {
        let exporter = UnifiedExporter::new("/tmp/export").with_encrypt_solutions(true);

        assert!(exporter.encrypt_solutions);
    }

    #[test]
    fn test_unified_exporter_export_empty() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let exporter = UnifiedExporter::new(temp_dir.path());

        let result = exporter.export(vec![]);

        assert!(matches!(result, Err(ExportError::NoTasks)));
    }

    #[test]
    fn test_unified_exporter_export_single_task() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let exporter = UnifiedExporter::new(temp_dir.path());

        let task = create_test_task("export-test-001");
        let result = exporter.export(vec![task]).expect("should export");

        assert_eq!(result.exported_count, 1);
        assert_eq!(result.exported_ids, vec!["export-test-001"]);
        assert!(result.failed.is_empty());

        // Verify directory structure
        let task_dir = temp_dir.path().join("export-test-001");
        assert!(task_dir.exists());
        assert!(task_dir.join("task.yaml").exists());
        assert!(task_dir.join("workdir").exists());
        assert!(task_dir.join("test.sh").exists());
        assert!(task_dir.join("Dockerfile").exists());
        assert!(task_dir.join(".canary").exists());
        assert!(task_dir.join(".solution").exists());
    }

    #[test]
    fn test_unified_exporter_export_multiple_tasks() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let exporter = UnifiedExporter::new(temp_dir.path());

        let tasks = vec![
            create_test_task("multi-001"),
            create_test_task("multi-002"),
            create_test_task("multi-003"),
        ];
        let result = exporter.export(tasks).expect("should export");

        assert_eq!(result.exported_count, 3);
        assert!(result.failed.is_empty());

        for id in ["multi-001", "multi-002", "multi-003"] {
            let task_dir = temp_dir.path().join(id);
            assert!(task_dir.exists(), "Task dir {} should exist", id);
        }
    }

    #[test]
    fn test_unified_exporter_with_workdir_files() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let exporter = UnifiedExporter::new(temp_dir.path());

        let mut files = HashMap::new();
        files.insert("main.rs".to_string(), "fn main() {}".to_string());
        files.insert("lib.rs".to_string(), "pub mod test;".to_string());

        let task = create_test_task("workdir-test").with_workdir_files(files);
        let result = exporter.export(vec![task]).expect("should export");

        assert_eq!(result.exported_count, 1);

        let workdir = temp_dir.path().join("workdir-test/workdir");
        assert!(workdir.join("main.rs").exists());
        assert!(workdir.join("lib.rs").exists());

        let main_content = fs::read_to_string(workdir.join("main.rs")).expect("should read");
        assert_eq!(main_content, "fn main() {}");
    }

    #[test]
    fn test_unified_exporter_encrypted_solutions() {
        let temp_dir = TempDir::new().expect("should create temp dir");
        let exporter = UnifiedExporter::new(temp_dir.path()).with_encrypt_solutions(true);

        let task = create_test_task("encrypted-test");
        exporter.export(vec![task]).expect("should export");

        let solution_path = temp_dir
            .path()
            .join("encrypted-test/.solution/solution.txt");
        let content = fs::read_to_string(solution_path).expect("should read");

        // Content should be base64 encoded
        assert!(!content.contains("Option<T>"));
    }

    #[test]
    fn test_task_source_serialization() {
        let source = TaskSource::github_issue("test/repo", 42);
        let json = serde_json::to_string(&source).expect("should serialize");
        let parsed: TaskSource = serde_json::from_str(&json).expect("should deserialize");

        assert_eq!(source, parsed);
    }

    #[test]
    fn test_verification_scripts_serialization() {
        let scripts = VerificationScripts::new()
            .with_fail_to_pass(["test1"])
            .with_pass_to_pass(["test2"]);

        let json = serde_json::to_string(&scripts).expect("should serialize");
        let parsed: VerificationScripts = serde_json::from_str(&json).expect("should deserialize");

        assert_eq!(scripts.fail_to_pass, parsed.fail_to_pass);
        assert_eq!(scripts.pass_to_pass, parsed.pass_to_pass);
    }

    #[test]
    fn test_task_output_serialization() {
        let task = create_test_task("serial-test");
        let json = serde_json::to_string(&task).expect("should serialize");
        let parsed: TaskOutput = serde_json::from_str(&json).expect("should deserialize");

        assert_eq!(task.id, parsed.id);
        assert_eq!(task.instruction, parsed.instruction);
        assert_eq!(task.category, parsed.category);
    }

    #[test]
    fn test_task_output_yaml_serialization() {
        let task = create_test_task("yaml-test");
        let yaml = serde_yaml::to_string(&task).expect("should serialize");

        assert!(yaml.contains("id: yaml-test"));
        assert!(yaml.contains("category: debugging"));
    }
}
