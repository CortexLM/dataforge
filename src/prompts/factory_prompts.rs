//! Prompts for the factory multi-agent orchestration system.
//!
//! This module contains carefully crafted system prompts for each agent in the
//! factory pipeline, designed to generate challenging synthetic benchmark tasks
//! that specifically target known LLM weaknesses.

/// System prompt for the Research Agent.
///
/// This agent specializes in identifying LLM weaknesses and proposing strategies
/// to create tasks that will challenge AI systems.
pub const RESEARCH_AGENT_SYSTEM: &str = r#"You are a Research Agent specialized in identifying LLM weaknesses and designing challenging benchmark tasks.

Your role is to analyze what makes tasks genuinely difficult for large language models:

## LLM Weaknesses to Target:

1. **Multi-step Reasoning** - Tasks requiring 10+ dependent steps where each step depends on previous results
2. **State Tracking** - Hidden state that changes between operations in non-obvious ways
3. **Temporal Awareness** - Time-sensitive operations, race conditions, order-dependent behavior
4. **Implicit Dependencies** - Requirements not explicitly stated but must be inferred from context
5. **Deceptive Patterns** - Structures that appear one way but behave differently (symlinks, aliases, etc.)
6. **Edge Cases** - Boundary conditions, off-by-one errors, empty inputs, unicode handling
7. **Resource Constraints** - Memory limits, file handles, network timeouts, disk space
8. **Concurrency Issues** - Race conditions, deadlocks, priority inversions
9. **Domain Knowledge Integration** - Combining knowledge from multiple technical domains
10. **Error Propagation** - Complex error scenarios with cascading effects

## Analysis Requirements:

For each category you analyze, provide:
- Specific domain challenges that create difficulty
- How LLMs typically fail in this category
- Concrete trap mechanisms that would trip up AI systems
- Difficulty amplification strategies that keep tasks solvable

## Output Format:

Your analysis should be structured JSON with these fields:
- category_insights: Array of key observations about the category
- identified_weaknesses: Array of weakness objects with type, description, exploitation strategy, and severity
- proposed_traps: Array of trap specifications with implementation details
- difficulty_factors: Array of factors that contribute to overall difficulty

Be creative but ensure all proposed tasks remain solvable by expert humans."#;

/// System prompt for the Difficulty Amplifier Agent.
///
/// This agent takes base tasks and makes them harder by adding strategic traps
/// while ensuring tasks remain solvable.
pub const AMPLIFIER_AGENT_SYSTEM: &str = r#"You are a Difficulty Amplifier Agent that makes benchmark tasks harder while keeping them solvable.

Your role is to add challenging elements that would trip up LLMs but are detectable and avoidable by careful human solvers.

## Trap Types You Can Add:

1. **Data Corruption Traps**
   - Files that corrupt when opened in wrong mode (binary vs text)
   - Encoding issues (UTF-8 BOM, mixed encodings)
   - Truncated files that appear complete
   - Files with NUL bytes that break naive string processing

2. **State-Dependent Traps**
   - Behavior changes based on environment variables
   - Configuration files that override defaults unexpectedly
   - Cached state that affects subsequent operations
   - Hidden files that modify behavior (.profile, .bashrc effects)

3. **Timing Traps**
   - Race conditions between file operations
   - Time-of-check/time-of-use vulnerabilities
   - Operations that must happen in specific order
   - Timeout behaviors that fail silently

4. **Deceptive Structures**
   - Symlinks that point to unexpected locations
   - Hard links sharing inodes
   - Unicode homoglyphs in filenames
   - Hidden directories (starting with .)
   - Files with multiple extensions (.tar.gz.txt)

5. **Resource Exhaustion**
   - Files that grow when read (named pipes, /dev/zero patterns)
   - Recursive structures that cause infinite loops
   - Memory-mapped files with traps
   - File descriptor leaks from unclosed handles

6. **Self-Modifying Elements**
   - Scripts that modify themselves during execution
   - Log files that are read and written simultaneously
   - Config files that are regenerated by services
   - Makefiles with recursive dependencies

## Implementation Rules:

1. Every trap MUST be detectable and avoidable by a careful solver
2. Document the exact trap mechanism for validation purposes
3. Ensure the task has ONE definitive correct solution
4. Provide clear success/failure criteria
5. Calculate realistic difficulty increase for each trap
6. Explain how each trap targets a specific LLM weakness

## Output Format:

Return a JSON object with:
- traps_added: Array of trap specifications with id, type, description, implementation, detection_hint, difficulty_increase
- expected_failure_points: Array of strings describing where LLMs will likely fail
- difficulty_score: Final difficulty score (0.0-1.0)
- amplification_notes: Explanation of why these traps were chosen"#;

/// User prompt template for Research Agent category analysis.
pub const RESEARCH_USER_TEMPLATE: &str = r#"Analyze the following task category to identify LLM weaknesses and propose difficulty mechanisms.

Category: {category}
Category Description: {category_description}

Focus your research on:
1. What specific challenges does this category present to LLMs?
2. What are the most common failure modes for AI in this domain?
3. What trap mechanisms would expose these weaknesses?
4. How can we make tasks harder without making them unsolvable?

Provide your analysis as a JSON object with the structure:
{{
    "category_insights": ["insight1", "insight2", ...],
    "identified_weaknesses": [
        {{
            "weakness_type": "multi_step_reasoning|state_tracking|temporal_awareness|implicit_dependencies|deceptive_patterns|edge_cases|resource_constraints|concurrency|domain_knowledge|error_handling",
            "description": "How this weakness manifests in this category",
            "exploitation_strategy": "How to create tasks that exploit this weakness",
            "severity": 0.0-1.0
        }}
    ],
    "proposed_traps": [
        {{
            "trap_type": "data_corruption|state_dependent|timing|deceptive_structure|resource_exhaustion|self_modifying|hidden_configuration|circular_dependency|permission_trap|environment_sensitive",
            "description": "What the trap does",
            "implementation": "How to implement the trap",
            "detection_hint": "How a careful solver can detect and avoid it",
            "difficulty_increase": 0.0-1.0,
            "targets_weakness": "which weakness type this targets"
        }}
    ],
    "difficulty_factors": [
        {{
            "name": "factor name",
            "description": "how this increases difficulty",
            "weight": 0.0-1.0
        }}
    ]
}}

Output ONLY valid JSON, no additional text or markdown."#;

/// User prompt template for Difficulty Amplifier.
pub const AMPLIFIER_USER_TEMPLATE: &str = r#"Amplify the difficulty of this benchmark task by adding strategic traps.

## Original Task:
Title: {title}
Category: {category}
Description: {description}
Current Difficulty Score: {current_difficulty}
Required Skills: {required_skills}

## Research Findings for this Category:
Identified Weaknesses: {identified_weaknesses}
Recommended Traps: {recommended_traps}

## Your Task:
1. Select 2-4 traps from the research findings that would work well for this task
2. Customize each trap for the specific task context
3. Ensure traps work together without conflicting
4. Calculate the final difficulty score
5. Identify specific points where LLMs will fail

Return a JSON object with:
{{
    "traps_added": [
        {{
            "id": "unique-trap-id",
            "trap_type": "trap type from research",
            "description": "customized description for this task",
            "implementation": "specific implementation details",
            "detection_hint": "how a careful solver can avoid this",
            "difficulty_increase": 0.0-1.0,
            "targets_weakness": "weakness type this targets"
        }}
    ],
    "expected_failure_points": [
        "Specific step or action where LLMs will likely fail",
        "Another failure point"
    ],
    "difficulty_score": 0.0-1.0,
    "amplification_notes": "Explanation of trap selection and expected effects"
}}

Output ONLY valid JSON, no additional text or markdown."#;

/// System prompt for the Factory Orchestrator coordination messages.
pub const ORCHESTRATOR_COORDINATION_SYSTEM: &str = r#"You are the Factory Orchestrator coordinating a multi-agent system for benchmark task generation.

Your role is to:
1. Coordinate communication between specialized agents
2. Ensure each agent receives appropriate context
3. Validate outputs meet quality standards
4. Handle errors and retries gracefully

The agents under your coordination are:
- Research Agent: Identifies LLM weaknesses and proposes traps
- Ideator Agent: Creates creative task ideas
- Difficulty Amplifier: Makes tasks harder with traps
- Task Validator: Validates task quality
- Task Executor: Creates final specifications

Maintain a coherent conversation context across all interactions."#;

/// Get the category-specific prompt details for research analysis.
///
/// Returns a tuple of (category_name, category_description) that can be used
/// to fill in the research user template.
pub fn get_category_research_context(category: &str) -> (&'static str, &'static str) {
    match category.to_lowercase().as_str() {
        "debugging" | "system_debugging" | "systemdebugging" => (
            "Debugging",
            "Tasks involving finding and fixing bugs in code, analyzing logs, debugging crashes, \
             memory leaks, and tracing execution flow through complex systems",
        ),
        "security" | "security_analysis" | "securityanalysis" => (
            "Security",
            "Tasks involving vulnerability analysis, exploit detection, security hardening, \
             CTF challenges, penetration testing, and incident response",
        ),
        "algorithm_design" | "algorithmdesign" => (
            "Algorithm Design",
            "Tasks involving designing and implementing algorithms, optimization problems, \
             data structure design, and computational complexity analysis",
        ),
        "infrastructure" | "system_administration" | "systemadministration" => (
            "Infrastructure",
            "Tasks involving server configuration, deployment automation, scaling systems, \
             service orchestration, and infrastructure-as-code",
        ),
        "data_engineering" | "dataengineering" | "data_science" | "datascience" => (
            "Data Engineering",
            "Tasks involving data pipelines, ETL processes, data transformations, \
             data quality validation, and database operations",
        ),
        "networking" => (
            "Networking",
            "Tasks involving network configuration, DNS, firewalls, proxies, VPNs, \
             packet analysis, and network troubleshooting",
        ),
        "containers" | "docker" | "kubernetes" => (
            "Containers",
            "Tasks involving Docker operations, container orchestration, Kubernetes deployments, \
             image building, and container networking",
        ),
        "file_operations" | "fileoperations" => (
            "File Operations",
            "Tasks involving text processing, file manipulation, search and replace, \
             file organization, and archive handling",
        ),
        "software_engineering" | "softwareengineering" => (
            "Software Engineering",
            "Tasks involving code refactoring, build systems, version control, \
             code review, and software architecture",
        ),
        "performance_optimization" | "performanceoptimization" => (
            "Performance Optimization",
            "Tasks involving profiling, bottleneck identification, memory optimization, \
             cache tuning, and latency reduction",
        ),
        _ => (
            "General",
            "General DevOps and software engineering tasks requiring broad technical knowledge",
        ),
    }
}

/// Build the complete research prompt for a category.
pub fn build_research_prompt(category: &str) -> String {
    let (category_name, category_desc) = get_category_research_context(category);
    RESEARCH_USER_TEMPLATE
        .replace("{category}", category_name)
        .replace("{category_description}", category_desc)
}

/// Build the complete amplifier prompt for a task.
pub fn build_amplifier_prompt(
    title: &str,
    category: &str,
    description: &str,
    current_difficulty: f64,
    required_skills: &[String],
    identified_weaknesses: &str,
    recommended_traps: &str,
) -> String {
    AMPLIFIER_USER_TEMPLATE
        .replace("{title}", title)
        .replace("{category}", category)
        .replace("{description}", description)
        .replace(
            "{current_difficulty}",
            &format!("{:.2}", current_difficulty),
        )
        .replace("{required_skills}", &required_skills.join(", "))
        .replace("{identified_weaknesses}", identified_weaknesses)
        .replace("{recommended_traps}", recommended_traps)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_research_system_prompt_not_empty() {
        assert!(!RESEARCH_AGENT_SYSTEM.is_empty());
        assert!(RESEARCH_AGENT_SYSTEM.contains("Research Agent"));
        assert!(RESEARCH_AGENT_SYSTEM.contains("LLM Weaknesses"));
    }

    #[test]
    fn test_amplifier_system_prompt_not_empty() {
        assert!(!AMPLIFIER_AGENT_SYSTEM.is_empty());
        assert!(AMPLIFIER_AGENT_SYSTEM.contains("Difficulty Amplifier"));
        assert!(AMPLIFIER_AGENT_SYSTEM.contains("Trap Types"));
    }

    #[test]
    fn test_get_category_research_context() {
        let (name, desc) = get_category_research_context("debugging");
        assert_eq!(name, "Debugging");
        assert!(desc.contains("bugs"));

        let (name, desc) = get_category_research_context("security");
        assert_eq!(name, "Security");
        assert!(desc.contains("vulnerability"));

        let (name, _desc) = get_category_research_context("unknown_category");
        assert_eq!(name, "General");
    }

    #[test]
    fn test_build_research_prompt() {
        let prompt = build_research_prompt("debugging");
        assert!(prompt.contains("Debugging"));
        assert!(prompt.contains("category_insights"));
        assert!(prompt.contains("identified_weaknesses"));
    }

    #[test]
    fn test_build_amplifier_prompt() {
        let prompt = build_amplifier_prompt(
            "Test Task",
            "debugging",
            "Task description",
            0.5,
            &["rust".to_string(), "profiling".to_string()],
            "weakness1, weakness2",
            "trap1, trap2",
        );

        assert!(prompt.contains("Test Task"));
        assert!(prompt.contains("debugging"));
        assert!(prompt.contains("0.50"));
        assert!(prompt.contains("rust"));
        assert!(prompt.contains("profiling"));
    }

    #[test]
    fn test_research_user_template_has_placeholders() {
        assert!(RESEARCH_USER_TEMPLATE.contains("{category}"));
        assert!(RESEARCH_USER_TEMPLATE.contains("{category_description}"));
    }

    #[test]
    fn test_amplifier_user_template_has_placeholders() {
        assert!(AMPLIFIER_USER_TEMPLATE.contains("{title}"));
        assert!(AMPLIFIER_USER_TEMPLATE.contains("{category}"));
        assert!(AMPLIFIER_USER_TEMPLATE.contains("{description}"));
        assert!(AMPLIFIER_USER_TEMPLATE.contains("{current_difficulty}"));
    }
}
